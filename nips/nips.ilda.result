0: A Dynamical Approach to Temporal Pattern Processing
    id = 77
    authors = Hogg_T Huberman_B Stornetta_W 
    10 (0.21350): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    19 (0.20048): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    4 (0.07355): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.06705): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.06379): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.03776): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

1: Minkowski-r Back-Propagation: Learning in Connectionist Models with Non-Euclidian Error Signals
    id = 36
    authors = Burr_D Hanson_S 
    6 (0.17770): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    13 (0.17119): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    14 (0.14841): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    3 (0.12237): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.03776): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    12 (0.01497): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

2: Data Analysis Using G/Splines
    id = 562
    authors = Rogers_D 
    27 (0.30462): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    5 (0.17444): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    13 (0.09308): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    61 (0.02474): 16 error  (0.07108) 21 problem  (0.07108) 17 state  (0.07108) 18 results  (0.07108) 23 hidden  (0.07108) 15 system  (0.07108) 4 input  (0.03019) 7 figure  (0.03019) 5 data  (0.03019) 6 function  (0.03019)
    12 (0.02474): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.02148): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    16 (0.01823): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.01497): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    21 (0.01172): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

3: COMPUTATIONAL STRUCTURE OF COORDINATE TRANSFORMATIONS: A GENERALIZATION STUDY
    id = 983
    authors = Ghahramani_Z Jordan_M Wolpert_D 
    20 (0.32089): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    13 (0.11586): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    10 (0.09634): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    5 (0.09308): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    26 (0.01823): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    17 (0.00847): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)

4: Feudal Reinforcement Learning
    id = 606
    authors = Dayan_P Hinton_G 
    4 (0.27208): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.13539): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.10284): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    5 (0.06054): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.05403): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.03776): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.02148): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    21 (0.00847): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

5: Odor Processing in the Bee: A Preliminary Study of the Role of Central Input to the Antennal Lobe
    id = 766
    authors = Kerszberg_M Linster_C Marson_D Masson_C 
    7 (0.27859): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.14841): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.11586): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.06705): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.04752): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    11 (0.01497): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    25 (0.01172): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

6: Globally Trained Handwritten Word Recognizer Using Spatial Representation, Convolutional Neural Networks, and Hidden Markov Models
    id = 817
    authors = Bengio_Y Henderson_D LeCun_Y 
    1 (0.31113): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.11912): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.11586): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.04752): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.02799): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.02799): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    14 (0.01823): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)

7: Comparison Training for a Rescheduling Problem in Neural Networks
    id = 800
    authors = Keymeulen_D de-Gerlache_M 
    18 (0.22001): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    8 (0.15166): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.10284): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    9 (0.07681): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    12 (0.07030): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.03125): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    14 (0.02474): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

8: The Statistical Mechanics of k-Satisfaction
    id = 755
    authors = Gyorgyi_G Kirkpatrick_S Tishby_N Troyansky_L 
    1 (0.22977): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.22001): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    17 (0.07355): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    11 (0.06705): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    21 (0.03125): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    4 (0.02799): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.02474): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    19 (0.01823): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    30 (0.00521): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)

9: Synergy of Clustering Multiple Back Propagation Networks
    id = 264
    authors = Lincoln_W Skrzypek_J 
    3 (0.17119): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.13539): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.12237): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.12237): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.06705): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    15 (0.05728): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

10: Phase-coupling in Two-Dimensional Networks of Interacting Oscillators . . .
    id = 302
    authors = Kammen_D Koch_C Niebur_E Ruderman_D Schuster_H 
    4 (0.26231): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    10 (0.21024): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.06379): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.05728): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    11 (0.05728): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.02148): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.01497): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

11: Analog Computation at a Critical Point .
    id = 304
    authors = Bialek_W Kruglyak_L 
    11 (0.41202): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    4 (0.13864): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.05728): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.03450): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    20 (0.03450): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

12: Analysis of Linsker's Simulations of Hebbian Rules
    id = 269
    authors = MacKay_D Miller_K 
    24 (0.27208): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    6 (0.18095): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    11 (0.06705): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.05403): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.05077): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.03776): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    16 (0.02474): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

13: Dynamics of Generalization in Linear Perceptrons .
    id = 407
    authors = Hertz_J Krogh_A 
    3 (0.23302): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.16793): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    10 (0.08983): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.07030): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.06379): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.03776): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.02148): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

14: Kohonen Networks and Clustering .
    id = 419
    authors = Bilbro_G Nissman_D Snyder_W VandenBout_D 
    14 (0.22326): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    7 (0.18746): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    50 (0.10284): 23 hidden  (0.22812) 20 information  (0.09208) 8 time  (0.07265) 4 input  (0.07265) 12 algorithm  (0.07265) 22 models  (0.05322) 3 neural  (0.05322) 18 results  (0.05322) 11 training  (0.03378) 21 problem  (0.03378)
    17 (0.09634): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    25 (0.03450): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    0 (0.02474): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

15: Neural Network Gaussian Mixture Hybrid for Speech Recognition or Density Estimation
    id = 450
    authors = Bengio_Y De-Mori_R Flammia_G Kompe_R 
    4 (0.36646): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    16 (0.14515): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    8 (0.08657): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    10 (0.04426): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

16: A Neural Network that Learns to Interpret Myocardial Planar Thallium Scintigrams
    id = 665
    authors = Atlan_H Erel_J Rosenberg_C 
    7 (0.19722): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.15166): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    13 (0.10610): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.06379): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    10 (0.06054): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    9 (0.06054): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    26 (0.02474): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    11 (0.01497): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    20 (0.00847): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

17: Locally Adaptive Nearest Neighbor Algorithms
    id = 723
    authors = Dietterich_T Wettschereck_D 
    10 (0.15817): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    3 (0.15492): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.14841): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.09308): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.05728): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    19 (0.05403): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    4 (0.02148): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

18: Dynamic, Non-Local Role Bindings and Inferencing in a Localist Network for Natural Language Understanding
    id = 152
    authors = Dyer_M Lange_T 
    23 (0.47060): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    7 (0.11912): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    14 (0.04752): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    9 (0.02148): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    17 (0.01497): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

19: Teaching Artificial Neural Systems to Drive: Manual Training Techniques for Autonomous Systems
    id = 71
    authors = Macy_S Shepanski_J 
    3 (0.26557): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.13539): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.08006): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    6 (0.07681): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.07355): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.03776): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    22 (0.01172): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    27 (0.00847): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

20: Statistics of Natural Images: Scaling in the Woods
    id = 769
    authors = Bialek_W Ruderman_D 
    15 (0.34042): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    11 (0.18746): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.08983): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    3 (0.02148): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.02148): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

21: A Topograhic Product for the Optimization of Self-Organizing Feature Maps . .
    id = 569
    authors = Bauer_H Geisel_T Pawelzik_K 
    11 (0.41202): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    12 (0.18095): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    7 (0.05403): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    16 (0.01497): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

22: A CHARGE-BASED CMOS PARALLEL ANALOG VECTOR QUANTIZER
    id = 940
    authors = Cauwenberghs_G Pedroni_V 
    10 (0.17119): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    25 (0.15166): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    11 (0.09959): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.08657): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    14 (0.08006): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    17 (0.06379): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    19 (0.00847): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

23: Extensions of a Theory of Networks for Approximation and Learning .
    id = 387
    authors = Caprile_B Girosi_F Poggio_T 
    0 (0.23628): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    19 (0.22001): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    18 (0.12237): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    6 (0.04426): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.04101): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    28 (0.01497): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

24: Implementing Intelligence on Silicon Using Neuron-Like Functional MOS  Transistors
    id = 815
    authors = Ishii_H Kosaka_H Kotani_K Ohmi_T Shibata_T Yamashita_T 
    7 (0.40226): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    6 (0.12888): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    9 (0.07355): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.02799): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.02474): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    18 (0.02148): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

25: Recognition-Based Segmentation of On-Line Cursive Handwriting
    id = 797
    authors = Flann_N 
    10 (0.18746): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.16793): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.13213): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.11586): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.06054): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

26: Locomotion in a Lower Vertebrate: Studies of the Cellular Basis of Rhythmogenesis and Oscillator Coupling
    id = 441
    authors = Buchanan_J 
    9 (0.34368): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    13 (0.12888): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    12 (0.07681): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.07355): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    25 (0.02148): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    26 (0.01823): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

27: OCULAR DOMINANCE AND PATTERNED LATERAL CONNFL-TIONS IN A SELF-ORGANIZING MODEL OFTHE PRIMARY VISUAL CORTEX
    id = 857
    authors = Miikkulainen_R Sirosh_J 
    25 (0.27859): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    6 (0.20699): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    15 (0.13213): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    2 (0.03450): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.02148): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

28: NEW ALGORITHMS FOR 2D AND 3D POINT MATCHING: POSE ESTIMATION AND CORRESPONDENCE
    id = 962
    authors = Gold_S Lu_C Mjolsness_E Pappu_S Rangarajan_A 
    13 (0.30137): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    10 (0.23953): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    3 (0.05728): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.02799): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    14 (0.02148): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    20 (0.02148): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.01823): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

29: A Neural Network for Feature Extraction
    id = 272
    authors = Intrator_N 
    4 (0.20699): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.12237): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    8 (0.10610): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.08983): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.08657): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.04426): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    21 (0.02799): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

30: A Short-Term Memory Architecture for the Learning of Morphophonemic Rules .
    id = 368
    authors = Gasser_M Lee_C 
    15 (0.35018): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    10 (0.15166): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    14 (0.06705): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.04426): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.04426): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.02148): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

31: The Capacity of the Kanerva Associative Memory is Exponential
    id = 18
    authors = Chou_P 
    6 (0.16793): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.13213): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.12888): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.10610): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    20 (0.05728): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    17 (0.03776): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    14 (0.02474): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.01497): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)

32: Constrained Differential Optimization
    id = 63
    authors = Barr_A Platt_J 
    14 (0.18421): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.16468): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.12237): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.08332): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.07030): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    18 (0.05728): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    31 (0.00521): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    30 (0.00521): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)

33: LEARNING LOCAL ERROR BARS FOR NONLINEAR REGRESSION
    id = 904
    authors = Nix_D Weigend_A 
    13 (0.28184): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.16143): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.08983): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.08657): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.02799): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    50 (0.01172): 23 hidden  (0.22812) 20 information  (0.09208) 8 time  (0.07265) 4 input  (0.07265) 12 algorithm  (0.07265) 22 models  (0.05322) 3 neural  (0.05322) 18 results  (0.05322) 11 training  (0.03378) 21 problem  (0.03378)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

34: Connectionist Music Composition Based on Melodic and Stylistic Constraints . .
    id = 392
    authors = Mozer_M Soukup_T 
    3 (0.31439): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.12888): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    12 (0.10935): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.07355): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.01823): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.01497): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

35: Memory-based Reinforcement Learning: Efficient Computation with Prioritized Sweeping
    id = 605
    authors = Atkeson_C Moore_A 
    8 (0.19722): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.16143): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.10610): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.08983): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.08332): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.02474): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    15 (0.01823): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

36: Associative Memory in a Simple Model of Oscillating Cortex ........
    id = 193
    authors = Baird_B 
    12 (0.22326): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    4 (0.20373): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    14 (0.13539): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.08657): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    22 (0.02148): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

37: HMM Speech Recognition with Neural Net Discrimination
    id = 208
    authors = Huang_W Lippmann_R 
    19 (0.31113): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    17 (0.15166): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    8 (0.08983): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.06054): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.02474): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    9 (0.02474): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    25 (0.02148): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00847): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

38: Forecasting Demand for Electric Power
    id = 663
    authors = Fine_T Yuan_J 
    6 (0.28835): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.16143): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    10 (0.07681): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.07030): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    35 (0.05077): 2 model  (0.12882) 11 training  (0.10820) 23 hidden  (0.08070) 24 performance  (0.07382) 0 network  (0.06695) 15 system  (0.05320) 22 models  (0.04632) 5 data  (0.03945) 6 function  (0.03945) 17 state  (0.03945)
    7 (0.03125): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

39: Global Regularization of Inverse Kinematics for Redundant Manipulators
    id = 604
    authors = DeMers_D Kreutz-Delgado_K 
    26 (0.23302): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    2 (0.20699): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    5 (0.10610): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.06705): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.03776): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.02474): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

40: A Formal Model of the Insect Olfactory Macroglomerulus: Simulations and Analytic Results
    id = 698
    authors = Dreyfus_G Kerszberg_M Linster_C Marsan_D Masson_C Personnaz_L 
    10 (0.29811): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    14 (0.14515): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    5 (0.10284): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.06054): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    12 (0.05077): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.01823): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

41: Fast Pruning Using Principal Components
    id = 704
    authors = Leen_T Levin_A Moody_J 
    4 (0.19397): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    20 (0.12888): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    2 (0.12563): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.11586): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    6 (0.06379): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    7 (0.03776): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.02148): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

42: Constructive Learning Using Internal Representation Conflicts
    id = 735
    authors = Jabri_M Leerink_L 
    6 (0.41527): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.12237): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.06705): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    3 (0.03125): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.01497): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    10 (0.01497): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

43: The VC-Dimension versus the Statistical Capacity of Multilayer Networks
    id = 542
    authors = Ji_C Psaltis_D 
    2 (0.28510): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.08657): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    10 (0.07030): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    14 (0.07030): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.05403): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.04426): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    16 (0.02799): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    25 (0.02148): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)

44: Node Splitting: A Contructive Algorithm for Feed-Forward Neural Networks
    id = 560
    authors = Wynne-Jones_M 
    6 (0.33066): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    9 (0.20699): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.06054): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.04101): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    20 (0.03450): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

45: Reorganization of Somatosensory Cortex after Tactile Training
    id = 995
    authors = Peterson_R Taylor_J 
    12 (0.29811): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    9 (0.11261): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.06054): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    25 (0.05728): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    5 (0.05077): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    18 (0.04426): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    10 (0.04426): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    23 (0.01497): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)

46: FROM DATA DISTRIBUTIONS TO REGULARIZATION IN INVARIANT LEARNING
    id = 871
    authors = Leen_T 
    10 (0.41527): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.14515): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.05077): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    20 (0.02799): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    46 (0.02474): 22 models  (0.12591) 14 number  (0.09337) 9 set  (0.09337) 23 hidden  (0.07710) 16 error  (0.07710) 17 state  (0.04456) 13 output  (0.04456) 11 training  (0.04456) 6 function  (0.04456) 1 learning  (0.04456)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    21 (0.00847): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

47: Two-Dimensional Object Localization by Coarse-to-Fine Correlation Matching
    id = 823
    authors = Lu_C Mjolsness_E 
    0 (0.21024): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.17119): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.13864): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.09308): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    15 (0.04426): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    16 (0.02474): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

48: Asynchronous Dynamics of Continuous Time Neural Networks
    id = 762
    authors = Blum_E Li_Q Wang_X 
    7 (0.22001): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    16 (0.17770): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    1 (0.09634): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.07681): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.06705): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.02148): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.01823): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

49: Optimal Filtering in the Salamander Retina .
    id = 336
    authors = Bialek_W Owen_W Rieke_F 
    5 (0.26557): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    8 (0.15166): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.14515): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.08332): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    36 (0.00847): 15 system  (0.22042) 19 units  (0.12720) 18 results  (0.06266) 14 number  (0.06266) 7 figure  (0.05549) 3 neural  (0.05549) 10 networks  (0.05549) 4 input  (0.04832) 23 hidden  (0.04832) 5 data  (0.03398)
    18 (0.00847): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

50: An Application of the Principle of Maximum Information Preservation to Linear Systems
    id = 111
    authors = Linsker_R 
    7 (0.28184): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.14841): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.11586): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    10 (0.08657): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    12 (0.02148): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    44 (0.01497): 16 error  (0.13557) 3 neural  (0.12005) 11 training  (0.08903) 0 network  (0.07351) 4 input  (0.05800) 24 performance  (0.05800) 9 set  (0.04248) 5 data  (0.04248) 10 networks  (0.04248) 23 hidden  (0.02697)
    19 (0.01497): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

51: Does the Neuron 'Learn' Like the Synapse?
    id = 109
    authors = Tawel_R 
    10 (0.26557): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    13 (0.13864): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.13213): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    22 (0.04752): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    8 (0.04752): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    11 (0.03776): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

52: Range Image Restoration Using Mean Field Annealing
    id = 158
    authors = Bilbro_G Snyder_W 
    2 (0.20373): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.20373): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    11 (0.11586): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    10 (0.06054): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    4 (0.05728): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    14 (0.03125): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

53: Relaxation Networks for Large Supervised Learning Problems .
    id = 423
    authors = Allen_R Alspector_J Jayakumar_A Meir_R Zeppenfeld_T 
    6 (0.24604): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    7 (0.19397): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.14515): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.05077): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    15 (0.01823): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

54: USING A NEURAL NETTO INSTANTlATE A DEFORMABLE MODEL
    id = 963
    authors = Hinton_G Revow_M Williams_C 
    1 (0.22977): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    11 (0.19397): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    31 (0.09959): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    4 (0.07355): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    6 (0.06379): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

55: ADAPTIVE ELASTIC INPUT FIELD FOR RECOGNITION IMPROVEMENT
    id = 980
    authors = Asogawa_M 
    13 (0.25906): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    1 (0.23628): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.10610): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.06379): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

56: Classifying Hand Gestures with a View-Based Distributed Representation
    id = 818
    authors = Darrell_T Pentland_A 
    12 (0.29486): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.15492): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.13864): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.08332): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

57: A Novel Approach to Prediction of the 3-Dimensional Structures .
    id = 356
    authors = Bohr_H Bohr_J Brunak_S Cotterill_R Fredholm_H Lautmp_B Petersen_S 
    8 (0.32740): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.18746): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.07030): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.05728): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    12 (0.02799): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

58: On The Circuit Complexity of Neural Networks .
    id = 415
    authors = Kailath_T Orlitsky_A Roychowdhury_V Siu_K 
    7 (0.30462): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.10284): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    22 (0.08657): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    9 (0.08332): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.06379): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    11 (0.01497): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    16 (0.01497): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    25 (0.01172): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

59: A Cost Function for Internal Representations
    id = 274
    authors = Hertz_J Krogh_A Thorbergsson_C 
    15 (0.36971): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    2 (0.19722): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.09308): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

60: Recognizing Overlapping Hand-Printed Characters by Centered-Object Integrated Segmentation and Recognition
    id = 490
    authors = Martin_G Rashid_M 
    4 (0.29811): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    1 (0.14841): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.08983): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.07355): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    17 (0.03450): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    40 (0.02148): 5 data  (0.16090) 16 error  (0.08362) 12 algorithm  (0.08362) 18 results  (0.07503) 22 models  (0.06645) 15 system  (0.04927) 13 output  (0.04927) 21 problem  (0.04927) 0 network  (0.04927) 2 model  (0.04927)
    15 (0.01497): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

61: Training a 3-Node Neural Network is NP-Complete
    id = 146
    authors = Blum_A Rivest_R 
    15 (0.34368): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    0 (0.11912): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.06054): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    27 (0.05728): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    32 (0.05077): 20 information  (0.10804) 9 set  (0.10804) 1 learning  (0.10804) 15 system  (0.09379) 19 units  (0.07953) 14 number  (0.07003) 10 networks  (0.06528) 22 models  (0.04627) 4 input  (0.04627) 17 state  (0.04152)
    1 (0.03125): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    21 (0.02474): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

62: BOLTZMANN CHAINS AND HIDDEN MARKOV MODELS
    id = 897
    authors = Jordan_M Saul_L 
    7 (0.37297): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.18421): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.04752): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.03776): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    16 (0.01497): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    17 (0.01172): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    22 (0.00847): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00847): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

63: Distributed Recursive Structure Processing ..
    id = 366
    authors = Legendre_G Miyata_Y Smolensky_P 
    4 (0.25255): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    15 (0.22977): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    14 (0.16143): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

64: A comparison between a neural netwok model for the formation of brain maps and experimental data
    id = 439
    authors = Blasdel_G Obermayer_K Schulten_K 
    13 (0.23628): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.12237): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.12237): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.07030): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.06379): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    24 (0.03450): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.01823): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    48 (0.00847): 21 problem  (0.14210) 16 error  (0.08701) 2 model  (0.08701) 10 networks  (0.08701) 17 state  (0.06865) 11 training  (0.06865) 8 time  (0.06865) 9 set  (0.05028) 14 number  (0.05028) 3 neural  (0.05028)

65: A Recurrent Neural Network for Word Identification from Continuous Phoneme Strings .
    id = 313
    authors = Allen_R Kamm_C 
    3 (0.18095): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.14841): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.12563): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.07681): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.06705): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.04426): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.03450): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

66: A SOLVABLE CONNECTIONIST MODEL OF IMMEDIATE RECALL OF ORDERED LISTS
    id = 850
    authors = Burgess_N 
    2 (0.19397): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    16 (0.15817): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    8 (0.10935): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.09959): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    7 (0.09308): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.01823): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

67: THE NI1000: HIGH SPEED PARALLEL VLSI FOR IMPLEMENTING MULTILAYER PERCEPTRONS
    id = 936
    authors = Cooper_L Perrone_M 
    0 (0.22651): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.17119): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.11912): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.08983): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    11 (0.06705): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

68: Kernel Regression and Backpropagation Training with Noise
    id = 555
    authors = Holmstrom_L Koistinen_P 
    0 (0.16793): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.15166): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    5 (0.09308): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    3 (0.08006): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.05728): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    16 (0.04426): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    8 (0.03776): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.03125): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    14 (0.02799): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)

69: Neural Analog Diffusion-Enhancement Layer and Spatio-Temporal Grouping in Early Vision
    id = 123
    authors = Cunningham_R Seibert_M Waxman_A Wu_J 
    2 (0.27208): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    16 (0.23953): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    1 (0.10935): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.04101): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    21 (0.00847): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

70: Temporal Adaptation in a Silicon Auditory Nerve
    id = 528
    authors = Lazzaro_J 
    16 (0.26557): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    10 (0.22651): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    5 (0.08332): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    3 (0.08006): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

71: Estimating Average-Case Learning Curves Using Bayesian, Statistical Physics and VC Dimension Methods
    id = 533
    authors = Haussler_D Kearns_M Opper_M Schapire_R 
    2 (0.17770): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.16468): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.14841): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.10284): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    15 (0.06379): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    22 (0.02148): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

72: Learning to Make Coherent Predictions in Domains with Discontinuities
    id = 474
    authors = Becker_S Hinton_G 
    5 (0.26231): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    28 (0.12888): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    14 (0.11912): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    4 (0.11912): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    13 (0.03125): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

73: A MIXTURE MODEL SYSTEM FOR MEDICAL AND MACHINE DIAGNOSIS
    id = 977
    authors = Sejnowski_T Stensmo_M 
    10 (0.33066): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    6 (0.16793): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.08657): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.05728): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    14 (0.01823): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    2 (0.01823): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

74: Hierarchies of adaptive experts
    id = 549
    authors = Jacobs_R Jordan_M 
    11 (0.30788): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    9 (0.12888): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.10284): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.05077): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.03450): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    5 (0.03125): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    8 (0.02148): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    14 (0.01497): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

75: GENESIS: A System for Simulating Neural Networks
    id = 145
    authors = Bhalla_U Bower_J Uhley_J Wilson_M 
    3 (0.34368): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    10 (0.18095): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    13 (0.10284): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    17 (0.01497): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    7 (0.01497): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    26 (0.01172): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    25 (0.00847): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

76: Learning Global Direct Inverse Kinematics
    id = 500
    authors = DeMers_D Kreutz-Delgado_K 
    1 (0.16793): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.14841): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.12888): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.08332): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.05403): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    11 (0.04752): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.02799): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)

77: Operational Fault Tolerance of CMAC Networks
    id = 226
    authors = Carter_M Nucci_A Rudolph_F 
    19 (0.32415): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    10 (0.15817): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    13 (0.08983): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.07681): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    27 (0.00847): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

78: Neural Computing with Small Weights
    id = 544
    authors = Bruck_J Siu_K 
    8 (0.21675): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.14841): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.08657): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.08332): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.07355): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    13 (0.06379): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

79: PREDICTIVE CODING WITH NEURAL NETS: APPLICATION TO TEXT COMPRESSION
    id = 973
    authors = Heil_S Schmidhuber_J 
    9 (0.36320): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.16143): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.11261): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    22 (0.01497): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

80: Developing Population Codes by Minimizing Description Length
    id = 701
    authors = Hinton_G Zemel_R 
    2 (0.22977): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    14 (0.18095): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    21 (0.07355): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    0 (0.07030): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.03776): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    22 (0.02474): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    12 (0.02474): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    25 (0.02148): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    10 (0.01497): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    16 (0.01497): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)

81: The Effective Number of Parameters: An Analysis of Generalization and Regularization in Nonlinear Learning Systems
    id = 532
    authors = Moody_J 
    14 (0.41853): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.22001): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    15 (0.01497): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

82: Adaptive Synchronization of Neural and Physical Oscillators
    id = 442
    authors = Doya_K Yoshizawa_S 
    2 (0.37622): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.19072): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.05077): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    37 (0.03450): 8 time  (0.12266) 18 results  (0.11534) 14 number  (0.11534) 6 function  (0.09335) 7 figure  (0.06404) 17 state  (0.04938) 16 error  (0.04205) 23 hidden  (0.04205) 10 networks  (0.04205) 9 set  (0.03472)
    13 (0.02148): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

83: FACTORIAL LEARNING BY CLUSTERING FEATURES
    id = 913
    authors = Tenenbaum_J Todorov_E 
    0 (0.20699): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    10 (0.15166): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    3 (0.13864): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    5 (0.06054): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    16 (0.04426): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    1 (0.04101): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.02799): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    13 (0.02148): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

84: Learning Mackey-Glass from 25 Examples, Plus or Minus 2
    id = 841
    authors = Cottrell_G Plutowski_M White_H 
    2 (0.23628): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    21 (0.23302): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    19 (0.13539): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    15 (0.04426): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    11 (0.01823): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    25 (0.00847): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

85: Reconfigurable Neural Net Chip with 32K Connections ..
    id = 426
    authors = Graf_H Henderson_D Janow_R Lee_R 
    11 (0.19072): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    9 (0.18421): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.16793): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.10610): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    16 (0.01497): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    40 (0.00847): 5 data  (0.16090) 16 error  (0.08362) 12 algorithm  (0.08362) 18 results  (0.07503) 22 models  (0.06645) 15 system  (0.04927) 13 output  (0.04927) 21 problem  (0.04927) 0 network  (0.04927) 2 model  (0.04927)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

86: How Receptive Field Parameters Affect Neural Learning ..
    id = 388
    authors = Mel_B Omohundro_S 
    3 (0.21675): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.17119): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.12237): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.06054): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    10 (0.06054): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.02474): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.01823): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)

87: Dynamics of Attention as Near Saddle-node Bifurcation Behavior
    id = 989
    authors = Doya_K Nakahara_H 
    4 (0.28510): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.19397): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.13864): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    5 (0.02148): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    24 (0.01497): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

88: Learning Sequential Structure in Simple Recurrent Networks
    id = 164
    authors = Cleeremans_A McClelland_J Servan-Schreiber_D 
    24 (0.21024): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    11 (0.16793): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.14515): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    15 (0.11912): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    8 (0.02799): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

89: USING A SALIENCY MAP FOR ACTIVE SPATIAL SUBJECTIVE ATTENTION: IMPLEMENTATION &INITIAL RESULTS
    id = 899
    authors = Baluja_S Pomerleau_D 
    22 (0.19072): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    6 (0.18095): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.09959): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    38 (0.09308): 15 system  (0.16412) 4 input  (0.11882) 18 results  (0.08862) 17 state  (0.06597) 24 performance  (0.06597) 23 hidden  (0.05842) 21 problem  (0.04332) 2 model  (0.04332) 7 figure  (0.03577) 8 time  (0.03577)
    7 (0.06054): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.03776): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

90: Statistical and Dynamical Interpretation of ISIH Data from Periodically Stimulated Sensory Neurons
    id = 694
    authors = Douglass_J Longtin_A Moss_F 
    16 (0.33066): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    13 (0.12563): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    6 (0.10935): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.08657): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.02474): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

91: Information Measure Based Skeletonisation
    id = 561
    authors = Pratt_L Ramachandran_S 
    0 (0.22651): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.15817): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.11261): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.09308): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.03776): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    22 (0.02799): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    2 (0.01823): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

92: Convergence of Stochastic Iterative Dynamic Programming Algorithms
    id = 788
    authors = Jaakkola_T Jordan_M Singh_S 
    0 (0.27859): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.19072): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.08332): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.05077): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.03450): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    10 (0.01497): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    41 (0.01497): 21 problem  (0.16446) 7 figure  (0.13864) 2 model  (0.09990) 16 error  (0.08699) 17 state  (0.07408) 24 performance  (0.07408) 14 number  (0.06117) 10 networks  (0.03535) 3 neural  (0.03535) 12 algorithm  (0.02244)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)

93: A Computational Basis for Phonology
    id = 230
    authors = Touretzky_D Wheeler_D 
    8 (0.23302): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    26 (0.18421): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    11 (0.10610): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    4 (0.08006): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.02474): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    18 (0.02148): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    10 (0.01497): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)

94: Remote Sensing Image Analysis via a Texture Classification Neural Network
    id = 625
    authors = Goodman_R Greenspan_H 
    0 (0.17119): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    16 (0.15817): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    4 (0.15166): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    9 (0.08983): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    14 (0.07681): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    5 (0.01823): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    21 (0.01823): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

95: Decoding of Neuronal Signals in Visual Pattern Recognition
    id = 472
    authors = Eskandar_E Hertz_J Kjaer_T Optican_L Richmond_B 
    0 (0.34042): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    18 (0.21024): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    25 (0.08006): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    8 (0.02799): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

96: Performance of Connectionist Learning Algorithms on 2-D SIMD Processor Arrays
    id = 283
    authors = Fortes_J Nunez_F 
    3 (0.22001): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.17770): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    14 (0.12563): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    45 (0.09308): 8 time  (0.15592) 21 problem  (0.10789) 2 model  (0.09188) 9 set  (0.09188) 22 models  (0.07587) 17 state  (0.04384) 10 networks  (0.04384) 0 network  (0.04384) 18 results  (0.04384) 5 data  (0.04384)
    9 (0.04752): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

97: Neural Networks for Template Matching: Application to Real-Time Classification of the Action Potentials of Real Neurons
    id = 10
    authors = Banik_J Bower_J Wong_Y 
    8 (0.35344): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.12888): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    14 (0.11586): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    36 (0.04752): 15 system  (0.22042) 19 units  (0.12720) 18 results  (0.06266) 14 number  (0.06266) 7 figure  (0.05549) 3 neural  (0.05549) 10 networks  (0.05549) 4 input  (0.04832) 23 hidden  (0.04832) 5 data  (0.03398)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    19 (0.00847): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

98: VISI15 A Neural Model of Covert Visual Attention
    id = 480
    authors = Ahmad_S 
    0 (0.31439): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.19397): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    8 (0.09634): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.02799): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    14 (0.02799): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    23 (0.02148): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

99: Time-Sequential Self-Organization of Hierarchical Neural Networks
    id = 73
    authors = Noetzel_A Silverman_R 
    8 (0.21675): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    14 (0.14190): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    2 (0.13864): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.08332): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.07355): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.02474): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

100: Neural Dynamics of Motion Segmentation and Grouping .
    id = 331
    authors = Mingolla_E 
    2 (0.15166): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    19 (0.10610): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    7 (0.09634): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    16 (0.09308): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    24 (0.08657): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    12 (0.05728): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.05403): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.02799): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    4 (0.02474): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

101: Bit-Serial Neural Networks
    id = 59
    authors = Butler_Z Murray_A Smith_A 
    2 (0.15492): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    5 (0.13864): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    9 (0.10284): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.09959): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    12 (0.07030): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    11 (0.06379): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.05728): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

102: Object-Based Analog VLSI Vision Circuits
    id = 674
    authors = Harris_J Koch_C Liu_S Luo_J Mathur_B Sivilotti_M 
    0 (0.23302): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    22 (0.16468): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    5 (0.11586): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.07681): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.04426): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    15 (0.02148): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    11 (0.01823): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    14 (0.01497): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

103: MURPHY: A Robot that Learns by Doing
    id = 56
    authors = Mel_B 
    7 (0.22326): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    26 (0.19397): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    13 (0.08983): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.08657): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.03450): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    9 (0.03450): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.02474): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

104: Diffusion Approximations for the Constant Step Size Backpropogation Algorithm and Resistance to Local Minima
    id = 629
    authors = Finnoff_W 
    23 (0.27208): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    14 (0.22326): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    9 (0.09308): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    4 (0.05403): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    12 (0.01497): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

105: An Analog VLSI Splining Network .
    id = 422
    authors = Samalam_V Schwartz_D 
    4 (0.26231): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    13 (0.16143): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    6 (0.12888): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    33 (0.06054): 0 network  (0.09122) 11 training  (0.08608) 14 number  (0.07065) 16 error  (0.07065) 3 neural  (0.06036) 12 algorithm  (0.06036) 17 state  (0.05522) 24 performance  (0.05522) 2 model  (0.05008) 18 results  (0.05008)
    14 (0.05403): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

106: Speech Recognition Using Demi-Syllable Neural Prediction Model .
    id = 316
    authors = Iso_K Watanabe_T 
    13 (0.22977): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.18095): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.12563): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.08006): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    16 (0.02799): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    14 (0.02148): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    22 (0.01823): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

107: Learning Classification with Unlabeled Data
    id = 714
    authors = de-Sa_V 
    8 (0.36320): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.14515): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    16 (0.08983): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    10 (0.05403): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    3 (0.01823): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

108: Time Warping Invariant Neural Networks
    id = 595
    authors = Chen_H Lee_Y Sun_G 
    5 (0.24279): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    4 (0.16793): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.14515): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.10284): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    21 (0.00847): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

109: Robust Reinforcement Learning in Motion Planning
    id = 782
    authors = Barto_A Connolly_C Ginpen_R Singh_S 
    1 (0.21675): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.20373): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    21 (0.18095): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.02799): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    30 (0.02148): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

110: A Multiscale Adaptive Network Model of Motion Computation in Primates . . .
    id = 332
    authors = Koch_C Mathur_B Wang_H 
    5 (0.24930): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.14841): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    14 (0.11586): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    2 (0.09959): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.05728): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

111: ANN Based Classification for Heart Defibrillators
    id = 506
    authors = Chi_Z Flower_B Jabri_M Leong_P Pickard_S Xie_Y 
    13 (0.17119): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.16143): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    0 (0.13864): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    36 (0.10935): 15 system  (0.22042) 19 units  (0.12720) 18 results  (0.06266) 14 number  (0.06266) 7 figure  (0.05549) 3 neural  (0.05549) 10 networks  (0.05549) 4 input  (0.04832) 23 hidden  (0.04832) 5 data  (0.03398)
    8 (0.05403): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    14 (0.03125): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)

112: Amplifying and Linearizing Apical Synaptic Inputs to Cortical Pyramidal Cells
    id = 765
    authors = Bernander_O Douglas_R Koch_C 
    15 (0.31764): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    13 (0.10935): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.08983): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    16 (0.05728): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    11 (0.05077): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.03125): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.02148): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    64 (0.01497): 18 results  (0.08101) 20 information  (0.08101) 17 state  (0.08101) 6 function  (0.03441) 5 data  (0.03441) 9 set  (0.03441) 7 figure  (0.03441) 8 time  (0.03441) 10 networks  (0.03441) 0 network  (0.03441)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

113: Efficient Simulation of Biological Neural Networks on Massively Parallel Supercomputers with Hypercube Architecture
    id = 813
    authors = Brettle_D Niebur_E 
    3 (0.22001): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.20373): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.14841): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    10 (0.08332): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

114: Basis-Function Trees as a Generalization of Local Variable Selection Methods . .
    id = 380
    authors = Sanger_T 
    14 (0.29160): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    7 (0.22326): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.05077): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    19 (0.04752): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    15 (0.02148): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    22 (0.01823): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    10 (0.01823): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

115: Constrained Optimization Applied to the Parameter Setting Problem  for Analog Circuits
    id = 525
    authors = Barr_A Fleischer_K Kirk_D Watts_L 
    7 (0.34693): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    19 (0.23953): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    1 (0.06705): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

116: PATIERN PLAYBACK IN THE '90S
    id = 946
    authors = Slaney_M 
    8 (0.25255): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.14515): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    16 (0.08006): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    3 (0.07030): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.03450): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.03450): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    19 (0.03125): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    2 (0.02474): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    11 (0.02474): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

117: Stationarity of Synaptic Coupling Strength Between Neurons with Nonstationary Discharge Properties
    id = 430
    authors = Sydorenko_M Young_E 
    14 (0.16793): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    11 (0.13539): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.12563): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    51 (0.11261): 23 hidden  (0.20869) 5 data  (0.18925) 21 problem  (0.11152) 18 results  (0.05322) 24 performance  (0.05322) 14 number  (0.03378) 1 learning  (0.03378) 13 output  (0.03378) 0 network  (0.03378) 17 state  (0.03378)
    8 (0.09959): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    27 (0.01172): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)

118: Analysis and Comparison of Different Learning Algorithms for Pattern Association Problems
    id = 7
    authors = Bernasconi_J 
    0 (0.34042): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.13213): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    1 (0.08983): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.07355): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.03450): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

119: PAIRWISE NEURAL NETWORK CLASSIFIERS WITH PROBABILISTIC OUTPUTS
    id = 981
    authors = Dreyfus_G Knerr_S Personnaz_L Price_D 
    5 (0.26557): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.16468): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.12888): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.09959): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    28 (0.00847): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

120: Identifying Fault-Prone Software Modules Using Feed-Forward Networks: A Case Study
    id = 799
    authors = Kamnanithi_N 
    5 (0.32740): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.13539): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.12888): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.03776): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    7 (0.02474): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    10 (0.02474): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

121: Clustering with a Domain-Specific Distance Measure
    id = 712
    authors = Gold_S Mjolsness_E Rangarajan_A 
    2 (0.31764): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    21 (0.25906): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    10 (0.05403): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    59 (0.03450): 7 figure  (0.09973) 12 algorithm  (0.09973) 15 system  (0.09973) 5 data  (0.06331) 18 results  (0.06331) 1 learning  (0.06331) 8 time  (0.02689) 9 set  (0.02689) 10 networks  (0.02689) 0 network  (0.02689)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

122: Learning Sequential Tasks by Incrementally Adding Higher Orders
    id = 587
    authors = Ring_M 
    18 (0.19397): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    3 (0.17444): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    10 (0.13539): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.07681): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.06705): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    13 (0.03125): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

123: Spontaneous and Information-Triggered Segments of Series of Human Brain Electric Field Maps
    id = 48
    authors = Brandeis_D Horst_A Lehmann_D Ozaki_H Pal_I 
    14 (0.29160): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    10 (0.20699): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    12 (0.09308): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.04752): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    30 (0.03125): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    28 (0.00847): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

124: CAPAClTY AND INFORMATION EFFICIENCY OF A BRAIN-LIKE ASSOCIATIVE NET
    id = 907
    authors = Graham_B Willshaw_D 
    9 (0.30788): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.16143): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.12237): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.07355): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

125: Counting Function Theorem for Multi-Layer Networks
    id = 747
    authors = Kowalczyk_A 
    9 (0.24930): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.22651): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.08657): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.08332): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.02474): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

126: Discrete Affine Wavelet Transforms .
    id = 386
    authors = Krishnaprasad_P Pati_Y 
    7 (0.22651): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    22 (0.15817): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    1 (0.15492): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.08657): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    26 (0.01823): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

127: Optical Implementation of a Self-Organizing Feature Extractor
    id = 529
    authors = Anderson_D Benkert_C Hebler_V Jang_J Montgomery_D Saffman_M 
    12 (0.24279): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    14 (0.22651): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    2 (0.13539): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.04426): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.02148): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

128: Back Propagation Implementation .
    id = 425
    authors = McCartor_H 
    0 (0.19072): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.11912): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.10284): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.09634): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.07030): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.05728): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    13 (0.02474): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    41 (0.02148): 21 problem  (0.16446) 7 figure  (0.13864) 2 model  (0.09990) 16 error  (0.08699) 17 state  (0.07408) 24 performance  (0.07408) 14 number  (0.06117) 10 networks  (0.03535) 3 neural  (0.03535) 12 algorithm  (0.02244)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)

129: Modeling Time Varying Systems Using Hidden Control Neural Architecture
    id = 305
    authors = Levin_E 
    6 (0.27208): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.20373): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.13213): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.05403): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    40 (0.00847): 5 data  (0.16090) 16 error  (0.08362) 12 algorithm  (0.08362) 18 results  (0.07503) 22 models  (0.06645) 15 system  (0.04927) 13 output  (0.04927) 21 problem  (0.04927) 0 network  (0.04927) 2 model  (0.04927)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

130: Credit Assignment through Time: Alternatives to Backpropagation
    id = 709
    authors = Bengio_Y Frasconi_P 
    8 (0.27208): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.15492): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.14190): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.04426): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.03776): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.03125): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

131: Planar Hidden Markov Modeling: from Speech to Optical Character Recognition
    id = 662
    authors = Levin_E Pieraccini_R 
    12 (0.23628): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.16143): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.13539): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    14 (0.08332): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.04426): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    17 (0.01172): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

132: Explanation-based Neural Network Learning for Robot Control
    id = 608
    authors = Mitchell_T Thrun_S 
    8 (0.15817): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.12563): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    10 (0.10610): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    14 (0.10610): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.06379): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    9 (0.04752): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.03776): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)

133: A LAGRANGIAN FORMULATION FOR OPTICAL BACKPROPAGATION TRAINING IN KERR-TYPE OPTICAL NETWORKS
    id = 939
    authors = Behrman_E Cmz-Cabrara_A Skinner_S Steck_J 
    7 (0.27208): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    14 (0.16793): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    10 (0.13539): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.03125): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    25 (0.02799): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

134: Interposing an Ontogenic Model Between Genetic Algorithms and Neural Networks
    id = 585
    authors = Belew_R 
    12 (0.22977): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.18746): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.12563): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.05728): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.03776): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    28 (0.03125): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    31 (0.00847): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

135: Learning Aspect Graph Representations from View Sequences
    id = 216
    authors = Seibert_M Waxman_A 
    10 (0.20048): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    8 (0.18746): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    26 (0.14515): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    9 (0.08332): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.04752): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

136: Predicting Weather Using a Genetic Memory: A Combination of Kanerva's Sparse Distributed Memory with Holland's Genetic Algorithms
    id = 240
    authors = Rogers_D 
    15 (0.31113): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    10 (0.26882): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    18 (0.03125): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    3 (0.02799): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.02474): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    5 (0.01497): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

137: A Bifurcation Theory Approach to the Programming of Periodic Attractors in Network Models of Olfactory Cortex
    id = 142
    authors = Baird_B 
    3 (0.25255): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.22001): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.13539): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.06379): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

138: A Parallel Analog CCD/CMOS Signal Processor
    id = 520
    authors = Neugebauer_C Yariv_A 
    17 (0.24279): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    24 (0.19722): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    6 (0.11586): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.04752): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.02799): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    14 (0.02799): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    18 (0.01497): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)

139: EXTRACTING RULES FROM ARTIFICIAL NEURAL NETWORKS WITH DISTRIBUTED REPRESENTATIONS
    id = 906
    authors = Thrun_S 
    10 (0.21024): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.14841): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    14 (0.12237): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.06054): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    13 (0.04101): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.03776): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.03125): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)

140: Synchronization, Oscillations, and l/f Noise in Networks of Spiking Neurons
    id = 779
    authors = Koch_C Olami_Z Stemmler_M Usher_M 
    12 (0.34693): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    14 (0.19722): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    7 (0.10610): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

141: A Weighted Probabilistic Neural Network
    id = 565
    authors = Montana_D 
    1 (0.20048): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.18421): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.12563): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.07355): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    11 (0.07355): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

142: Higher Order Recurrent Networks and Grammatical Inference
    id = 231
    authors = Chen_D Chen_H Giles_C Lee_Y Sun_G 
    10 (0.17444): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    6 (0.14841): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    19 (0.11912): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    11 (0.08983): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.05077): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    22 (0.04426): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    13 (0.03776): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.02148): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)

143: Emergence of Global Structure from Local Associations
    id = 837
    authors = Ghiselli-Crippa_T Munro_P 
    4 (0.30462): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.17119): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.07681): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    6 (0.04101): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.03776): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.02474): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    12 (0.02148): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    34 (0.01497): 23 hidden  (0.09126) 4 input  (0.09126) 11 training  (0.08546) 19 units  (0.07966) 8 time  (0.07386) 22 models  (0.06227) 21 problem  (0.06227) 20 information  (0.05647) 24 performance  (0.05067) 16 error  (0.04487)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

144: A Second-Order Translation, Rotation and Scale Invariant Neural Network
    id = 327
    authors = Goggin_S Gustafson_K Johnson_K 
    6 (0.33717): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    5 (0.29811): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    16 (0.02799): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

145: Postal Address Block Location Using a Convolutional Locator Network
    id = 793
    authors = Platt_J Wolf_R 
    18 (0.23302): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    14 (0.22326): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    4 (0.19072): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    29 (0.01497): 6 function  (0.17004) 11 training  (0.13338) 4 input  (0.08041) 1 learning  (0.08041) 18 results  (0.07227) 5 data  (0.07227) 16 error  (0.05190) 9 set  (0.05190) 8 time  (0.04375) 17 state  (0.03560)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

146: Networks with Learned Unit Response Functions
    id = 557
    authors = Moody_J Yarvin_N 
    3 (0.15817): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.11586): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.11586): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.11261): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    24 (0.05728): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    11 (0.04752): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.04426): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    27 (0.02799): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)

147: Incremental Parsing by Modular Recurrent Connectionist Networks
    id = 229
    authors = Jain_A Waibel_A 
    15 (0.52593): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    0 (0.13213): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

148: ON THE COMPUTATIONAL COMPLEXITY OF NETWORKS OF SPIKING NEURONS
    id = 866
    authors = Maass_W 
    9 (0.16143): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    20 (0.15166): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    8 (0.13213): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.11912): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.09634): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.00847): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

149: Applications of Neural Networks in Video Signal Processing
    id = 324
    authors = Pearson_J Spence_C Sverdlove_R 
    23 (0.29486): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    2 (0.23302): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.07355): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.07030): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

150: Models Wanted: Must Fit Dimensions of Sleep and Dreaming
    id = 429
    authors = Hobson_J Mamelak_A Sutton_J 
    5 (0.21675): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    16 (0.18095): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    43 (0.11261): 11 training  (0.14878) 10 networks  (0.08767) 3 neural  (0.08767) 18 results  (0.07239) 7 figure  (0.07239) 8 time  (0.07239) 0 network  (0.05711) 9 set  (0.05711) 6 function  (0.04183) 1 learning  (0.04183)
    10 (0.09959): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    12 (0.03125): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    19 (0.02474): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

151: Discovering Viewpoint-Invariant Relationships That Characterize Objects
    id = 325
    authors = Hinton_G Zemel_R 
    0 (0.22326): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.17444): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    22 (0.08006): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    12 (0.07681): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    15 (0.06054): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    25 (0.03776): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    10 (0.02474): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    21 (0.01497): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

152: Network Model of State-Dependent Sequencing
    id = 463
    authors = Hobson_J Mamelak_A Sutton_J 
    3 (0.25906): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    15 (0.22651): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    9 (0.11261): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.04101): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.01823): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    21 (0.01497): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    17 (0.00847): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

153: Comparing Biases for Minimal Network Construction with Back-Propagation
    id = 110
    authors = Hanson_S Pratt_L 
    4 (0.18746): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.11586): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.09959): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.08657): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    17 (0.08006): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    22 (0.04752): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    11 (0.04426): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    15 (0.02474): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)

154: Oscillation Onset in Neural Delayed Feedback .
    id = 303
    authors = Longtin_A 
    0 (0.21675): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.21675): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.09634): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    22 (0.07355): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    6 (0.05077): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    18 (0.01497): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

155: Speaker Recognition Using Neural Tree Networks
    id = 829
    authors = Farrell_K Mammone_R 
    14 (0.17770): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    13 (0.15492): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    19 (0.12563): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    1 (0.10610): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.08006): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    20 (0.02148): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    17 (0.01172): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

156: Exploiting Chaos to Control the Future
    id = 781
    authors = Chen_H Flake_G Lee_Y Sun_G 
    28 (0.37297): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    2 (0.12237): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.10610): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.05077): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

157: A Comparison of Projection Pursuit and Neural Network Regression Modeling
    id = 571
    authors = Hwang_J Li_H Maechler_M Martin_R Schimert_J 
    9 (0.25906): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.11912): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    15 (0.10284): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.08332): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.07030): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.04426): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

158: Training Connectionist Networks with Queries and Selective Sampling
    id = 253
    authors = Atlas_L Cohn_D Ladnet_R 
    4 (0.30137): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    3 (0.18746): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.09308): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.08332): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    22 (0.00847): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

159: Using Genetic Algorithms to Improve Pattern Classification Performance .
    id = 393
    authors = Chang_E Lippmann_R 
    9 (0.18421): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.14841): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.12563): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.10284): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.08006): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.02148): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.01497): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    26 (0.01172): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

160: Statistical Mechanics of Learning in a Large Committee Machine
    id = 637
    authors = Hertz_J Schwarze_H 
    20 (0.23953): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    7 (0.14515): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.11912): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.08983): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    5 (0.05728): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    9 (0.01823): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

161: An Optimization Method of Layered Neural Networks Based on the Modified Information Criterion
    id = 737
    authors = Watanabe_S 
    8 (0.19722): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.16468): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.10610): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.09308): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.07681): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    19 (0.02799): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    18 (0.01497): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

162: A MODEL OF THE HIPPOCAMPUS COMBINING SELF-ORGANIZATION AND ASSOCIATIVE MEMORY FUNCTION
    id = 853
    authors = Hasselmo_M Schnell_E 
    1 (0.24930): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.22326): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    6 (0.05728): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.04752): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    11 (0.04752): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.04101): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

163: NEURAL NETWORK ENSEMBLES, CROSS VALIDATION, AND ACTIVE LEARNING
    id = 872
    authors = Krogh_A Vedelsby_J 
    13 (0.31764): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    12 (0.19397): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    7 (0.10935): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

164: An Analog VLSI Saccadic Eye Movement System
    id = 773
    authors = Bisofberger_B Horiuchi_T Koch_C 
    11 (0.19397): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.14190): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.09634): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    22 (0.07030): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    0 (0.06054): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.05403): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.04101): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    15 (0.02474): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    21 (0.01497): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

165: Combined Neural Networks for Time Series Analysis
    id = 728
    authors = Ginzburg_I Horn_D 
    6 (0.17444): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.13864): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.12563): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    27 (0.07355): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    23 (0.06054): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    15 (0.05077): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    26 (0.04101): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    7 (0.02148): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

166: ALVINN: An Autonomous Land Vehicle in a Neural Network
    id = 125
    authors = Pomerleau_D 
    5 (0.36646): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    16 (0.21024): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    13 (0.05403): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.03125): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

167: A Passive Shared Element Analog Electrical Cochlea
    id = 166
    authors = Eisenberg_J Feld_D Lewis_E 
    2 (0.33391): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.13539): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.11912): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.07681): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

168: OPTIMAL MOVEMENT PRIMITIVES
    id = 970
    authors = Sanger_T 
    1 (0.17444): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.16143): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    35 (0.14841): 2 model  (0.12882) 11 training  (0.10820) 23 hidden  (0.08070) 24 performance  (0.07382) 0 network  (0.06695) 15 system  (0.05320) 22 models  (0.04632) 5 data  (0.03945) 6 function  (0.03945) 17 state  (0.03945)
    11 (0.08006): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    4 (0.07355): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.03125): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.01497): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

169: Input Reconstruction Reliability Estimation
    id = 607
    authors = Pomerleau_D 
    7 (0.17444): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.16468): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.15817): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    17 (0.12237): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    1 (0.04101): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    11 (0.02148): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

170: A Practice Strategy for Robot Learning Control
    id = 614
    authors = Sanger_T 
    12 (0.24930): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.14190): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.09959): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    27 (0.07030): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    0 (0.06379): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    19 (0.02799): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    18 (0.02474): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

171: Combining Neural and Symbolic Learning to Revise Probabilistic Rule Bases
    id = 586
    authors = Mahoney_J Mooney_R 
    0 (0.29160): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    11 (0.24279): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    26 (0.07355): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    6 (0.04101): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

172: Linear Operator for Object Recognition
    id = 484
    authors = Basri_R Ullman_S 
    1 (0.18421): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.16468): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.12237): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.08983): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.06705): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.03776): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    27 (0.00847): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    22 (0.00847): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

173: A Computer Modeling Approach to Understanding the Inferior Olive and Its Relationships to the Cerebellar Cortex in Rats
    id = 199
    authors = Bower_J Lee_M 
    2 (0.18746): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.13539): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.13213): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    0 (0.11912): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.05077): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    19 (0.02474): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    3 (0.02148): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.02148): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    31 (0.00521): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)

174: PREDICTING THE RISK OF COMPLICATIONS IN CORONARY ARTERY BYPASS OPERATIONS USING NEURAL NETWORKS
    id = 974
    authors = Kukolich_L Lippmann_R Shahian_D 
    7 (0.40551): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.11586): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    11 (0.07355): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    10 (0.05077): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.02148): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.01497): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

175: CAM Storage of Analog Patterns and Continuous Sequences with 3N 2 Weights .
    id = 298
    authors = Baird_B Eeckman_F 
    9 (0.23302): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.14515): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.09959): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    11 (0.07030): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    4 (0.05403): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.03450): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.01823): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

176: Simple Spin Models for the Development of Ocular Dominance Columns and Iso-Orientation Patches
    id = 289
    authors = Cowen_J Friedman_A 
    1 (0.24604): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.20373): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.08657): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.05077): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.04101): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    5 (0.03125): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    24 (0.00847): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    19 (0.00847): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

177: Parameterising Feature Sensitive Cell Formation in Linsker Networks in the Auditory System
    id = 696
    authors = Bisset_D Walton_L 
    6 (0.27859): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.20048): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.09634): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.03776): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.03450): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    11 (0.03450): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

178: Assessing the Quality of Learned Local Models
    id = 720
    authors = Atkeson_C Schaal_S 
    10 (0.29160): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.14515): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    18 (0.11912): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    12 (0.11261): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    17 (0.00521): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)

179: REINFORCEMENT LEARNING ALGORITHM FOR PARTIALLY OBSERVABLE MARKOV DECISION PROBLEMS
    id = 886
    authors = Jaakkola_T Jordan_M Singh_S 
    4 (0.30788): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.17444): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.07355): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    15 (0.06705): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.03125): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    14 (0.02148): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

180: Development of Orientation and Ocular Dominance Columns in Infant Macaques
    id = 768
    authors = Blasdel_G Kiorpes_L Obermayer_K 
    1 (0.22326): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.13864): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.13539): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.12888): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    7 (0.02799): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.01823): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    18 (0.00847): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

181: Bayesian Backpropagation over I-O Functions Rather Than Weights
    id = 725
    authors = Wolpert_D 
    19 (0.33391): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    7 (0.16143): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    20 (0.08983): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    0 (0.07030): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    11 (0.01823): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

182: A Neural Network Classifier Based on Coding Theory
    id = 17
    authors = Chiueh_T Goodman_R 
    0 (0.25906): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.16143): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.13864): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.06705): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    19 (0.03125): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    7 (0.01497): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

183: Use of Multi-Layered Networks for Coding Speech with Phonetic Features
    id = 115
    authors = Bengio_Y Cardin_R Cosi_P De-Mori_R 
    3 (0.20373): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.11912): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    14 (0.11912): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.10284): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.08006): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.03450): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    18 (0.01497): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

184: Modeling Consistency in a Speaker Independent Continuous Speech Recognition System
    id = 656
    authors = Abrash_V Cohen_M Franco_H Konig_Y Morgan_N Wooters_C 
    13 (0.24279): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.16793): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.14190): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.08006): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.04426): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

185: A Note on Learning Vector Quantization
    id = 600
    authors = Ballard_D de-Sa_V 
    3 (0.31113): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.15492): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.08657): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    9 (0.06705): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    14 (0.05077): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

186: Phasor Neural Networks
    id = 60
    authors = Noest_A 
    9 (0.27533): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    13 (0.22326): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.08006): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    32 (0.08006): 20 information  (0.10804) 9 set  (0.10804) 1 learning  (0.10804) 15 system  (0.09379) 19 units  (0.07953) 14 number  (0.07003) 10 networks  (0.06528) 22 models  (0.04627) 4 input  (0.04627) 17 state  (0.04152)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

187: ASSOCIATIVE DECORRELATION DYNAMICS: A THEORY OF SELF-ORGANIZATION AND OPTIMIZATION IN FEEDBACK NETWORKS
    id = 958
    authors = Dong_D 
    3 (0.34042): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.12888): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    1 (0.10935): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.07681): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    32 (0.01172): 20 information  (0.10804) 9 set  (0.10804) 1 learning  (0.10804) 15 system  (0.09379) 19 units  (0.07953) 14 number  (0.07003) 10 networks  (0.06528) 22 models  (0.04627) 4 input  (0.04627) 17 state  (0.04152)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

188: Generalization Performance in PARSEC--A Structured Connectionist Parsing Architecture
    id = 454
    authors = Jain_A 
    0 (0.16468): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.15166): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.09959): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    17 (0.09634): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    16 (0.08332): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    2 (0.06054): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.01497): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

189: Computational Efficiency: A Common Organizing Principle for Parallel Computer Maps and Brain Maps?
    id = 192
    authors = Bower_J Nelson_M 
    21 (0.26557): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    13 (0.16793): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    17 (0.11912): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    11 (0.08006): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    8 (0.02474): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.01823): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    22 (0.00847): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

190: Tonal Music as a Componential Code: Learning Temporal Relationships between and within Pitch and Timing Components
    id = 835
    authors = Stevens_C Wiles_J 
    7 (0.33391): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.11261): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.09308): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    21 (0.08332): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    6 (0.02799): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    15 (0.02148): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

191: On Line Estimation of Optimal Control Sequences: HJB Estimators
    id = 612
    authors = Peterson_J 
    5 (0.28184): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    15 (0.15492): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.11261): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.10610): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    26 (0.01823): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

192: A Self-Organizing Multiple-View Representation of 3D Objects
    id = 218
    authors = Btilthoff_H Edelman_S Weinshall_D 
    17 (0.29160): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    9 (0.11586): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    14 (0.08983): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.06379): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.05077): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.03125): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    10 (0.01497): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)

193: Closed-Form Inversion of Backpropagation Networks
    id = 403
    authors = Rossen_M 
    3 (0.33391): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.12563): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.07030): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.05403): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.05077): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.03450): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.01497): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

194: Context-Dependent Multiple Distribution Phonetic Modeling with MLPs
    id = 652
    authors = Abrash_V Cohen_M Franco_H Morgan_N Rumelhart_D 
    1 (0.22326): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.13864): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    16 (0.12888): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    12 (0.06054): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.04426): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    10 (0.04426): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    14 (0.02799): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    11 (0.02474): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

195: Holographic Recurrent Networks
    id = 577
    authors = Plate_T 
    10 (0.33066): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.23953): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.05077): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.03125): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.02148): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

196: Reinforcement Learning in Markovian and Non-Markovian Environments . . .
    id = 353
    authors = Schmidhuber_J 
    4 (0.19397): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    3 (0.12888): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.12888): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    15 (0.08657): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    5 (0.03125): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.03125): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    21 (0.02799): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    7 (0.02799): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.02148): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    32 (0.01497): 20 information  (0.10804) 9 set  (0.10804) 1 learning  (0.10804) 15 system  (0.09379) 19 units  (0.07953) 14 number  (0.07003) 10 networks  (0.06528) 22 models  (0.04627) 4 input  (0.04627) 17 state  (0.04152)

197: Speech Recognition: Statistical and Neural Information Processing Approaches
    id = 183
    authors = Bridle_J 
    22 (0.25906): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    13 (0.18421): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.15492): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    27 (0.06705): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

198: Active Exploration in Dynamic Environments
    id = 493
    authors = Moller_K Thrun_S 
    19 (0.22977): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    5 (0.12563): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.08983): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.08332): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.07681): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.07681): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

199: A Dynamical Model of Priming and Repetition Blindness
    id = 680
    authors = Bavelier_D Jordan_M 
    2 (0.21675): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.17444): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.14190): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.07030): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    11 (0.04426): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    13 (0.02148): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.01172): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

200: Connection Topology and Dynamics in Lateral Inhibition Networks
    id = 299
    authors = Marcus_C Waugh_F Westervelt_R 
    7 (0.24604): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.18095): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.11912): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.05728): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.04101): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    17 (0.01497): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    21 (0.00847): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

201: Single Neuron Model: Response to Weak Modulation in the Presence of Noise
    id = 437
    authors = Bulsara_A Jacobs_E Moss_Moss 
    5 (0.26231): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.15817): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.11586): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.09959): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.01823): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

202: Optimization by Mean Field Annealing
    id = 100
    authors = Bilbro_G Mann_R Miller_T Snyder_W VandenBout_D White_M 
    6 (0.23302): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.13864): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.09959): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.08657): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.06705): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.05728): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

203: Incrementally Learning Time-varying Half-planes
    id = 541
    authors = Kuh_A Petsche_T Rivest_R 
    5 (0.24604): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    4 (0.16793): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.15817): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.03776): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    3 (0.02799): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.01823): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    18 (0.01172): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

204: Learning Curves: Asymptotic Values and Rate of Convergence
    id = 741
    authors = Cortes_C Denker_J Jackel_L Solla_S Vapnik_V 
    25 (0.38598): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    5 (0.15492): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.09308): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    9 (0.02799): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    18 (0.00847): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

205: Schema for Motor Control Utilizing a Network Model of the Cerebellum
    id = 38
    authors = Houk_J 
    11 (0.28184): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.17444): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    15 (0.13213): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    9 (0.05728): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.01823): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.01497): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

206: Retinogeniculate Development: The Role of Competition and Correlated Retinal Activity
    id = 440
    authors = Keesing_R Shatz_C Stork_D 
    7 (0.31439): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.09634): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.07681): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.07030): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    16 (0.04752): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.03125): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    10 (0.02474): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

207: AN ALTERNATIVE MODEL FOR MIXTURES OF EXPERTS
    id = 922
    authors = Hinton_G Jordan_M Xu_L 
    12 (0.24604): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    4 (0.22001): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    3 (0.08332): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.06705): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.04101): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    11 (0.01823): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

208: Neural Network Implementation of Admission Control ..
    id = 352
    authors = Guyon_I Milito_R Solla_S 
    15 (0.14515): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.13213): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.11586): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.08983): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.07355): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    16 (0.05403): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    8 (0.02799): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    11 (0.02148): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    26 (0.01497): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)

209: Using Neural Networks to Improve Cochlear Implant Speech Perception
    id = 81
    authors = Tenorio_M 
    12 (0.18421): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    15 (0.16793): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    9 (0.13213): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    11 (0.10610): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    8 (0.06379): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.01823): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    17 (0.01172): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

210: A Method for the Associative Storage of Analog Vectors
    id = 256
    authors = Abu-Mostafa_Y Atiya_A 
    3 (0.22977): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.16793): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    10 (0.10284): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    12 (0.08332): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.04426): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.02799): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.01823): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    20 (0.00847): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

211: Operators and curried functions: Training and analysis of simple recurrent networks
    id = 468
    authors = Bloesch_A Wiles_J 
    0 (0.29486): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.18421): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    11 (0.08006): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    20 (0.04752): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    4 (0.03125): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    28 (0.02799): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    63 (0.01497): 4 input  (0.11674) 8 time  (0.07411) 5 data  (0.07411) 16 error  (0.07411) 10 networks  (0.03147) 7 figure  (0.03147) 9 set  (0.03147) 11 training  (0.03147) 0 network  (0.03147) 1 learning  (0.03147)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

212: BAYESIAN QUERY CONSTRUCTION FOR NEURAL NETWORK MODELS
    id = 898
    authors = Kindermann_J Paass_G 
    28 (0.23628): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    3 (0.13864): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.13213): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    25 (0.12888): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    9 (0.01823): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.01823): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

213: Fixed Point Analysis for Recurrent Networks
    id = 107
    authors = Ballard_D Oftaway_M Simard_P 
    0 (0.23628): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.21024): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    8 (0.09634): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    20 (0.07030): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    26 (0.03776): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    18 (0.01823): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

214: Speech Production Using A Neural Network with a Cooperative Learning Mechanism
    id = 116
    authors = Komura_M Tanaka_A 
    9 (0.18095): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.17119): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.14515): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    22 (0.12888): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    13 (0.02799): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

215: FINANCIAL APPLICATIONS OF LEARNING FROM HINTS
    id = 894
    authors = Abu-Mostafa_Y 
    7 (0.22651): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.19722): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.13539): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.04752): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    37 (0.02799): 8 time  (0.12266) 18 results  (0.11534) 14 number  (0.11534) 6 function  (0.09335) 7 figure  (0.06404) 17 state  (0.04938) 16 error  (0.04205) 23 hidden  (0.04205) 10 networks  (0.04205) 9 set  (0.03472)
    13 (0.02148): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.01823): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

216: A NOVEL REINFORCEMENT MODEL OF BIRDSONG VOCALIZATION LEARNING
    id = 856
    authors = Doya_K Sejnowski_T 
    17 (0.22326): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    0 (0.20373): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    11 (0.12237): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.08006): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    21 (0.02148): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

217: A Systematic Study of the Input/Output Properties of a 2 Compartment Model Neuron With Active Membranes
    id = 203
    authors = Rhodes_P 
    24 (0.37622): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    13 (0.15166): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    20 (0.06379): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    5 (0.05077): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    16 (0.02799): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    17 (0.01172): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    30 (0.00521): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    29 (0.00521): 6 function  (0.17004) 11 training  (0.13338) 4 input  (0.08041) 1 learning  (0.08041) 18 results  (0.07227) 5 data  (0.07227) 16 error  (0.05190) 9 set  (0.05190) 8 time  (0.04375) 17 state  (0.03560)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

218: Image Segmentation with Networks of Variable Scales
    id = 487
    authors = Ben_J Graf_H Nohl_C 
    12 (0.25255): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    3 (0.15166): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.08657): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.07355): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    16 (0.03776): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    20 (0.03450): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    0 (0.03125): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.01497): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    19 (0.01172): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)

219: A 'Neural' Network that Learns to Play Backgammon
    id = 82
    authors = Sejnowski_T Tesauro_G 
    0 (0.21024): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.17444): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.09959): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.08006): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    9 (0.04101): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    14 (0.03450): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    21 (0.02799): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.01497): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)

220: WATTLE: A Trainable Gain Analogue VLSI Neural Network
    id = 809
    authors = Coggins_R Jabri_M 
    0 (0.21350): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.21350): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.15817): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.07355): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    22 (0.00847): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

221: Mixtures of Controllers for Jump Linear and Non-Linear Plants
    id = 790
    authors = Cacciatore_T Nowlan_S 
    5 (0.34368): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    16 (0.23953): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.03125): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    22 (0.00847): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

222: Merging Constrained Optimisation with Deterministic Annealing to "Solve" Combinatorially Hard Problems
    id = 554
    authors = Stolorz_P 
    8 (0.16143): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.14841): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.12237): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.11261): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.10935): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    21 (0.02474): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

223: A Neural Network Approach for Three-Dimensional Object Recognition
    id = 326
    authors = Tresp_V 
    18 (0.45107): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    7 (0.13864): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.04752): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.02148): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    25 (0.01172): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

224: Event-Driven Simulation of Networks of Spiking Neurons
    id = 816
    authors = Watts_L 
    12 (0.29811): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    26 (0.19397): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    21 (0.07030): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    0 (0.05403): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    11 (0.03125): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    8 (0.02148): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.01823): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

225: Filter Selection Model for Generating Visual Motion Signals
    id = 618
    authors = Nowlan_S Sejnowski_T 
    4 (0.23628): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    14 (0.23628): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    16 (0.10284): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    0 (0.05728): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.02148): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.01497): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    17 (0.01172): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

226: Structural and Behavioral Evolution of Recurrent Networks
    id = 711
    authors = Angeline_P Pollack_J Saunders_G 
    4 (0.19397): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.17119): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    13 (0.10284): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    15 (0.09959): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.06705): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.02474): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    18 (0.01497): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

227: Generalization Abilities of Cascade Network Architecture
    id = 596
    authors = Littmann_E Ritter_H 
    6 (0.21675): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.11912): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.09959): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.09959): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    26 (0.09308): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    0 (0.03450): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    18 (0.01172): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    20 (0.00847): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00847): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

228: Structured Machine Learning for "Soft" Classification with Smoothing Spline ANOVA and Stacked Tuning, Testing, and Evaluation
    id = 752
    authors = Gu_C Klein_B Klein_R Wahba_G Wang_Y 
    13 (0.25255): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.15166): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.12888): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.08657): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.04426): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

229: Information Theoretic Analysis of Connection Structure from Spike Trains
    id = 636
    authors = Matsumoto_K Nakashima_M Shiono_S Yamada_S 
    14 (0.51942): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    9 (0.08983): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    15 (0.03776): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    7 (0.02474): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)

230: Statistical Reliability of a Blowfly Movement-Sensitive Neuron
    id = 432
    authors = Bialek_W de-Ruyter-van-Steveninck_R 
    1 (0.35669): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.13213): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.09959): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.06379): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.02474): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

231: Optimal Unsupervised Motor Learning Predicts the Internal Representation of Barn Owl Head Movements
    id = 777
    authors = Sanger_T 
    3 (0.35344): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    15 (0.20048): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    12 (0.08332): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.01497): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    18 (0.00847): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

232: Some Estimates of Necessary Number of Connections and Hidden Units for Feed-Forward Networks
    id = 651
    authors = Kowalczyk_A 
    15 (0.15817): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    0 (0.11261): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    14 (0.10935): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    5 (0.09634): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    9 (0.06705): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.06705): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.06054): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

233: Weight Space Probability Densities in Stochastic Learning: II. Transients and Basin Hopping Times
    id = 635
    authors = Leen_T Orr_G 
    2 (0.23302): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.19397): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.13539): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.08332): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    14 (0.02799): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

234: Dynamics of Learning in Recurrent Feature-Discovery Networks .
    id = 295
    authors = Leen_T 
    0 (0.29160): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.21350): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.09308): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.06379): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

235: USING VOICE TRANSFORMATIONS TO CREATE ADDITIONAL TRAINING TALKERS FOR WORD SPOTTING
    id = 952
    authors = Chang_E Lippmann_R 
    9 (0.25580): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.18095): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    11 (0.14515): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.07355): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.01172): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

236: Simulation and Measurement of the Electric Fields Generated by Weakly Electric Fish
    id = 139
    authors = Assad_C Bower_J Nelson_M Rasnow_B 
    4 (0.28184): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    9 (0.21675): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.11586): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.02799): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.01497): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

237: Non-Linear Dimensionality Reduction
    id = 644
    authors = Cottrell_G DeMers_D 
    12 (0.25255): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    4 (0.24604): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    33 (0.12237): 0 network  (0.09122) 11 training  (0.08608) 14 number  (0.07065) 16 error  (0.07065) 3 neural  (0.06036) 12 algorithm  (0.06036) 17 state  (0.05522) 24 performance  (0.05522) 2 model  (0.05008) 18 results  (0.05008)
    20 (0.01823): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    5 (0.01823): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    57 (0.01172): 23 hidden  (0.19481) 11 training  (0.05901) 10 networks  (0.05901) 13 output  (0.05901) 2 model  (0.05901) 6 function  (0.05901) 24 performance  (0.05901) 5 data  (0.02506) 21 problem  (0.02506) 4 input  (0.02506)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

238: Learning Time-varying Concepts .
    id = 310
    authors = Kuh_A Petsche_T Rivest_R 
    5 (0.32415): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    8 (0.13864): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.10610): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.08332): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

239: High Order Neural Networks for Efficient Associative Memory Design
    id = 24
    authors = Dreyfus_G Guyon_I Nadal_J Personnaz_L 
    7 (0.22651): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.16468): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    15 (0.10610): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.09634): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.07355): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

240: ART2/BP Architecture for Adaptive Estimation of Dynamic Processes
    id = 308
    authors = Sorheim_E 
    6 (0.24930): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.17770): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    15 (0.15166): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    4 (0.04752): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.02799): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.02474): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

241: Fault Diagnosis of Antenna Pointing Systems Using Hybrid Neural Network and Signal Processing Models
    id = 510
    authors = Mellstrom_J Smyth_P 
    2 (0.25255): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    10 (0.16793): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.10610): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.08657): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.05077): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

242: An Analog VLSI Chip for Radial Basis Functions
    id = 666
    authors = Anderson_J Kirk_D Platt_J 
    17 (0.30462): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    1 (0.14515): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    10 (0.09634): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    9 (0.07681): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    12 (0.03776): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    11 (0.02148): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

243: Resolving Motion Ambiguities
    id = 822
    authors = Diamantaras_K Geiger_D 
    11 (0.30462): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    16 (0.28835): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    1 (0.06379): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

244: Temporal Representations in a Connectionist Speech System
    id = 117
    authors = Smythe_E 
    3 (0.24604): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.20373): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.10935): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.06379): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    10 (0.04101): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    4 (0.01823): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

245: Single-iteration Threshold Hamming Networks
    id = 642
    authors = Meilijson_I Ruppin_E Sipper_M 
    8 (0.13864): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.13213): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.13213): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    3 (0.10935): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.10935): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    28 (0.05077): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

246: On Properties of Networks of Neuron-Like Elements
    id = 4
    authors = Baldi_P Venkatesh_S 
    1 (0.35018): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.12563): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.11586): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.04101): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    6 (0.03450): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

247: Adaptive Development of Connectionist Decoders for Complex Error-Correcting Codes
    id = 513
    authors = Blaum_M Gish_S 
    6 (0.31764): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    10 (0.13213): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    4 (0.09634): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    3 (0.07030): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.03450): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    15 (0.01497): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    27 (0.00847): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)

248: Supervised Learning with Growing Cell Structures
    id = 732
    authors = Fritzke_B 
    3 (0.41202): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.08657): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.08332): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    19 (0.05403): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    7 (0.02474): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

249: Analog Cochlear Model for Multiresolution Speech Analysis
    id = 654
    authors = Andreou_A Goldstein_M Liu_W 
    0 (0.27533): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    10 (0.20699): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    6 (0.13213): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    11 (0.05077): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

250: Non-Linear Statistical Analysis and Self-Organizing Hebbian Networks
    id = 751
    authors = Prtigel-Bennett_A Shapiro_J 
    1 (0.28184): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    27 (0.14190): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    2 (0.09959): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.09959): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.02799): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.01823): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

251: A Boundary Hunting Radial Basis Function Classifier which Allocates Centers Constructively
    id = 590
    authors = Chang_E Lippmann_R 
    5 (0.20048): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    3 (0.14841): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    22 (0.10935): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    1 (0.09634): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.06379): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    4 (0.01823): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.01497): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)

252: EMPATH: Face, Emotion, and Gender Recognition Using Holons ..
    id = 362
    authors = Cottrell_G Metcalfe_J 
    15 (0.22651): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    13 (0.12563): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    9 (0.09308): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.08983): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    19 (0.06054): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    6 (0.05403): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.03125): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

253: Connectionist Models for Auditory Scene Analysis
    id = 833
    authors = Duda_R 
    5 (0.37947): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.17119): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.10935): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

254: VLSI Phase Locking Architectures for Feature Linking in Multiple Target Tracking Systems
    id = 808
    authors = Andreou_A Edwards_T 
    4 (0.21350): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.19397): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.09308): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.07355): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.05077): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    11 (0.04101): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.01823): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

255: Neural Network Definitions of Highly Predictable Protein Secondary Structure Classes
    id = 801
    authors = Farber_R Lapedes_A Steeg_E 
    16 (0.35344): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    27 (0.27859): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    4 (0.02474): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    19 (0.01172): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

256: Order Reduction for Dynamical Systems Describing the Behavior of Complex Neurons .
    id = 293
    authors = Abbott_L Kepler_T Marder_E 
    0 (0.31113): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.20699): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.11586): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    21 (0.03450): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

257: Learning Fuzzy Rule-Based Neural Networks for Control
    id = 616
    authors = Goodman_R Higgins_C 
    6 (0.38924): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    5 (0.20048): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.07681): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

258: An Attractor Neural Network Model of Recall and Recognition .
    id = 373
    authors = Ruppin_E Yeshurun_Y 
    5 (0.16793): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    26 (0.11261): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    16 (0.11261): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    1 (0.11261): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.09959): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.04752): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.01497): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)

259: The Role of MT Neuron Receptive Field Surrounds in Computing Object Shape from Velocity Fields
    id = 821
    authors = Albright_T Buracas_G 
    3 (0.28510): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.13213): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    22 (0.10610): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    1 (0.09959): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    37 (0.03125): 8 time  (0.12266) 18 results  (0.11534) 14 number  (0.11534) 6 function  (0.09335) 7 figure  (0.06404) 17 state  (0.04938) 16 error  (0.04205) 23 hidden  (0.04205) 10 networks  (0.04205) 9 set  (0.03472)
    9 (0.02148): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

260: On the K-Winners-Take-All Network
    id = 163
    authors = Abu-Mostafa_Y Erlanson_R Majani_E 
    2 (0.23302): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.19722): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.12563): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.08332): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    11 (0.02799): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    26 (0.01497): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

261: Combined Neural Network and Rule-Based Framework for Probabilistic Pattern Recognition and Discovery
    id = 483
    authors = Chellappa_R Goodman_R Greenspan_H 
    4 (0.27859): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    9 (0.19072): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.15492): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.02148): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    14 (0.01497): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

262: Computing with Arrays of Bell-Shaped and Sigrnoid Functions .
    id = 385
    authors = Baldi_P 
    11 (0.11912): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    26 (0.11261): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    15 (0.11261): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.07355): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.06379): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.05403): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    3 (0.05403): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.05403): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    10 (0.03450): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    7 (0.01497): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)

263: Further Explorations in Visually-Guided Reaching: Making MURPHY Smarter
    id = 130
    authors = Mel_B 
    9 (0.15492): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.15492): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.13539): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.09634): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    15 (0.08983): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.01823): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    19 (0.01497): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)

264: Iterative Construction of Sparse Polynomial Approximations
    id = 559
    authors = Matheus_C Sanger_T Sutton_R 
    19 (0.18746): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    22 (0.16468): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    1 (0.13213): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    21 (0.08006): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    5 (0.05077): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    16 (0.02474): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    2 (0.02474): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.02474): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

265: Mathematical Analysis of Learning Behavior of Neuronal Models
    id = 16
    authors = Cheung_J Omidvar_M 
    5 (0.29486): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.12237): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    13 (0.09959): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    18 (0.06379): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    10 (0.05728): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    17 (0.02799): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    25 (0.01172): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

266: Grouping Contours by Iterated Pairing Network .
    id = 330
    authors = Shashua_A Ullman_S 
    1 (0.31764): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.14841): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.09308): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.07030): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.03125): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    22 (0.01823): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

267: Information through a Spiking Neuron
    id = 994
    authors = Stevens_C Zador_A 
    0 (0.20699): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.13864): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    25 (0.09308): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    5 (0.06054): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    19 (0.05403): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    4 (0.04752): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    35 (0.04426): 2 model  (0.12882) 11 training  (0.10820) 23 hidden  (0.08070) 24 performance  (0.07382) 0 network  (0.06695) 15 system  (0.05320) 22 models  (0.04632) 5 data  (0.03945) 6 function  (0.03945) 17 state  (0.03945)
    15 (0.03125): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)

268: A Network for Image Segmentation Using Color
    id = 124
    authors = Hurlbert_A Poggio_T 
    17 (0.29811): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    11 (0.12563): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    9 (0.08983): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.06705): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.05728): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

269: Recurrent Networks and NARMA Modeling
    id = 465
    authors = Atlas_L Connor_J Martin_D 
    37 (0.25580): 8 time  (0.12266) 18 results  (0.11534) 14 number  (0.11534) 6 function  (0.09335) 7 figure  (0.06404) 17 state  (0.04938) 16 error  (0.04205) 23 hidden  (0.04205) 10 networks  (0.04205) 9 set  (0.03472)
    11 (0.21350): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    10 (0.13864): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.06054): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

270: Polynomial Uniform Convergence of Relative Frequencies to Probabilities
    id = 539
    authors = Bertoni_A Campadelli_P Morpurgo_A Panizza_S 
    16 (0.33391): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    4 (0.22651): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    13 (0.05077): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    14 (0.02474): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

271: Neural Approach for TV Image Compression Using a Hopfield Type Network
    id = 120
    authors = Naillon_M Theeten_J 
    20 (0.28184): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    0 (0.18095): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.13864): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.02799): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

272: A Self-Learning Neural Network
    id = 178
    authors = Hartstein_A Koch_R 
    18 (0.27859): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    0 (0.19072): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.13213): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.03450): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.03125): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    20 (0.01497): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

273: RECURRENT NETWORKS: SECOND ORDER PROPERTIES AND PRUNING
    id = 927
    authors = Hansen_L Pedersen_M 
    22 (0.26557): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    2 (0.19072): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    15 (0.16793): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

274: Neural Network Implementation Approaches for the Connection Machine
    id = 12
    authors = Brown_N 
    3 (0.22651): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.16468): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    14 (0.11586): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    1 (0.10610): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.04752): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    20 (0.01172): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

275: AN INTEGRATED ARCHITECTURE OF ADAPTIVE NEURAL NETWORK CONTROL FOR DYNAMIC SYSTEMS
    id = 971
    authors = Ke_L McVey_B Tokar_R 
    1 (0.22001): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.19722): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.15492): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.08332): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    28 (0.02148): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

276: A Hybrid Linear/Nonlinear Approach to Channel Equilization Problems
    id = 655
    authors = Lee_W Pearson_J 
    25 (0.42504): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    9 (0.12888): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.08657): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    14 (0.02474): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

277: AN ACTOR/CRITIC ALGORITHM THAT IS EQUIVALENT TO Q-LEARNING
    id = 893
    authors = Barto_A Crites_R 
    1 (0.36320): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    14 (0.16143): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    0 (0.11912): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

278: Learning Representations by Recirculation
    id = 37
    authors = Hinton_G McClelland_J 
    9 (0.32089): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.12237): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    16 (0.08657): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    10 (0.06705): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    8 (0.05728): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

279: Forward Dynamics Modeling of Speech Motor Control Using Physiological Data
    id = 452
    authors = Hirayama_M Jordan_M Kawato_M Vatikiotis-Bateson_E 
    14 (0.28835): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    0 (0.22651): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.08657): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.04752): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    10 (0.01823): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

280: Performance of a Stochastic Learning Microchip
    id = 176
    authors = Allen_R Alspector_J Gupta_B 
    11 (0.18746): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    14 (0.14841): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    9 (0.12563): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.06705): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    26 (0.05077): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    1 (0.03450): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.03450): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.03125): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    7 (0.01497): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    17 (0.00847): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)

281: Rapidly Adapting Artificial Neural Networks for Autonomous Navigation .
    id = 343
    authors = Pomerleau_D 
    12 (0.29160): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.27859): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.07681): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    24 (0.01497): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

282: Digital-Analog Hybrid Synapse Chips for Electronic Neural Networks
    id = 278
    authors = Duong_T Moopenn_A Thakoor_A 
    13 (0.20048): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.14190): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.10935): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    16 (0.08657): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    22 (0.04752): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    19 (0.04426): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    12 (0.02474): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)

283: Spherical Units as Dynamic Consequential Regions .
    id = 375
    authors = Gluck_M Hanson_S 
    18 (0.24279): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    20 (0.12888): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    7 (0.11912): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    10 (0.10610): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    15 (0.05077): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    13 (0.03125): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

284: Supervised Learning of Probability Distributions by Neural Networks
    id = 5
    authors = Baum_E Wilczek_F 
    4 (0.18095): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.16143): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    20 (0.13213): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    3 (0.11261): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.08657): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

285: Training Multilayer Perceptrons with the Extended Kalman Algorithm
    id = 105
    authors = Singhal_S Wu_L 
    10 (0.30462): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.21675): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.10284): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    9 (0.02474): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.02474): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

286: Neural Network Analysis of Event Related Potentials and Electroencephalogram Predicts Vigilance
    id = 508
    authors = Lytton_W Sejnowski_T Venturini_R 
    1 (0.29811): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.19072): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    17 (0.08332): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    3 (0.07355): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    45 (0.01823): 8 time  (0.15592) 21 problem  (0.10789) 2 model  (0.09188) 9 set  (0.09188) 22 models  (0.07587) 17 state  (0.04384) 10 networks  (0.04384) 0 network  (0.04384) 18 results  (0.04384) 5 data  (0.04384)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    18 (0.00847): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

287: The Power of Amnesia
    id = 722
    authors = Ron_D Singer_Y Tishby_N 
    10 (0.32089): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    6 (0.16468): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    22 (0.14841): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    2 (0.03776): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

288: Collective Oscillations in the Visual Cortex
    id = 194
    authors = Holmes_P Kammen_D Koch_C 
    0 (0.24930): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.16793): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    52 (0.10284): 11 training  (0.11603) 1 learning  (0.11603) 18 results  (0.11603) 23 hidden  (0.09581) 4 input  (0.07559) 5 data  (0.05537) 13 output  (0.05537) 2 model  (0.05537) 7 figure  (0.03515) 10 networks  (0.03515)
    7 (0.06379): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    22 (0.05077): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    14 (0.04752): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

289: Second Order Properties of Error Surfaces .
    id = 410
    authors = Kanter_I LeCun_Y Solla_S 
    15 (0.29486): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    10 (0.23302): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.13213): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

290: The Recurrent Cascade-Correlation Architecture .
    id = 311
    authors = Fahlman_S 
    7 (0.22326): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.16143): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.12888): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    3 (0.07681): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.04752): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.03776): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

291: Unsupervised Parallel Feature Extraction from First Principles
    id = 717
    authors = Lenz_R Osterberg_M 
    12 (0.34693): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.10284): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.09308): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    19 (0.08006): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    6 (0.02148): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    7 (0.01497): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)

292: Extended Regularization Methods for Nonconvergent Model Selections
    id = 601
    authors = Finnoff_W Hergert_Hergert Zimmermann_H 
    11 (0.31764): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.19397): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.08332): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.03776): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.02799): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.01823): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

293: Learning to Control an Unstable System with Forward Modeling
    id = 224
    authors = Jacobs_R Jordan_M 
    1 (0.25255): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.11912): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    20 (0.10935): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    28 (0.08983): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    0 (0.07030): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.02148): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    21 (0.01823): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

294: A NON-LINEAR INFORMATION MAXIMISATION ALGORITHM THAT PERFORMS BLIND SEPARATION
    id = 901
    authors = Bell_A Sejnowski_T 
    2 (0.26882): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.11261): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.10284): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.08657): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    9 (0.06705): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    16 (0.02148): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    22 (0.01823): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    10 (0.01497): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

295: A Comparison of Dynamic Reposing and Tangent Distance for Drug Activity Prediction
    id = 727
    authors = Dietterich_T Jain_A Lathrop_R Lozano-Perez_T 
    10 (0.26557): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.12888): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.12237): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.09308): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    27 (0.04752): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    3 (0.02148): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

296: Analog Neural Networks as Decoders .
    id = 365
    authors = Abu-Mostafa_Y Erlanson_R 
    21 (0.22977): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    5 (0.20699): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    19 (0.10284): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    12 (0.05403): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.03776): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    15 (0.02474): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)

297: Direct Memory Access Using Two Cues .
    id = 372
    authors = Bain_J Dennis_S Humphreys_M Wiles_J 
    2 (0.21024): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    18 (0.20373): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    7 (0.07681): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.06054): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    15 (0.05403): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    5 (0.03776): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    4 (0.03450): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)

298: DIFFUSION OF CREDIT IN MARKOVIAN MODELS
    id = 912
    authors = Bengio_Y Frasconi_P 
    22 (0.40877): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    7 (0.17444): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    43 (0.05077): 11 training  (0.14878) 10 networks  (0.08767) 3 neural  (0.08767) 18 results  (0.07239) 7 figure  (0.07239) 8 time  (0.07239) 0 network  (0.05711) 9 set  (0.05711) 6 function  (0.04183) 1 learning  (0.04183)
    10 (0.02799): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    20 (0.01497): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    17 (0.00521): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)

299: Time Trials on Second-Order and Variable-Learning-Rate Algorithms .
    id = 418
    authors = Rohwer_R 
    3 (0.16793): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    5 (0.13864): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    10 (0.11912): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    13 (0.09959): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    15 (0.08657): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.06054): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

300: Convergence of a Neural Network Classifier .
    id = 399
    authors = Baras_J LaVigna_A 
    8 (0.28510): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    11 (0.22001): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.10935): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.05403): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

301: Synchronization and Grammatical Inference in an Oscillating Elman Net
    id = 602
    authors = Baird_B Eeckman_F Troyer_T 
    20 (0.23953): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    0 (0.14841): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    14 (0.09959): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    1 (0.08332): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.06705): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    7 (0.02148): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    15 (0.01823): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    24 (0.01172): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

302: A SILICON AXON
    id = 935
    authors = Coggins_R Diorio_C Hasler_P Mead_C Minch_B 
    0 (0.20048): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.20048): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.09308): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    15 (0.08006): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.07030): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.03776): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

303: VLSI Implementations of Learning and Memory Systems ..
    id = 420
    authors = Holler_M 
    2 (0.20699): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    42 (0.18421): 11 training  (0.10393) 21 problem  (0.09050) 2 model  (0.09050) 6 function  (0.07707) 13 output  (0.06364) 15 system  (0.06364) 5 data  (0.06364) 24 performance  (0.06364) 17 state  (0.05021) 22 models  (0.03678)
    25 (0.16143): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    0 (0.06379): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.02148): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.01823): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    18 (0.01497): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    22 (0.01172): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    45 (0.00847): 8 time  (0.15592) 21 problem  (0.10789) 2 model  (0.09188) 9 set  (0.09188) 22 models  (0.07587) 17 state  (0.04384) 10 networks  (0.04384) 0 network  (0.04384) 18 results  (0.04384) 5 data  (0.04384)

304: A COMPARISON OF DISCRETE-TIME OPERATOR MODELS FOR NONLINEAR SYSTEM IDENTIFICATION
    id = 953
    authors = Back_A Tsoi_A 
    17 (0.52267): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    0 (0.05403): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.03125): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    44 (0.01497): 16 error  (0.13557) 3 neural  (0.12005) 11 training  (0.08903) 0 network  (0.07351) 4 input  (0.05800) 24 performance  (0.05800) 9 set  (0.04248) 5 data  (0.04248) 10 networks  (0.04248) 23 hidden  (0.02697)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

305: Analog VLSI Implementation of Gradient Descent
    id = 669
    authors = Barr_A Fleischer_K Kerns_D Kirk_D 
    10 (0.25580): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.16468): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.08983): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    19 (0.05728): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.04101): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    5 (0.03776): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.02474): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

306: VLSI Implementation of a High-Capacity Neural Network Associative Memory
    id = 281
    authors = Chiueh_T Goodman_R 
    14 (0.16468): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    16 (0.12237): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    5 (0.08983): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    23 (0.08006): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    17 (0.06054): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    10 (0.04101): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    22 (0.04101): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    4 (0.03776): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.03125): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.02148): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)

307: Multi-State Time Delay Neural Networks for Continuous Speech Recognition
    id = 445
    authors = Haffner_P Waibel_A 
    9 (0.23628): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.15817): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.09959): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.09308): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.07030): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.01823): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    40 (0.01172): 5 data  (0.16090) 16 error  (0.08362) 12 algorithm  (0.08362) 18 results  (0.07503) 22 models  (0.06645) 15 system  (0.04927) 13 output  (0.04927) 21 problem  (0.04927) 0 network  (0.04927) 2 model  (0.04927)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

308: Probabilistic Characterization of Neural Model Computations
    id = 33
    authors = Golden_R 
    14 (0.34042): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    4 (0.12888): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.06705): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.05403): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.02799): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    13 (0.02148): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    5 (0.01823): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)

309: AN INPUT OUTPUT HMM ARCHITECTURE
    id = 896
    authors = Bengio_Y Frasconi_P 
    13 (0.27533): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.15492): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.15166): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.05403): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.02148): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.01823): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

310: An Analog VLSI Chip for Finding Edges from Zero-crossings .
    id = 339
    authors = Bair_W Koch_C 
    24 (0.35344): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    18 (0.21024): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    9 (0.07355): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    21 (0.02799): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

311: Q-Learning with Hidden-Unit Restarting
    id = 583
    authors = Anderson_C 
    9 (0.24279): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    14 (0.17770): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    11 (0.13864): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.09308): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    17 (0.02474): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

312: On Tropistic Processing and Its Applications
    id = 27
    authors = Fernandez_M 
    16 (0.23302): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    1 (0.21350): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.13539): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.05728): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    17 (0.01497): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    23 (0.01497): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)

313: Performance Comparisons Between Backpropagation Networks and Classification Trees on Three Real-World Applications
    id = 260
    authors = Atlas_L Barnard_E Cole_R Connor_J El-Sharkawi_M Marks_R Muthusamy_Y 
    8 (0.23302): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.14190): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.09959): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.07355): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.05403): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.03125): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    31 (0.03125): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    15 (0.01497): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    10 (0.01497): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)

314: A Connectionist Symbol Manipulator that Discovers the Structure of Context-Free Languages
    id = 678
    authors = Das_S Mozer_M 
    15 (0.27533): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.16468): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.08657): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    19 (0.07355): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    3 (0.04752): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    16 (0.01823): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    2 (0.01823): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    31 (0.00521): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

315: A Local Algorithm to Learn Trajectories with Stochastic Neural Networks
    id = 710
    authors = Movellan_J 
    3 (0.24604): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.19397): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.12563): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    28 (0.10284): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

316: Synaptic Weight Noise During MLP Learning Enhances Fault-Tolerance, Generalization and Learning Trajectory
    id = 633
    authors = Edwards_P Murray_A 
    5 (0.32415): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    3 (0.16468): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.10610): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.07355): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

317: Sequential Decision Problems and Neural Networks
    id = 268
    authors = Barto_A Sutton_R Watkins_C 
    13 (0.19397): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    5 (0.14515): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.11586): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.06705): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.06379): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.06379): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)

318: Analyzing the Energy Landscapes of Distributed Winner-Take-All Networks
    id = 162
    authors = Touretzky_D 
    1 (0.27859): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    10 (0.12237): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    6 (0.09634): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    16 (0.08657): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    45 (0.04426): 8 time  (0.15592) 21 problem  (0.10789) 2 model  (0.09188) 9 set  (0.09188) 22 models  (0.07587) 17 state  (0.04384) 10 networks  (0.04384) 0 network  (0.04384) 18 results  (0.04384) 5 data  (0.04384)
    3 (0.04426): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

319: A Hodgkin-Huxley Type Neuron Model That Learns Slow Non-Spike Oscillation
    id = 771
    authors = Doya_K Rowat_P Selverston_A 
    29 (0.17119): 6 function  (0.17004) 11 training  (0.13338) 4 input  (0.08041) 1 learning  (0.08041) 18 results  (0.07227) 5 data  (0.07227) 16 error  (0.05190) 9 set  (0.05190) 8 time  (0.04375) 17 state  (0.03560)
    8 (0.14515): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    27 (0.11912): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    0 (0.10284): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.07681): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.03125): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    41 (0.02148): 21 problem  (0.16446) 7 figure  (0.13864) 2 model  (0.09990) 16 error  (0.08699) 17 state  (0.07408) 24 performance  (0.07408) 14 number  (0.06117) 10 networks  (0.03535) 3 neural  (0.03535) 12 algorithm  (0.02244)
    11 (0.02148): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    19 (0.00847): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

320: Intersecting Regions: The Key to Combinatorial Structure in Hidden Unit Space
    id = 576
    authors = Ollila_M Wiles_J 
    16 (0.27533): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    1 (0.26882): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.06705): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    7 (0.03125): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.03125): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    22 (0.00847): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

321: Capacity for Patterns and Sequences in Kanerva's SDM as Compared to Other Associative Memory Models
    id = 43
    authors = Keeler_J 
    26 (0.21350): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    0 (0.17119): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.09634): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.09308): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.07355): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    22 (0.00847): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)

322: Green's Function Method for Fast On-line Learning Algorithm of Recurrent Neural Networks
    id = 469
    authors = Chen_H Lee_Y Sun_G 
    9 (0.32089): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.25580): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    20 (0.05728): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    2 (0.02148): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    27 (0.01823): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

323: A Knowledge-Based Model of Geometry Learning
    id = 681
    authors = Lehrer_R Towell_G 
    10 (0.19072): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    7 (0.17444): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.12888): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.12563): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.03776): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    24 (0.00847): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

324: On Learning mu-Perceptron Networks with Binary Weights
    id = 645
    authors = Golea_M Hancock_T Marchand_M 
    3 (0.25580): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.18095): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.15817): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.05077): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    11 (0.01497): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    20 (0.01497): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

325: Nets with Unreliable Hidden Nodes Learn Error-Correcting Codes
    id = 584
    authors = Judd_S Munro_P 
    4 (0.28184): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.23302): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.09634): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.05077): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.01172): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

326: BOOSTING THE PERFORMANCE OF RBF NETWORKS WITH DYNAMIC DECAY ADJUSTMENT
    id = 908
    authors = Berthold_M Diamond_J 
    2 (0.32415): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.16793): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.16468): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.01172): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

327: DIRECT MULTI-STEP TIME SERIES PREDICTION USING TD(LAMBDA)
    id = 933
    authors = Kazlas_P Weigend_A 
    5 (0.48036): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    8 (0.09634): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.04752): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.03125): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

328: INSTANCE-BASED STATE IDENTIFICATION FOR REINFORCEMENT LEARNING
    id = 890
    authors = McCallum_R 
    14 (0.18421): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    9 (0.11261): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    13 (0.11261): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.09308): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    6 (0.07355): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.04426): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    17 (0.03776): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    10 (0.03450): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

329: Implications of Recursive Distributed Representations
    id = 150
    authors = Pollack_J 
    4 (0.27208): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.20048): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.10935): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.05077): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.02474): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    18 (0.01172): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

330: Observability of Neural Network Behavior
    id = 757
    authors = Botelho_F Garzon_M 
    10 (0.23953): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.19072): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    22 (0.08983): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    3 (0.06705): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.06379): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    15 (0.01497): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    12 (0.01497): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

331: Multi-Digit Recognition Using a Space Displacement Neural Network
    id = 488
    authors = Burges_C Denker_J LeCun_Y Matan_O 
    14 (0.27859): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.18746): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.08006): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.08006): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.02148): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    26 (0.01497): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    24 (0.01497): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

332: Fast Non-Linear Dimension Reduction
    id = 719
    authors = Kambhatla_N Leen_T 
    10 (0.21675): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    7 (0.14515): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    22 (0.13213): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    1 (0.09959): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.04426): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.03450): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

333: e-Entropy and the Complexity of Feedforward Neural Networks .
    id = 414
    authors = Williamson_R 
    14 (0.21350): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    1 (0.21024): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.12237): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.05728): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    17 (0.04426): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    36 (0.01497): 15 system  (0.22042) 19 units  (0.12720) 18 results  (0.06266) 14 number  (0.06266) 7 figure  (0.05549) 3 neural  (0.05549) 10 networks  (0.05549) 4 input  (0.04832) 23 hidden  (0.04832) 5 data  (0.03398)
    26 (0.01172): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    22 (0.01172): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

334: ON-LINE LEARNING OF DICHOTOMIES
    id = 881
    authors = Barkai_N Seung_H 
    11 (0.19397): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    10 (0.17444): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.16793): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.06705): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.03776): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    20 (0.01823): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    27 (0.01172): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)

335: Evaluation of Adaptive Mixtures of Competing Experts ..
    id = 390
    authors = Hinton_G Nowlan_S 
    4 (0.15817): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    32 (0.13864): 20 information  (0.10804) 9 set  (0.10804) 1 learning  (0.10804) 15 system  (0.09379) 19 units  (0.07953) 14 number  (0.07003) 10 networks  (0.06528) 22 models  (0.04627) 4 input  (0.04627) 17 state  (0.04152)
    21 (0.10935): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    2 (0.10610): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.08006): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    29 (0.05077): 6 function  (0.17004) 11 training  (0.13338) 4 input  (0.08041) 1 learning  (0.08041) 18 results  (0.07227) 5 data  (0.07227) 16 error  (0.05190) 9 set  (0.05190) 8 time  (0.04375) 17 state  (0.03560)
    1 (0.04101): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

336: A Segment-based Automatic Language Identification System
    id = 458
    authors = Cole_R Muthusamy_Y 
    4 (0.30462): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    3 (0.19397): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.11261): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.04426): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

337: A Framework for the Cooperation of Learning Algorithms .
    id = 391
    authors = Bottou_L Gallinari_P 
    7 (0.16793): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    14 (0.16468): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.13213): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.08006): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    11 (0.05403): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.04101): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.02799): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    24 (0.02474): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

338: Central and Pairwise Data Clustering by Competitive Neural Networks
    id = 713
    authors = Buhmann_J Hofmann_T 
    9 (0.18421): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    27 (0.14841): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    17 (0.12237): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    22 (0.11586): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    6 (0.03776): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    5 (0.02799): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    36 (0.01497): 15 system  (0.22042) 19 units  (0.12720) 18 results  (0.06266) 14 number  (0.06266) 7 figure  (0.05549) 3 neural  (0.05549) 10 networks  (0.05549) 4 input  (0.04832) 23 hidden  (0.04832) 5 data  (0.03398)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    19 (0.01172): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

339: ANALYSIS OF UNSTANDARDIZED CONTRIBUTIONS IN CROSS CONNECTED NETWORKS
    id = 918
    authors = Oshima-Takane_Y Shultz_T Takane_Y 
    13 (0.41853): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.13864): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    1 (0.10284): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

340: A Computer Simulation of Cerebral Neocortex: Computational Capabilities of Nonlinear Neural Networks
    id = 74
    authors = Donoghue_J Singer_A 
    12 (0.23953): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    4 (0.20048): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    1 (0.06379): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.06054): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    14 (0.05728): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    7 (0.05728): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

341: Solvable Models of Artificial Neural Networks
    id = 753
    authors = Watanabe_S 
    0 (0.21024): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.16468): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.10284): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    21 (0.08657): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    11 (0.06705): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    7 (0.02148): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    12 (0.02148): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

342: Signature Verification Using a "Siamese" Time Delay Neural Network
    id = 792
    authors = Bromley_J Guyon_I LeCun_Y Sackinger_E Shah_R 
    0 (0.22001): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.20048): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.09308): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.08657): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.03450): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    15 (0.02799): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)

343: Shaping the State Space Landscape in Recurrent Networks .
    id = 300
    authors = Raysz_J Simard_P Victorri_B 
    7 (0.24604): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    5 (0.12237): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.11912): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.08332): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.08006): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    16 (0.01823): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

344: Neuronal Group Selection Theory: A Grounding in Robotics
    id = 222
    authors = Donnett_J Smithers_T 
    4 (0.29811): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.09634): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    8 (0.08657): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    27 (0.06705): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    5 (0.06379): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.02474): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.02148): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.02148): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)

345: A Recurrent Neural Network Model of Velocity Storage in the Vestibulo-Ocular Reflex
    id = 290
    authors = Anastasio_T 
    1 (0.28835): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    16 (0.16143): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    14 (0.13539): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.08006): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

346: Neural Networks that Learn to Discriminate Similar Kanji Characters
    id = 128
    authors = Mori_Y Yokosawa_K 
    15 (0.20373): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    10 (0.15166): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    13 (0.10935): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    17 (0.10284): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    6 (0.07681): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)

347: ALCOVE: A Connectionist Model of Human Category Learning .
    id = 374
    authors = Kruschke_J 
    0 (0.20373): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.15166): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.10284): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.08006): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.07355): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.06054): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.01172): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

348: Generation of Internal Representation by a-Transformation
    id = 734
    authors = Kamimura_R 
    8 (0.18746): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.11261): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.09634): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.09308): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.08006): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    11 (0.05403): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    15 (0.03125): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    13 (0.02799): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)

349: A RIGOROUS ANALYSIS OF LINSKER-TYPE HEBBIAN LEARNING
    id = 883
    authors = Feng_J Pan_H Roychowdhury_V 
    17 (0.42504): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    7 (0.10610): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.05403): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    19 (0.04426): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    0 (0.04426): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

350: A Self-organizing Associative Memory System for Control Applications
    id = 225
    authors = Hormel_M 
    10 (0.14190): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.12237): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    7 (0.10935): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.10610): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    53 (0.07681): 14 number  (0.15506) 6 function  (0.10904) 8 time  (0.10904) 9 set  (0.08602) 23 hidden  (0.06301) 15 system  (0.06301) 21 problem  (0.04000) 7 figure  (0.04000) 1 learning  (0.04000) 5 data  (0.04000)
    16 (0.05403): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    19 (0.04752): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    2 (0.01823): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)

351: Planning with an Adaptive World Model .
    id = 346
    authors = Linden_A Moller_K Thrun_S 
    17 (0.29811): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    5 (0.24279): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    8 (0.07355): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    15 (0.02474): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

352: Automatic Capacity Tuning of Very Large VC-Dimension Classifiers
    id = 591
    authors = Boser_B Guyon_I Vapnik_V 
    1 (0.27208): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.15817): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.11261): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    11 (0.07355): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.02474): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    12 (0.01497): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

353: A Neural Network for Real-Time Signal Processing
    id = 215
    authors = Malkoff_D 
    21 (0.31764): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    19 (0.12237): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    15 (0.09959): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.06705): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.04101): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    41 (0.02148): 21 problem  (0.16446) 7 figure  (0.13864) 2 model  (0.09990) 16 error  (0.08699) 17 state  (0.07408) 24 performance  (0.07408) 14 number  (0.06117) 10 networks  (0.03535) 3 neural  (0.03535) 12 algorithm  (0.02244)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    18 (0.00847): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

354: Learning Control Under Extreme Uncertainty
    id = 613
    authors = Gullapalli_V 
    3 (0.22977): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.10935): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    1 (0.09959): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.08983): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    11 (0.07681): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    9 (0.03450): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.03125): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    36 (0.01823): 15 system  (0.22042) 19 units  (0.12720) 18 results  (0.06266) 14 number  (0.06266) 7 figure  (0.05549) 3 neural  (0.05549) 10 networks  (0.05549) 4 input  (0.04832) 23 hidden  (0.04832) 5 data  (0.03398)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    26 (0.00521): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)

355: Analyzing Cross-Connected Networks
    id = 839
    authors = Elman_J Shultz_T 
    14 (0.38598): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    13 (0.18421): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    10 (0.04752): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    16 (0.02474): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    24 (0.02148): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

356: Maximum Likelihood Competitive Learning
    id = 254
    authors = Nowlan_S 
    4 (0.19072): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.17770): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    12 (0.13539): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.07355): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    19 (0.03776): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    8 (0.03450): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.02474): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.01823): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

357: Neural Network Exploration Using Optimal Experiment Design
    id = 785
    authors = Cohn_D 
    5 (0.20373): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.19072): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.18746): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    14 (0.07030): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    10 (0.02148): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

358: Oscillatory Model of Short Term Memory
    id = 444
    authors = Horn_D Usher_M 
    3 (0.24279): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    5 (0.20048): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.10284): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.06705): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    14 (0.04752): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    22 (0.02148): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

359: HARMONET: A Neural Net for Harmonizing Chorales in the Style of J.S. Bach
    id = 461
    authors = Feulner_J Hild_H Menzel_W 
    1 (0.14515): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.12563): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.12237): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.11912): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    16 (0.08657): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    5 (0.05728): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    4 (0.02148): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

360: Rule Induction through Integrated Symbolic and Subsymbolic Processing
    id = 547
    authors = McMillan_C Mozer_M Smolensky_P 
    8 (0.21024): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.16468): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.14841): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.08983): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.04101): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.02148): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

361: Generalization and Scaling in Reinforcement Learning
    id = 251
    authors = Ackley_D Littman_M 
    1 (0.22326): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.15166): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.14841): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.09959): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    10 (0.05077): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

362: LEARNING WITH PREKNOWLEDGE: CLUSTERING WITH FOINT AND GRAPH MATCHING DISTANCE MEASURES
    id = 932
    authors = Gold_S Mjolsness_E Rangarajan_A 
    9 (0.22326): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    13 (0.17444): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.17444): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.09634): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

363: Generalization Error and the Expected Network Complexity
    id = 746
    authors = Ji_C 
    3 (0.24930): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.22326): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.14515): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    22 (0.02148): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    5 (0.01497): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

364: Simulation of Optimal Movements Using the Minimum-Muscle-Tension-Change Model
    id = 505
    authors = Dornay_M Kawato_M Suzuki_R Uno_Y 
    4 (0.24279): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.15817): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.15492): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.09308): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    22 (0.02148): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

365: Note on Learning Rate Schedules for Stochastic Optimization .
    id = 398
    authors = Darken_C Moody_J 
    12 (0.23628): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.13539): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.10935): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.07681): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.05728): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.05077): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    18 (0.01497): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

366: A Recurrent Neural Network for Generation of Occular Saccades
    id = 697
    authors = Massone_L 
    12 (0.17770): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    5 (0.17119): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    3 (0.15492): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.14841): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    28 (0.02148): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

367: A COMPUTATIONAL MODEL OF PREFRONTAL CORTEX FUNCTION
    id = 861
    authors = Braver_T Cohen_J Servan-Schreiber_D 
    5 (0.22651): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    15 (0.13213): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    0 (0.13213): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    11 (0.04752): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    13 (0.03776): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.03450): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.02799): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.02474): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    12 (0.02148): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    19 (0.01823): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

368: REINFORCEMENT LEARNING PREDICTS THE SITE OF PLASTICITY FOR AUDITORY REMAPPING IN THE BARN OWL
    id = 859
    authors = Deffayet_C Pouget_A Sejnowski_T 
    19 (0.42504): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    34 (0.10284): 23 hidden  (0.09126) 4 input  (0.09126) 11 training  (0.08546) 19 units  (0.07966) 8 time  (0.07386) 22 models  (0.06227) 21 problem  (0.06227) 20 information  (0.05647) 24 performance  (0.05067) 16 error  (0.04487)
    7 (0.07355): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.04101): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.01823): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

369: The Cocktail Party Problem: Speech/Data Signal Separation Comparison between Backpropagation and SONN
    id = 250
    authors = Kassebaum_J Schaefers_C Tenorio_M 
    2 (0.19397): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.18095): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.12888): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.10610): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    17 (0.05403): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

370: CORRELATION AND INTERPOLATION NETWORKS FOR REAL-TIME EXPRESSION ANALYSIS/SYNTHESIS
    id = 956
    authors = Darrell_T Essa_I Pentland_A 
    11 (0.23953): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    17 (0.15492): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    8 (0.12237): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.06705): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.05403): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.03450): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

371: Computer Simulation of Oscillatory Behavior in Cerebral Cortical Networks
    id = 195
    authors = Bower_J Wilson_M 
    17 (0.28510): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    3 (0.10935): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.09634): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.06379): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.04101): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    7 (0.03450): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.02474): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    16 (0.01823): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)

372: Monte Carlo Matrix Inversion and Reinforcement Learning
    id = 786
    authors = Barto_A Duff_M 
    12 (0.20048): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    3 (0.18421): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.15492): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.07355): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    19 (0.05077): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

373: Scaling and Generalization in Neural Networks: A Case Study
    id = 108
    authors = Ahmad_S Tesauro_G 
    17 (0.29811): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    0 (0.13539): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.10284): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.07355): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.03776): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    9 (0.03125): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

374: Optimal Brain Damage
    id = 257
    authors = Denker_J LeCun_Y Solla_S 
    2 (0.36320): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.19722): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    14 (0.05077): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.03776): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.01823): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

375: Studies of a Model for the Development and Regeneration of Eye-Brain Maps
    id = 286
    authors = Cowen_J Friedman_A 
    2 (0.31439): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.13539): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    9 (0.12563): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    15 (0.04426): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    19 (0.01823): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    7 (0.01497): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    26 (0.01172): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    23 (0.01172): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)

376: Adaptive Range Coding .
    id = 351
    authors = Goodwin_J Rosen_B Vidal_J 
    10 (0.23302): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    5 (0.20048): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.15166): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.04752): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.02474): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    21 (0.00847): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

377: Asymptotic Convergence of Backpropagation: Numerical Experiments
    id = 258
    authors = Ahmad_S He_Y Tesauro_G 
    8 (0.33066): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.12563): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    20 (0.09308): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    1 (0.05403): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.04752): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    19 (0.03125): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

378: Bayesian Inference of Regular Grammar and Markov Source Models
    id = 232
    authors = Miller_M Smith_K 
    2 (0.23953): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.17444): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.12563): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    15 (0.08983): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    4 (0.01823): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    5 (0.01497): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

379: Learning to Categorize Objects Using Temporal Coherence
    id = 617
    authors = Becker_S 
    9 (0.29811): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    14 (0.14190): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    18 (0.09959): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    3 (0.08332): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.04101): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    27 (0.00847): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

380: ESTIMATING CONDITIONAL PROBABILITY DENSroES FOR PERIODIC VARIABLES
    id = 923
    authors = Bishop_C Legleye_C 
    3 (0.19722): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    15 (0.19072): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    18 (0.15492): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    9 (0.08006): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.03125): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    25 (0.02799): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    31 (0.00521): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)

381: Benchmarking Feed-Forward Neural Networks: Models and Measures
    id = 572
    authors = Hamey_L 
    4 (0.22651): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    9 (0.14841): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.14190): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.08332): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.05728): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    10 (0.01497): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

382: GLOVE-TALK II: MAPPING HAND GESTURES TO SPEECH USING NEURAL NETWORKS
    id = 948
    authors = Fels_S Hinton_G 
    28 (0.36971): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    0 (0.19722): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.06705): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.02474): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

383: Address Block Location with a Neural Net System
    id = 798
    authors = Cosatto_E Graf_H 
    2 (0.30137): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    17 (0.14190): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    1 (0.10935): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    30 (0.05728): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)
    21 (0.05077): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

384: Coupled Dynamics of Fast Neurons and Slow Interactions
    id = 756
    authors = Coolen_A Penney_R Sherrington_D 
    9 (0.30788): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.13864): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.08657): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    5 (0.08332): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.04101): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    15 (0.02148): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

385: PLASTICITY-MEDIATED COMPEIITIVE LEARNING
    id = 902
    authors = Schraudolph_N Sejnowski_T 
    12 (0.29486): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    11 (0.11912): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    8 (0.08983): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.06379): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.06054): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.04426): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

386: Optimal Brain Surgeon: Extensions and Performance Comparisons
    id = 733
    authors = Hassibi_B Stork_D Watanabe_T Wolff_G 
    14 (0.31439): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.11586): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    7 (0.08332): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.07355): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    25 (0.04752): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    16 (0.04101): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

387: 'Ensemble' Boltzmann Units have Collective Computational Properties like those of Hopfield and Tank Neurons
    id = 23
    authors = Derthick_M Tebelskis_J 
    20 (0.25580): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    3 (0.12563): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.11912): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.06379): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.04426): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    37 (0.04101): 8 time  (0.12266) 18 results  (0.11534) 14 number  (0.11534) 6 function  (0.09335) 7 figure  (0.06404) 17 state  (0.04938) 16 error  (0.04205) 23 hidden  (0.04205) 10 networks  (0.04205) 9 set  (0.03472)
    12 (0.03450): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

388: When Will a Genetic Algorithm Outperform Hill Climbing?
    id = 706
    authors = Forrest_S Holland_J Mitchell_M 
    16 (0.38598): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    2 (0.13539): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.06379): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    18 (0.03776): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    9 (0.02474): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    20 (0.01823): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    27 (0.01172): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    19 (0.00847): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)

389: Learning in Compositional Hierarchies: Inducing the Structure of Objects from Data
    id = 736
    authors = Utans_J 
    1 (0.19072): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.16793): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    10 (0.14841): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.13213): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.01497): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    32 (0.01172): 20 information  (0.10804) 9 set  (0.10804) 1 learning  (0.10804) 15 system  (0.09379) 19 units  (0.07953) 14 number  (0.07003) 10 networks  (0.06528) 22 models  (0.04627) 4 input  (0.04627) 17 state  (0.04152)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

390: Integrated Segmentation and Recognition of Hand-Printed Numerals .
    id = 361
    authors = Keeler_J Leow_W Rumelhart_D 
    14 (0.18095): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    0 (0.14515): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.13213): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.07030): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    19 (0.06054): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    7 (0.05077): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.03450): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    21 (0.00847): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

391: The Role of Activity in Synaptic Competition at the Neuromuscular Junction
    id = 997
    authors = Joseph_S Willshaw_D 
    2 (0.26557): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.15166): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.14190): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.09959): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

392: A Neural-Network Solution to the Concentrator Assignment Problem
    id = 80
    authors = Page_E Tagliarini_G 
    0 (0.28184): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.15817): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    22 (0.12237): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    6 (0.09959): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

393: Application of Neural Network Methodology to the Modelling of the Yield Strength in a Steel Rolling Plate Mill
    id = 514
    authors = Tsoi_A 
    10 (0.31764): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.16793): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    11 (0.06054): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    15 (0.04426): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    4 (0.04426): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.02799): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    21 (0.01497): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    24 (0.00847): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

394: GENERALIZATION IN REINFORCEMENT LEARNING: SAFELY APPROXIMATING THE VALUE FUNCTION
    id = 889
    authors = Boyan_J Moore_A 
    7 (0.23302): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    5 (0.22001): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.08657): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.06054): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    4 (0.04101): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    14 (0.03125): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    24 (0.01497): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

395: Connected Letter Recognition with a Multi-State Time Delay Neural Network
    id = 660
    authors = Hild_H Waibel_A 
    3 (0.25906): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.21675): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    11 (0.10610): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.05077): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    10 (0.01823): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    18 (0.01823): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    24 (0.01497): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    17 (0.00847): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

396: Correlational Strength and Computational Algebra of Synaptic Connections Between Neurons
    id = 28
    authors = Fetz_E 
    13 (0.23628): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    5 (0.22326): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.13213): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.05077): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.01823): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.01823): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

397: Neural Networks Structured for Control Application to Aircraft Landing .
    id = 341
    authors = Chauvin_Y Golden_R Henkle_V Schley_C 
    5 (0.25906): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    13 (0.23302): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    9 (0.08983): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.05077): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.03776): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    18 (0.00847): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

398: A Connectionist Learning Control Architecture for Navigation .
    id = 347
    authors = Bachrach_J 
    12 (0.21350): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    9 (0.16793): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.10935): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.08332): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    17 (0.05728): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    10 (0.03450): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)

399: VLSI Implementation of TInMANN .
    id = 428
    authors = Melton_M Phan_T Reeves_D VandenBout_D 
    9 (0.31439): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.18095): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.09959): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.07355): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

400: A Learning Analog Neural Network Chip with Continuous-Time Recurrent Dynamics
    id = 807
    authors = Cauwenberghs_G 
    10 (0.23628): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    12 (0.21675): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.12563): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.07355): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.01497): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

401: A Fast Stochastic Error-Descent Algorithm for Supervised Learning and Optimization
    id = 603
    authors = Cauwenberghs_G 
    0 (0.22001): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.20373): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.14841): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.07030): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.02799): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

402: Neural Network Star Pattern Recognition for Spacecraft Attitude Determination and Control
    id = 126
    authors = Alvelda_P SanMartin_A 
    3 (0.29811): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.09634): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.08006): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.07355): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    15 (0.04752): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    0 (0.04752): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.04426): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

403: An Optimization Network for Matrix Inversion
    id = 41
    authors = Jang_J Lee_S Shin_S 
    3 (0.32089): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.08983): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.08657): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    10 (0.07355): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    21 (0.07030): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)

404: On the Distribution of the Number of Local Minima of a Random Function on a Graph
    id = 273
    authors = Baldi_P Rinott_Y Stein_C 
    8 (0.24279): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.16793): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    18 (0.13539): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    0 (0.10284): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    44 (0.01172): 16 error  (0.13557) 3 neural  (0.12005) 11 training  (0.08903) 0 network  (0.07351) 4 input  (0.05800) 24 performance  (0.05800) 9 set  (0.04248) 5 data  (0.04248) 10 networks  (0.04248) 23 hidden  (0.02697)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    22 (0.00847): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

405: Neural Network Diagnosis of Avascular Necrosis from Magnetic Resonance Images
    id = 507
    authors = Christy_P Ehman_R Manduca_A 
    10 (0.21024): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.13539): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.11912): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    17 (0.08983): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    6 (0.08983): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    5 (0.01823): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

406: A MODEL OF THE NEURAL BASIS OF THE RAT'S SENSE OF DIRECTION
    id = 865
    authors = Knierim_J Kudrimoti_H McNaughton_B Skaggs_W 
    3 (0.18421): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    17 (0.15817): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    2 (0.07030): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.07030): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.06705): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.05077): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    16 (0.05077): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    6 (0.03450): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

407: CONNECTIONIST SPEAKER NORMALIZATION WITH GENERALIZED RESOURCE ALLOCATING NETWORKS
    id = 951
    authors = Furlanello_C Giuliani_D Trentin_E 
    4 (0.22651): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.15492): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.12888): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.11912): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.02799): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    62 (0.02474): 4 input  (0.11197) 9 set  (0.11197) 6 function  (0.07108) 10 networks  (0.07108) 8 time  (0.03019) 7 figure  (0.03019) 11 training  (0.03019) 0 network  (0.03019) 1 learning  (0.03019) 5 data  (0.03019)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

408: The Performance of Convex Set Projection Based Neural Networks
    id = 55
    authors = Atlas_L Marks_R Oh_S Ritcey_J 
    24 (0.31764): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    4 (0.13539): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.06054): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    5 (0.04752): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    2 (0.04101): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    15 (0.03450): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    12 (0.02799): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    44 (0.01497): 16 error  (0.13557) 3 neural  (0.12005) 11 training  (0.08903) 0 network  (0.07351) 4 input  (0.05800) 24 performance  (0.05800) 9 set  (0.04248) 5 data  (0.04248) 10 networks  (0.04248) 23 hidden  (0.02697)
    18 (0.01172): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)

409: Connecting to the Past
    id = 52
    authors = MacDonald_B 
    9 (0.17119): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    25 (0.14190): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    7 (0.13539): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    12 (0.08983): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    15 (0.07681): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.06379): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

410: A Novel Net that Learns Sequential Decision Process
    id = 78
    authors = Chen_H Lee_Y Sun_G 
    25 (0.22001): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    2 (0.20048): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    11 (0.11912): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    10 (0.03776): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    13 (0.03125): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.02148): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    9 (0.01823): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    21 (0.01497): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)

411: Scaling Properties of Coarse-Coded Symbol Memories
    id = 67
    authors = Rosenfeld_R Touretzky_D 
    16 (0.24604): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    2 (0.15492): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.13864): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.06705): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    7 (0.03776): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    10 (0.02148): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    25 (0.01823): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

412: Topography and Ocular Dominance with Positive Correlations
    id = 693
    authors = Goodhill_G 
    23 (0.23302): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    7 (0.11586): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    14 (0.09308): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.08006): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    11 (0.05403): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    9 (0.04426): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    15 (0.03125): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    5 (0.02799): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)

413: Analytic Solutions to the Formation of Feature-Analysing Cells of a Three-Layer Feedforward Visual Information Processing Neural Net
    id = 204
    authors = Tang_D 
    13 (0.18095): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    6 (0.13213): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    15 (0.11912): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    9 (0.09634): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.07681): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.05728): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

414: A Massively-Parallel SIMD Processor for Neural Network and Machine Vision Applications
    id = 805
    authors = Glover_M Miller_W 
    6 (0.23628): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.17119): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    10 (0.16143): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.09634): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

415: Learning with Temporal Derivatives in Pulse-Coded Neuronal Systems
    id = 112
    authors = Gluck_M Parker_D Reifsnider_E 
    1 (0.18746): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.16468): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    22 (0.14190): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    3 (0.07030): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.06379): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.03776): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    40 (0.02148): 5 data  (0.16090) 16 error  (0.08362) 12 algorithm  (0.08362) 18 results  (0.07503) 22 models  (0.06645) 15 system  (0.04927) 13 output  (0.04927) 21 problem  (0.04927) 0 network  (0.04927) 2 model  (0.04927)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

416: Navigating Through Temporal Difference .
    id = 348
    authors = Dayan_P 
    3 (0.34693): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.21675): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.08332): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.02148): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

417: Storing Covariance by the Associative Long-Term Potentiation and Depression of Synaptic Strengths in the Hippocampus
    id = 135
    authors = Sejnowski_T Stanton_P 
    2 (0.44782): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.08983): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.08657): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.03125): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.01823): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

418: Subgrouping Reduces Complexity and Speeds Up Learning in Recurrent Networks
    id = 262
    authors = Zipser_D 
    10 (0.21675): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    13 (0.16468): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    7 (0.15817): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.10935): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    41 (0.01172): 21 problem  (0.16446) 7 figure  (0.13864) 2 model  (0.09990) 16 error  (0.08699) 17 state  (0.07408) 24 performance  (0.07408) 14 number  (0.06117) 10 networks  (0.03535) 3 neural  (0.03535) 12 algorithm  (0.02244)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

419: On Stochastic Complexity and Admissible Models for Neural Network Classifiers
    id = 396
    authors = Smyth_P 
    3 (0.27533): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    15 (0.17444): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.08332): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.05077): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.03776): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.02474): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.02148): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    4 (0.01823): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)

420: PHASE-SPACE LEARNING
    id = 903
    authors = Cottrell_G Tsung_F 
    9 (0.29486): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    4 (0.20048): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.09308): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    29 (0.04752): 6 function  (0.17004) 11 training  (0.13338) 4 input  (0.08041) 1 learning  (0.08041) 18 results  (0.07227) 5 data  (0.07227) 16 error  (0.05190) 9 set  (0.05190) 8 time  (0.04375) 17 state  (0.03560)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

421: Dynamically-Adaptive Winner-Take-All Networks
    id = 470
    authors = Lange_T 
    5 (0.29160): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.27533): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.06054): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.02799): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

422: Convergence of Indirect Adaptive Asynchronous Value Iteration Algorithms
    id = 787
    authors = Barto_A Gullapalli_V 
    6 (0.15492): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    16 (0.11912): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    9 (0.11586): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.09308): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.06379): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.04752): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.03776): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    23 (0.02799): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    11 (0.02474): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    22 (0.01823): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

423: Qualitative Structure From Motion .
    id = 333
    authors = Weinshall_D 
    7 (0.26557): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.16143): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.16143): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.07030): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    63 (0.01172): 4 input  (0.11674) 8 time  (0.07411) 5 data  (0.07411) 16 error  (0.07411) 10 networks  (0.03147) 7 figure  (0.03147) 9 set  (0.03147) 11 training  (0.03147) 0 network  (0.03147) 1 learning  (0.03147)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

424: LEARNING IN LARGE LINEAR PERCEPTRONS AND WHY THE THERMODYNAMIC LIMIT IS RELEVANT TO THE REAL WORLD
    id = 869
    authors = Sollich_P 
    1 (0.29486): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    10 (0.17444): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.11586): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.06054): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    9 (0.02148): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

425: Mapping Between Neural and Physical Activities of the Lobster Gastric Mill
    id = 684
    authors = Boyle_M Doya_K Selverston_A 
    23 (0.30788): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    0 (0.24279): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.08983): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.03125): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

426: LEARNING DIRECTION IN GLOBAL MOTION: TWO CLASSES OF PSYCHOPHYSICAI J .Y-MOTIVATED MODELS
    id = 957
    authors = Sundareswaran_V Vaina_L 
    3 (0.22651): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.18746): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    47 (0.14190): 5 data  (0.09492) 12 algorithm  (0.07837) 9 set  (0.07837) 15 system  (0.07837) 6 function  (0.07837) 24 performance  (0.07837) 22 models  (0.06183) 10 networks  (0.06183) 17 state  (0.06183) 4 input  (0.04529)
    6 (0.04426): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.02474): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    11 (0.02474): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    15 (0.01823): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    2 (0.01823): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

427: Learning Unambiguous Reduced Sequence Descriptions
    id = 464
    authors = Schmidhuber_J 
    14 (0.24930): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.17770): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    9 (0.13864): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    18 (0.04752): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    5 (0.03125): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    2 (0.03125): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

428: Centric Models of the Orientation Map in Primary Visual Cortex
    id = 6
    authors = Baxter_W Dow_B 
    0 (0.17770): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.17119): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.11912): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    10 (0.10610): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    5 (0.06054): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.04101): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    21 (0.01172): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

429: Training Stochastic Model Recognition Algorithms as Networks can Lead to Maximum Mutual Information Estimation of Parameters
    id = 210
    authors = Bridle_J 
    13 (0.42504): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    7 (0.16143): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    14 (0.06054): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

430: A Model of Distributed Sensorimotor Control in The Cockroach Escape Turn . .
    id = 354
    authors = Beer_R Chiel_H Kacmarcik_G Ritzmann_R 
    5 (0.21024): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    8 (0.15166): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.12888): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    14 (0.05728): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.05403): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    3 (0.03776): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.03125): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    15 (0.01497): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

431: Neurally Inspired Plasticity in Oculomotor Processes
    id = 220
    authors = Viola_P 
    2 (0.31439): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    25 (0.16793): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    22 (0.13213): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    11 (0.02148): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

432: EFFICIENT METHODS FOR DEALING WITH MISSING DATA IN SUPERVISED LEARNING
    id = 929
    authors = Ahmad_S Neuneier_R Tresp_V 
    8 (0.28184): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.12237): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.09959): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.08332): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    16 (0.05403): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    7 (0.04101): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

433: High Density Associative Memories
    id = 21
    authors = Dembo_A Zeitouni_O 
    7 (0.24930): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    11 (0.23628): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    18 (0.09959): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    1 (0.06705): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    25 (0.01497): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

434: Rational Parameterizations of Neural Networks
    id = 649
    authors = Helmke_U Williamson_R 
    2 (0.37297): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.12563): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    11 (0.10935): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.04752): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

435: Improving Convergence in Hierarchical Matching Networks for Object Recognition
    id = 622
    authors = Gindi_G Utans_J 
    3 (0.15166): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.13213): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.13213): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    1 (0.09959): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    30 (0.07355): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)
    9 (0.06054): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.03450): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

436: Adaptive Elastic Models for Hand-Printed Character Recognition
    id = 491
    authors = Hinton_G Revow_M Williams_C 
    1 (0.37297): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    11 (0.16143): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.06705): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    9 (0.06054): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

437: NONLINEAR IMAGE INTERPOLATION USING MANIFOLD LEARNING
    id = 964
    authors = Bregler_C Omohundro_S 
    8 (0.16468): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.13864): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    15 (0.11912): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    0 (0.10610): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.09959): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.05403): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

438: Multimodular Architecture for Remote Sensing Options
    id = 511
    authors = Badran_F Crepon_M Mejia_C Thiria_S 
    3 (0.24279): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    15 (0.19397): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.15492): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.06054): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

439: Hierarchical Learning Control--An Approach with Neuron-Like Associative Memories
    id = 26
    authors = Ersu_E Tolle_H 
    11 (0.31439): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.12888): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.10935): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.08983): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.02474): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

440: Shooting Craps in Search of an Optimal Strategy for Training Connectionist Pattern Classifiers
    id = 567
    authors = Hampshire_J Kumar_B 
    0 (0.24279): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    18 (0.23302): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    2 (0.13539): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.03776): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    21 (0.01823): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

441: Learning the Structure of Similarity
    id = 984
    authors = Tenenbaum_J 
    0 (0.19397): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.17119): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.16468): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    15 (0.09308): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.04752): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

442: A Competitive Modular Connectionist Architecture .
    id = 389
    authors = Jacobs_R Jordan_M 
    10 (0.19722): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.16793): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.14515): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.13213): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.02474): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

443: Combining Visual and Acoustic Speech Signals with a Neural Network Improves Intelligibility
    id = 213
    authors = Goldstein_M Jenkins_R Sejnowski_T Yuhas_B 
    0 (0.23628): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.15492): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    24 (0.13864): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    15 (0.05403): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    2 (0.05403): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.01497): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

444: Distributed Neural Information Processing in the Vestibulo-Ocular System
    id = 47
    authors = Honrubia_V Lau_C 
    11 (0.37622): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.12888): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.06054): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.05728): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.02799): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    16 (0.01823): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    15 (0.01497): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

445: Hierarchical Transformation of Space in the Visual System
    id = 479
    authors = Fisher_S Pouget_A Sejnowski_T 
    3 (0.29486): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.19722): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.13864): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    14 (0.03776): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

446: Digital Boltzmann VLSI for Constraint Satisfaction and Learning
    id = 812
    authors = Boonyanit_K Burr_J Kritayakirana_K Leung_M Murray_M Peterson_A Schwartz_E Stork_D Watanabe_T Wolff_G 
    23 (0.29160): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    8 (0.15492): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    7 (0.08983): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    10 (0.06379): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    18 (0.04752): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    4 (0.02474): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

447: Classification of Electroencephalogram Using Artificial Neural Networks
    id = 843
    authors = Sergejew_A So_D Tsoi_A 
    15 (0.32740): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    4 (0.17770): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    9 (0.09959): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    14 (0.03125): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    2 (0.01823): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    31 (0.00847): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

448: Reflexive Associative Memories
    id = 51
    authors = Loos_H 
    3 (0.25906): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    18 (0.20048): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    5 (0.10284): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.04752): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    8 (0.04426): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.01497): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

449: Continuous Speech Recognition by Linked Predictive Neural Networks .
    id = 312
    authors = Petek_B Schmidbauer_O Tebelskis_J Waibel_A 
    16 (0.24604): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    6 (0.14515): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    7 (0.12237): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    26 (0.10610): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    0 (0.02799): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    19 (0.02799): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    18 (0.01172): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

450: How Neural Nets Work
    id = 46
    authors = Farber_R Lapedes_A 
    6 (0.23953): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    24 (0.09959): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    1 (0.08983): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.08332): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    3 (0.06379): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.04426): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.04101): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    25 (0.01823): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    15 (0.01497): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)

451: Coupled Markov Random Fields and Mean Field Theory
    id = 265
    authors = Geiger_D Girosi_F 
    28 (0.37947): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    9 (0.14841): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.08983): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.02799): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.01823): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

452: Against Edges: Function Approximation with Multiple Support Maps
    id = 476
    authors = Darrell_T Pentland_A 
    0 (0.23302): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.21024): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.11586): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    14 (0.08006): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    15 (0.03125): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    20 (0.00847): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

453: Dual Inhibitory Mechanisms for Definition of Receptive Field Characteristics in a Cat Striate Cortex
    id = 438
    authors = Bonds_A 
    11 (0.29486): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.10610): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.07030): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    14 (0.06705): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.05728): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    26 (0.05077): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    20 (0.02474): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    15 (0.02148): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

454: Designing Application-Specific Neural Networks Using the Genetic Algorithm
    id = 239
    authors = Guha_A Harp_S Samad_T 
    5 (0.31439): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.11586): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    15 (0.10935): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    14 (0.05077): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    3 (0.04752): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    17 (0.02474): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    19 (0.00847): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

455: Attractor Neural Networks with Local Inhibition: from Statistical Physics to a Digital Programmable Integrated Circuit
    id = 671
    authors = Pasero_E Zecchina_R 
    0 (0.21024): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.13864): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.11586): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.08006): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.06705): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    14 (0.05077): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    4 (0.02474): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

456: Dynamic Behavior of Constrained Back-Propagation Networks
    id = 263
    authors = Chauvin_Y 
    2 (0.15492): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    36 (0.13539): 15 system  (0.22042) 19 units  (0.12720) 18 results  (0.06266) 14 number  (0.06266) 7 figure  (0.05549) 3 neural  (0.05549) 10 networks  (0.05549) 4 input  (0.04832) 23 hidden  (0.04832) 5 data  (0.03398)
    4 (0.09959): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    9 (0.08983): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    15 (0.08657): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    7 (0.04426): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    21 (0.03450): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.02799): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    6 (0.02474): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

457: Using Prior Knowledge in a NNDPA to Learn Context-Free Languages
    id = 581
    authors = Das_S Giles_C Sun_G 
    5 (0.21350): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    4 (0.20048): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.08657): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    18 (0.08006): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    2 (0.07355): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.01823): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

458: A Large-Scale Neural Network Which Recognizes Handwritten Kanji Characters
    id = 235
    authors = Joe_K Mori_Y 
    2 (0.24930): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.11586): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    21 (0.10935): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    14 (0.10610): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    31 (0.05077): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    6 (0.03450): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

459: Spoken Letter Recognition .
    id = 315
    authors = Cole_R Fanty_M 
    10 (0.31439): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    4 (0.21024): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.11261): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    17 (0.02799): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

460: Linear Learning: Landscapes and Algorithms
    id = 97
    authors = Baldi_P 
    10 (0.23302): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    13 (0.20699): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.09634): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    19 (0.08006): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    14 (0.04101): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    4 (0.01823): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

461: GENERALISATION IN FEEDFORWARD NETWORKS
    id = 870
    authors = Ferra_H Kowalczyk_A 
    17 (0.19072): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    40 (0.16793): 5 data  (0.16090) 16 error  (0.08362) 12 algorithm  (0.08362) 18 results  (0.07503) 22 models  (0.06645) 15 system  (0.04927) 13 output  (0.04927) 21 problem  (0.04927) 0 network  (0.04927) 2 model  (0.04927)
    10 (0.13213): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    19 (0.09308): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    15 (0.04752): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    31 (0.04752): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

462: Information, Prediction, and Query by Committee
    id = 632
    authors = Freund_Y Seung_H Shamir_E Tishby_N 
    17 (0.19397): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    1 (0.19072): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.13213): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.08983): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.04101): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    5 (0.01497): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    14 (0.01497): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    41 (0.01172): 21 problem  (0.16446) 7 figure  (0.13864) 2 model  (0.09990) 16 error  (0.08699) 17 state  (0.07408) 24 performance  (0.07408) 14 number  (0.06117) 10 networks  (0.03535) 3 neural  (0.03535) 12 algorithm  (0.02244)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

463: A Contrast Sensitive Silicon Retina with Reciprocal Synapses
    id = 522
    authors = Andreou_A Boahen_K 
    1 (0.20048): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    21 (0.12888): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    4 (0.10610): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    13 (0.07681): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    56 (0.05403): 13 output  (0.17152) 4 input  (0.11174) 8 time  (0.08185) 9 set  (0.05196) 2 model  (0.05196) 24 performance  (0.05196) 20 information  (0.05196) 23 hidden  (0.05196) 6 function  (0.02207) 5 data  (0.02207)
    0 (0.04426): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.03776): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    27 (0.03450): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

464: Deriving Receptive Fields Using an Optimal Encoding Criterion
    id = 689
    authors = Linsker_R 
    4 (0.31439): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.12888): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.12237): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.07355): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    2 (0.03125): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

465: Connectionist Architectures for Multi-Speaker Phoneme Recognition
    id = 209
    authors = Hampshire_J Waibel_A 
    0 (0.28835): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.15492): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.13213): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.06379): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    22 (0.01823): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

466: Learning Cellular Automaton Dynamics with Neural Networks
    id = 650
    authors = Hertz_J Wulff_N 
    9 (0.15492): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.14190): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    14 (0.11261): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.09634): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    15 (0.08332): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.07355): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    20 (0.01497): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    19 (0.01172): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

467: Neural Network Simulation of Somatosensory Representational Plasticity
    id = 191
    authors = Grajski_K Merzenich_M 
    12 (0.18746): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.18421): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    9 (0.13864): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.08657): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    10 (0.04752): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    5 (0.03450): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

468: Fast Learning with Predictive Forward Models
    id = 497
    authors = Brody_C 
    32 (0.24604): 20 information  (0.10804) 9 set  (0.10804) 1 learning  (0.10804) 15 system  (0.09379) 19 units  (0.07953) 14 number  (0.07003) 10 networks  (0.06528) 22 models  (0.04627) 4 input  (0.04627) 17 state  (0.04152)
    0 (0.16793): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.09959): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.08983): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    21 (0.03776): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    2 (0.03125): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    22 (0.01172): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

469: Propagation Filters in PDS Networks for Sequencing and Ambiguity Resolution
    id = 457
    authors = Dyer_M Sumida_R 
    19 (0.17770): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    2 (0.13539): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.11912): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.09634): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    14 (0.07681): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.03776): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.02799): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

470: Two Iterative Algorithms for Computing the Singular Value Decomposition from Input/Output Samples
    id = 718
    authors = Sanger_T 
    3 (0.22977): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    14 (0.15492): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    1 (0.12563): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.08006): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.05728): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    26 (0.02148): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    5 (0.01497): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

471: Hoo Optimality Criteria for LMS and Backpropagation
    id = 744
    authors = Hassibi_B Kailath_T Sayed_A 
    26 (0.20048): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    1 (0.13213): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.11912): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.09634): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.09634): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    22 (0.02474): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.01497): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

472: Using Aperiodic Reinforcement for Directed Self-Organization During Development
    id = 691
    authors = Dayan_P Montague_P Nowlan_S Pouget_A Sejnowski_T 
    4 (0.21024): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.14841): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.14190): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    10 (0.12563): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    9 (0.03125): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    19 (0.00847): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

473: How to Describe Neuronal Activity: Spikes, Rates, or Assemblies?
    id = 758
    authors = Gerstner_W vanHemmen_J 
    5 (0.33066): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    18 (0.25580): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    4 (0.02474): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    15 (0.02474): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.02148): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

474: Applications of Error Back-Propagation to Phonetic Classification
    id = 113
    authors = Leung_H Zue_V 
    2 (0.31439): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.29811): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    17 (0.05077): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    31 (0.00521): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

475: Dynamic Modulation of Neurons and Networks
    id = 764
    authors = Marder_E 
    23 (0.22326): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    10 (0.19397): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.14190): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    18 (0.05728): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    1 (0.03776): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    21 (0.02474): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    31 (0.00521): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

476: Stereopsis by a Neural Network Which Learns the Constraints .
    id = 329
    authors = Khotanzad_A Lee_Y 
    10 (0.23302): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    15 (0.20048): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    0 (0.15166): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.06379): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    11 (0.02474): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

477: Sequential Adaptation of Radial Basis Function Neural Networks ..
    id = 383
    authors = Fallside_F Kadirkamanathan_V Niranjan_M 
    7 (0.31764): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.20048): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.11586): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    11 (0.02148): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    4 (0.01823): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

478: THE USE OF DYNAMIC WRITING INFORMATION IN A CONNECTIONIST ON-LINE CURSIVE HANDWRITING RECOGNITION SYSTEM
    id = 979
    authors = Finke_M Manke_S Waibel_A 
    0 (0.22651): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    14 (0.18746): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    20 (0.11261): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    8 (0.06705): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.06379): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    17 (0.01823): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

479: An Electronic Photoreceptor Sensitive to Small Changes in Intensity
    id = 173
    authors = Delbruck_T Mead_C 
    33 (0.22326): 0 network  (0.09122) 11 training  (0.08608) 14 number  (0.07065) 16 error  (0.07065) 3 neural  (0.06036) 12 algorithm  (0.06036) 17 state  (0.05522) 24 performance  (0.05522) 2 model  (0.05008) 18 results  (0.05008)
    16 (0.20699): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    14 (0.09959): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    26 (0.09634): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    4 (0.02474): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    1 (0.02474): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

480: A CRITICAL COMPARISON OF MODELS FOR ORIENTATION AND OCULAR DOMINANCE COLUMNS IN THE STRIATE CORTEX
    id = 855
    authors = Erwin_E Obermayer_K Schulten_K 
    3 (0.34042): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.14515): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.07030): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.05403): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    16 (0.03125): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    7 (0.02799): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    10 (0.01497): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

481: AN AUD1TORY LOCALIZATION AND COORDINATE TRANSFORM CHIP
    id = 941
    authors = Horiuchi_T 
    8 (0.45107): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.07681): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.07355): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.06705): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

482: TRANSFORMATION INVARIANT AUTOASSOCIATION WITH APPLICATION TO HANDWRrITEN CHARACTER RECOGNITION
    id = 966
    authors = Milgram_M Schwenk_H 
    16 (0.25580): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    11 (0.21350): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    21 (0.18421): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)

483: Physiologically Based Speech Synthesis
    id = 653
    authors = Hirayama_M Honda_K Kawato_M Kioke_Y Vatikiotis-Bateson_E 
    3 (0.20373): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.17444): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.15166): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.04426): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.04426): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    18 (0.03450): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    2 (0.02799): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

484: Interpretation of Artificial Neural Networks: Mapping Knowledge-Based Neural Networks into Rules
    id = 548
    authors = Shavlik_J Towell_G 
    14 (0.15492): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.14515): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.09959): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.08006): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.07030): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.05403): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    18 (0.04101): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    11 (0.02148): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    15 (0.01497): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)

485: Neural Networks for Model Matching and Perceptual Organization
    id = 161
    authors = Anandan_P Gindi_G Mjolsness_E 
    8 (0.34693): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    19 (0.15817): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    2 (0.14190): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.02474): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

486: Unsupervised learning of distributions on binary vectors using 2- layer networks
    id = 540
    authors = Freund_Y Haussler_D 
    27 (0.24930): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    30 (0.17770): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)
    5 (0.05077): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.04101): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    10 (0.03776): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    13 (0.03450): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.03450): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    29 (0.03450): 6 function  (0.17004) 11 training  (0.13338) 4 input  (0.08041) 1 learning  (0.08041) 18 results  (0.07227) 5 data  (0.07227) 16 error  (0.05190) 9 set  (0.05190) 8 time  (0.04375) 17 state  (0.03560)
    0 (0.02799): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.01497): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)

487: Development and Regeneration of Eye-Brain Maps: A Computational Model .
    id = 196
    authors = Cowan_J Friedman_A 
    5 (0.33717): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.18095): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    15 (0.11586): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    28 (0.02474): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

488: Encoding Geometric Invariances in Higher-Order Neural Networks
    id = 32
    authors = Giles_C Griffin_R Maxwell_T 
    13 (0.21350): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.16143): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.15166): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.09308): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.02799): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    15 (0.02474): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    22 (0.01497): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

489: Practical Issues in Temporal Difference Learning
    id = 460
    authors = Tesauro_G 
    11 (0.29811): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    7 (0.27208): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    5 (0.06054): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.01823): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

490: The Effects of Circuit Integration on a Feature Map Vector Quantizer
    id = 212
    authors = Mann_J 
    6 (0.26231): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.15817): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.13864): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.09959): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    17 (0.00847): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

491: Invariant Object Recognition Using a Distributed Associative Memory
    id = 86
    authors = Wechsler_H Zimmerman_G 
    11 (0.30788): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.16143): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.16143): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.03125): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

492: Learning by Choice of Internal Representations
    id = 98
    authors = Domany_E Grossman_T Meir_R 
    0 (0.25580): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.20048): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.09308): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.05728): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    25 (0.05077): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    19 (0.00847): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

493: A Self-Organizing Integrated Segmentation and Recognition Neural Net
    id = 489
    authors = Keeler_J Rumelhart_D 
    3 (0.19722): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.19072): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    15 (0.13864): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    4 (0.12563): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    9 (0.02148): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

494: Optimal Sampling of Natural Images .
    id = 334
    authors = Bialek_W Ruderman_D Zee_A 
    2 (0.29486): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.15817): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    1 (0.09634): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.05403): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.02799): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.02474): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.01497): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

495: An Object-Oriented Framework for the Simulation of Neural Networks
    id = 670
    authors = Linden_A Sudbrak_T Tietz_C Weber_Weber 
    25 (0.13864): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    13 (0.12237): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.11912): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.10610): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.10284): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    11 (0.04101): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.02799): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.01823): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)

496: Using Hippocampal 'Place Cells' for Navigation, Exploiting Phase Coding
    id = 686
    authors = Burgess_N O'Keefe_J Recce_M 
    0 (0.33391): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.15492): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    6 (0.05728): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.03776): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    17 (0.03776): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    10 (0.03450): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.01823): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    27 (0.01497): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

497: Tangent Prop--A formalism for specifying selected invariances in an adaptive network
    id = 538
    authors = Denker_J LeCun_Y Simard_P Victorri_B 
    11 (0.52918): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    9 (0.10935): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.02799): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    17 (0.00521): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)

498: Simulations Suggest Information Processing Roles for the Diverse Currents in Hippocampal Neurons
    id = 8
    authors = Borg-Graham_L 
    5 (0.52267): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.10284): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.03125): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

499: A Dynamical Model of Context Dependencies for the Vestibulo-Ocular Reflex
    id = 996
    authors = Coenen_O Sejnowski_T 
    17 (0.27533): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    15 (0.24930): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    22 (0.03776): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    1 (0.03450): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.03450): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    5 (0.02474): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    19 (0.02148): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)

500: Training Knowledge-Based Neural Networks to Recognize Genes ..
    id = 357
    authors = Noordewier_M Shavlik_J Towell_G 
    12 (0.22977): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    5 (0.20699): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.15817): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.03125): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    16 (0.02799): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

501: Performance Through Consistency: MS-TDNN's for Large Vocabulary Continuous Speech Recognition
    id = 658
    authors = Tebelskis_J Waibel_A 
    4 (0.24279): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.21675): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    10 (0.07681): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    3 (0.07355): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.05403): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

502: Hoeffding Races: Accelerating Model Selection Search for Classification and Function Approximation
    id = 707
    authors = Maron_O Moore_A 
    4 (0.16793): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.15492): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.14190): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    30 (0.10610): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)
    7 (0.06054): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.02148): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.01823): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    17 (0.01497): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    22 (0.01172): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

503: CCD Neural Network Processors for Pattern Recognition
    id = 519
    authors = Chiang_A Chuang_M LaFranchise_J 
    7 (0.19722): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    14 (0.15166): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.13864): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.12563): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.03776): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

504: Extracting and Learning an Unknown Grammar with Recurrent Neural Networks
    id = 467
    authors = Chen_D Chen_H Giles_C Lee_Y Miller_C Sun_G 
    0 (0.29160): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    22 (0.13213): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    15 (0.12563): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    7 (0.05403): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.03776): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.02474): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.01823): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

505: SIMPLIFYING NEURAL NETS BY DISCOVERING FLAT MINIMA
    id = 909
    authors = Hochreiter_S Schmidhuber_J 
    12 (0.19072): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    15 (0.14841): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    11 (0.09634): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.08983): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.06054): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.04426): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.02799): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    6 (0.01823): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    19 (0.01172): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

506: Neural Network Application to Diagnostics ..
    id = 358
    authors = Marko_K 
    3 (0.19397): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    22 (0.14841): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    18 (0.12237): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    1 (0.10935): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    24 (0.05728): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    15 (0.01823): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    10 (0.01823): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)

507: Constructing Hidden Units Using Examples and Queries ..
    id = 408
    authors = Baum_E Lang_K 
    6 (0.24279): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    26 (0.17444): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    17 (0.11586): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    13 (0.10935): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    22 (0.01497): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    18 (0.00847): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

508: Assessing and Improving Neural Network Predictions by the Bootstrap Algorithm
    id = 597
    authors = Paass_G 
    6 (0.29160): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    19 (0.13539): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    7 (0.12563): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.07355): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.02148): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    5 (0.01497): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    8 (0.01497): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    21 (0.00847): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00847): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

509: Directional Hearing by the Mauthner System
    id = 772
    authors = Eaton_R Guzik_A 
    6 (0.20048): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    13 (0.12563): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    5 (0.12563): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.10610): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.06705): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    9 (0.02474): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    11 (0.01497): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)

510: An Analog VLSI Model of Adaptation in the Vestibulo-Ocular Reflex
    id = 275
    authors = DeWeerth_S Mead_C 
    9 (0.18746): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    17 (0.15817): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    3 (0.15492): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.11261): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.04752): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    16 (0.01823): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

511: Robust Parameter Estimation and Model Selection for Neural Network Regression
    id = 724
    authors = Liu_Y 
    3 (0.30137): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.13864): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    15 (0.13864): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.03776): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    16 (0.02474): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    20 (0.02148): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    14 (0.01497): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

512: Neural Network Visualization
    id = 241
    authors = Tesauro_G Wejchert_J 
    1 (0.26231): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.23628): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    18 (0.13539): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    7 (0.01497): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    22 (0.01172): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

513: Silicon Auditory Processors as Computer Peripherals
    id = 673
    authors = Gillespie_D Lazzaro_J Mahowald_M Sivilotti_M Wawrzynek_J 
    0 (0.20373): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.13864): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.09308): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.06705): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.06054): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.05077): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    20 (0.03450): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    9 (0.02799): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    11 (0.02148): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

514: Second Order Derivatives for Network Pruning: Optimal Brain Surgeon
    id = 593
    authors = Hassibi_B Stork_D 
    10 (0.21675): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    16 (0.12888): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    34 (0.12237): 23 hidden  (0.09126) 4 input  (0.09126) 11 training  (0.08546) 19 units  (0.07966) 8 time  (0.07386) 22 models  (0.06227) 21 problem  (0.06227) 20 information  (0.05647) 24 performance  (0.05067) 16 error  (0.04487)
    30 (0.11912): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)
    9 (0.02799): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.02799): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.02799): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.01497): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)

515: A Reinforcement Learning Variant for Control Scheduling ..
    id = 350
    authors = Guha_A 
    5 (0.30788): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    8 (0.15492): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.15492): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.05077): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

516: LEARNING MANY RELATED TASKS AT THE SAME TIME WITH BACKPROPAGATION
    id = 925
    authors = Camana_R 
    13 (0.54220): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    1 (0.09308): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.03125): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

517: Principled Architecture Selection for Neural Networks: Application to Corporate Bond Rating Prediction
    id = 512
    authors = Moody_J Utans_J 
    11 (0.22001): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    12 (0.17770): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    9 (0.10610): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.06705): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.04752): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.04426): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    17 (0.00847): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)

518: A Method for the Design of Stable Lateral Inhibition Networks that is Robust in the Presence of Circuit Parasitics
    id = 89
    authors = Standley_D Wyatt_J 
    14 (0.26231): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    10 (0.21024): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    5 (0.08983): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    4 (0.03776): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    13 (0.02474): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.01823): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    18 (0.01823): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    22 (0.01497): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)

519: Probability Estimation from a Database Using a Gibbs Energy Model
    id = 638
    authors = Goodman_R Miller_J 
    4 (0.35669): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.22001): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    10 (0.06705): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    6 (0.02474): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    28 (0.00847): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

520: Optimal Depth Neural Networks for Multiplication and Related Problems
    id = 580
    authors = Roychowdhury_V Siu_K 
    5 (0.43480): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    4 (0.09308): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    3 (0.08332): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.02474): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.02474): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    22 (0.01172): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

521: Towards Faster Stochastic Gradient Search
    id = 552
    authors = Darken_C Moody_J 
    0 (0.37622): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.11586): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.11261): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.05728): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    17 (0.01172): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

522: Constant-Time Loading of Shallow 1-Dimensional Networks
    id = 534
    authors = Judd_S 
    2 (0.26882): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.17770): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.12237): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    16 (0.06705): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    6 (0.02148): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    53 (0.01497): 14 number  (0.15506) 6 function  (0.10904) 8 time  (0.10904) 9 set  (0.08602) 23 hidden  (0.06301) 15 system  (0.06301) 21 problem  (0.04000) 7 figure  (0.04000) 1 learning  (0.04000) 5 data  (0.04000)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

523: Chaitin-Kolmogorov Complexity and Generalization in Neural Networks .
    id = 411
    authors = Pearlmutter_B Rosenfeld_R 
    12 (0.17119): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    14 (0.16143): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    4 (0.12237): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.11261): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.04752): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    18 (0.03125): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    8 (0.02148): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.01497): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)

524: Adjoint Operator Algorithms for Faster Learning in Dynamical Neural Networks
    id = 245
    authors = Barhen_J Gulati_S Toomarian_N 
    12 (0.23628): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    11 (0.20699): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.10610): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.06379): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.03125): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.01823): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    17 (0.01172): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

525: Acoustic-Imaging Computations by Echolocating Bats: Unification of Diversely-Represented Stimulus Features into Whole Images
    id = 185
    authors = Simmons_J 
    8 (0.26231): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.17770): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.15166): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.06379): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

526: Fool's Gold: Extracting Finite State Machines from Recurrent Network Dynamics
    id = 763
    authors = Kolen_J 
    24 (0.32089): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    14 (0.10610): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    3 (0.07681): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.06705): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.05403): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.05077): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

527: Learning Complex Boolean Functions: Algorithms and Applications
    id = 814
    authors = Oliveira_A Sangiovanni-Vincentelli_A 
    11 (0.21675): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    12 (0.15492): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.14841): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.13539): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

528: RECOGNIZING HANDWRITEN DIGITS USING MIXTURES OF LINEAR MODELS
    id = 969
    authors = Dayan_P Hinton_G Revow_M 
    9 (0.49338): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.06379): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.05077): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.03450): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

529: Bayesian Self-Organization
    id = 825
    authors = Smimakis_S Xu_L Yuille_A 
    19 (0.31764): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    12 (0.17770): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    5 (0.15166): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    17 (0.01172): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

530: The Clusteron: Toward a Simple Abstraction for a Complex Neuron
    id = 433
    authors = Mel_B 
    1 (0.26557): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.14515): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.10610): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.07681): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    9 (0.06054): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

531: Electronic Receptors for Tactile/Haptic Sensing
    id = 180
    authors = Andreou_A 
    1 (0.25255): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    27 (0.12237): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    3 (0.11586): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    5 (0.05728): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.04752): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.04752): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.03776): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

532: Analogy--Watershed or Waterloo? Structural Alignment and the Development of Connectionist Models of Cognition
    id = 677
    authors = Gentner_D Markman_A 
    8 (0.34042): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    11 (0.28510): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.02474): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    22 (0.01172): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    20 (0.00847): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

533: Discontinuous Generalization in Large Committee Machines
    id = 750
    authors = Hertz_J Schwarze_H 
    1 (0.28835): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.14515): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.12563): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.06054): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.04752): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    27 (0.01172): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

534: Speech Recognition Experiments with Perceptrons
    id = 14
    authors = Burr_D 
    1 (0.28835): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    16 (0.18095): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    4 (0.08657): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.05728): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.04426): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.02148): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

535: Feedback Synapse to Cone and Light Adaptation .
    id = 338
    authors = Skrzypek_J 
    6 (0.24279): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.10284): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.09308): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.07681): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    14 (0.06379): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    16 (0.06054): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    3 (0.03125): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.01497): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)

536: Network generalization for production: Learning and producing styled letterforms
    id = 566
    authors = Grebert_I Keesing_R Mims_S Stork_D 
    2 (0.33717): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    18 (0.21675): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    0 (0.08983): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    10 (0.02148): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

537: Learning on a General Network
    id = 2
    authors = Atiya_A 
    5 (0.36320): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    2 (0.12888): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.04752): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.04426): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.03776): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.03125): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.02148): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

538: Practical Characteristics of Neural Network and Conventional Pattern Classifiers on Artificial and Speech Problems
    id = 205
    authors = Lee_Y Lippmann_R 
    26 (0.37622): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    14 (0.15817): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    1 (0.06054): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.03776): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    18 (0.01497): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    30 (0.01497): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    19 (0.00847): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    31 (0.00521): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)

539: PCA-PYRAMIDS FOR IMAGE COMPRESSION
    id = 960
    authors = Bischof_H Hornik_K 
    11 (0.23953): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.21024): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.09634): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.08332): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    14 (0.02474): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

540: The Cascade-Correlation Learning Architecture
    id = 248
    authors = Fahlman_S Lebiere_C 
    4 (0.42178): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    1 (0.09308): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    11 (0.09308): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.03450): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    20 (0.03450): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

541: AN ANALOG NEURAL NETWORK INSPIRED BY FRACFAL BLOCK CODING
    id = 942
    authors = Andreou_A Pineda_F 
    0 (0.22326): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.15492): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.12888): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    49 (0.11912): 20 information  (0.18217) 6 function  (0.10734) 13 output  (0.10734) 4 input  (0.05122) 2 model  (0.05122) 17 state  (0.05122) 12 algorithm  (0.05122) 11 training  (0.05122) 1 learning  (0.05122) 21 problem  (0.03252)
    8 (0.03776): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

542: Non-Boltzmann Dynamics in Networks of Spiking Neurons
    id = 198
    authors = Bialek_W Crair_M 
    16 (0.50314): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    0 (0.07355): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.02799): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    15 (0.02474): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    2 (0.02474): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    28 (0.01172): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

543: Competitive Anti-Hebbian Learning of Invariants
    id = 553
    authors = Schraudolph_N Sejnowski_T 
    18 (0.39900): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    10 (0.10610): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    9 (0.09959): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    4 (0.02799): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.02474): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    37 (0.01497): 8 time  (0.12266) 18 results  (0.11534) 14 number  (0.11534) 6 function  (0.09335) 7 figure  (0.06404) 17 state  (0.04938) 16 error  (0.04205) 23 hidden  (0.04205) 10 networks  (0.04205) 9 set  (0.03472)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

544: Bounds on the Complexity of Recurrent Neural Network Implementations of Finite State Machines
    id = 745
    authors = Home_B Hush_D 
    0 (0.22977): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.21024): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.17119): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.04101): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.02148): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

545: Recognizing Hand-Printed Letters and Digits
    id = 234
    authors = Martin_G Pittman_J 
    3 (0.29811): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.28835): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    15 (0.04426): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    19 (0.04101): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

546: Feature Densities Are Required for Computing Feature Correspondences
    id = 820
    authors = Ahmad_S 
    2 (0.25255): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.16143): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.14841): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    25 (0.03776): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    1 (0.03776): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.02474): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    29 (0.01172): 6 function  (0.17004) 11 training  (0.13338) 4 input  (0.08041) 1 learning  (0.08041) 18 results  (0.07227) 5 data  (0.07227) 16 error  (0.05190) 9 set  (0.05190) 8 time  (0.04375) 17 state  (0.03560)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)

547: Generalization Dynamics in LMS Trained Linear Networks .
    id = 406
    authors = Chauvin_Y 
    9 (0.39249): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.22001): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.02799): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    14 (0.01497): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    11 (0.01497): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

548: Neuronal Maps for Sensory-Motor Control in the Barn Owl
    id = 132
    authors = Gelfand_J Pearson_J Peterson_R Spence_C Sullivan_W 
    15 (0.22326): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.18421): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.17119): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.03450): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.02799): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

549: A CONNECIIONIST TECHNIQUE FOR ACCELERATED TEXTUAL INPUT: LETTING A NETWORK DO THE TYPING
    id = 972
    authors = Pomerleau_D 
    2 (0.24604): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.22326): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    3 (0.07030): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    5 (0.04752): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.04101): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.02148): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    11 (0.01823): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    17 (0.00847): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

550: NON-LINEAR PREDICTION OF ACOUSTIC VECTORS USING HIERARCHICAL MIXTURES OF EXPERTS
    id = 947
    authors = Robinson_A Waterhouse_S 
    9 (0.20048): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.18095): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    10 (0.10610): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    4 (0.09959): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    19 (0.05403): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    3 (0.02148): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

551: Modeling Applications with the Focused Gamma Net
    id = 446
    authors = Kuo_J Principe_J de-Oliveira_P de-Vries_B 
    16 (0.24604): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    9 (0.18421): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.08657): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.08006): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.04426): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.03776): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

552: A STUDY OF PARALLEL PERTURBATIVE GRADIENT DESCENT
    id = 943
    authors = Alspector_J Lippe_D 
    1 (0.27208): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    17 (0.20699): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    2 (0.10284): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    14 (0.05403): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    0 (0.02474): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.02148): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

553: Mechanisms for Neuromodulation of Biological Neural Networks
    id = 187
    authors = Harris-Warrick_R 
    8 (0.24279): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    15 (0.17444): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    12 (0.10935): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.08983): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    19 (0.04426): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.01823): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

554: STOCHASTIC DYNAMICS OF THREE-STATE NEURAL NETWORKS
    id = 877
    authors = Cowan_J Ohira_T 
    15 (0.28510): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    14 (0.20373): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.08332): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.06705): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.03450): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

555: Improved Hidden Markov Model Speech Recognition Using Radial Basis Function Networks
    id = 448
    authors = Lippmann_R Singer_E 
    0 (0.20373): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.15166): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    13 (0.11912): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    1 (0.06379): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.05403): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.04101): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    26 (0.03125): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    2 (0.01823): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)

556: Analog Implementation of Shunting Neural Networks
    id = 170
    authors = Darling_R Nabet_B Pinter_R 
    4 (0.16143): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.15166): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.13539): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    29 (0.09634): 6 function  (0.17004) 11 training  (0.13338) 4 input  (0.08041) 1 learning  (0.08041) 18 results  (0.07227) 5 data  (0.07227) 16 error  (0.05190) 9 set  (0.05190) 8 time  (0.04375) 17 state  (0.03560)
    8 (0.08657): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.05077): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

557: Integration of Visual and Somatosensory Information for Preshaping Hand in Grasping Movements
    id = 611
    authors = Fukumura_N Kawato_M Suzuki_R Uno_Y 
    13 (0.29160): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.18421): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.12888): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.03125): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    5 (0.02148): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    15 (0.01823): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    17 (0.01172): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

558: An Analog VLSI Chip for Thin-Plate Surface Interpolation
    id = 169
    authors = Harris_J 
    6 (0.35995): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    17 (0.20699): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    8 (0.08657): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

559: Burst Synchronization without Frequency Locking in a Completely Solvable Network Model
    id = 443
    authors = Koch_C Schuster_H 
    12 (0.42829): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    11 (0.16143): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    25 (0.02474): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    7 (0.02148): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    21 (0.02148): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

560: LEARNING FROM QUERIES FOR MAXIMUM INFORMATION GAIN IN IMPERFECTLY LEARNABLE PROBLEMS
    id = 879
    authors = Saad_D Sollich_P 
    10 (0.49013): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    5 (0.08983): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.07355): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

561: Self-Organizing Rules for Robust Principal Component Analysis
    id = 630
    authors = Xu_L Yuille_A 
    7 (0.21675): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.19072): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.16793): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.04101): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    14 (0.02474): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    9 (0.02148): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

562: Self Organizing Neural Networks for the Identification Problem
    id = 96
    authors = Lee_W Tenorio_M 
    19 (0.28510): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    5 (0.13213): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.09308): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.06379): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.03125): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.02799): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    11 (0.02148): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    26 (0.02148): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    17 (0.02148): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

563: Discovering Structure from Motion in Monkey, Man and Machine
    id = 72
    authors = Siegel_R 
    11 (0.31113): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    7 (0.16468): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.08006): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    22 (0.04426): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    0 (0.03450): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.02148): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

564: Links Between Markov Models and Multilayer Percepttons
    id = 147
    authors = Bourlard_H Wellekens_C 
    9 (0.20373): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    12 (0.11261): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    4 (0.09959): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    21 (0.09634): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    7 (0.03776): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    19 (0.03776): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    1 (0.03776): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    15 (0.03125): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    16 (0.03125): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)

565: Learning Trajectory and Force Control of an Artifidal Muscle Arm .
    id = 344
    authors = Katayama_M Kawato_M 
    2 (0.28835): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.24604): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.06379): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.03450): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.02474): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    11 (0.02148): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

566: A Theory for Neural Networks with Time Delays
    id = 307
    authors = Principe_J de-Vries_B 
    1 (0.43806): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.21675): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

567: LEARNING SACCADIC EYE MOVEMENTS USING MULTISCALE SPATIAL FILTERS
    id = 954
    authors = Ballard_D Rao_R 
    21 (0.27859): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    0 (0.14515): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.14190): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.04426): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.04101): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    30 (0.02799): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

568: Optimal Neural Spike Classification
    id = 9
    authors = Atiya_A Bower_J 
    7 (0.12888): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    16 (0.12237): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    11 (0.09959): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.08983): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.07681): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.06379): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    12 (0.06054): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    48 (0.02474): 21 problem  (0.14210) 16 error  (0.08701) 2 model  (0.08701) 10 networks  (0.08701) 17 state  (0.06865) 11 training  (0.06865) 8 time  (0.06865) 9 set  (0.05028) 14 number  (0.05028) 3 neural  (0.05028)
    14 (0.01497): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    23 (0.01497): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

569: Performance Measures for Associative Memories that Learn and Forget
    id = 45
    authors = Kuh_A 
    3 (0.24604): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.09959): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    12 (0.07030): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    22 (0.07030): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    4 (0.05077): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    19 (0.05077): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    17 (0.03776): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    9 (0.02474): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    28 (0.02148): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)

570: Development and Spatial Structure of Cortical Feature Maps: A Model Study
    id = 287
    authors = Obermayer_K Ritter_H Schulten_K 
    0 (0.30788): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.14515): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.13213): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    21 (0.05728): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    6 (0.01823): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    5 (0.01497): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

571: UNSUPERVISED CLASSIFICATION OF 3D OBJECFS FROM 2D VIEWS
    id = 961
    authors = Ando_H Suzuki_S 
    12 (0.23302): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    3 (0.16793): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    5 (0.15166): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.06054): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.02148): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.01823): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    22 (0.01497): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    66 (0.00847): 15 system  (0.08934) 8 time  (0.03794) 7 figure  (0.03794) 6 function  (0.03794) 10 networks  (0.03794) 9 set  (0.03794) 11 training  (0.03794) 1 learning  (0.03794) 2 model  (0.03794) 0 network  (0.03794)

572: Neural Implementation of Motivated Behavior: Feeding in an Artificial Insect
    id = 190
    authors = Beer_R Chiel_H 
    14 (0.23628): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.15166): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.10610): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    15 (0.08657): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.05077): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    5 (0.02474): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    19 (0.01823): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    31 (0.00521): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

573: Cholinergic Modulation May Enhance Cortical Associative Memory Function . .
    id = 292
    authors = Anderson_B Bower_J Hasselmo_M 
    3 (0.17770): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.11586): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.10610): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.08332): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.07030): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    18 (0.05728): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    4 (0.04752): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    19 (0.02148): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    23 (0.01823): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

574: Generic Analog Neural Computation: The Epsilon Chip
    id = 667
    authors = Baxter_D Churcher_S Hamilton_A Murray_A Reekie_H 
    3 (0.39575): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.14841): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.11261): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

575: Lipreading by Neural Networks: Visual Preprocessing, Learning, and Sensory Integration
    id = 828
    authors = Hennecke_M Prasad_K Stork_D Wolff_G 
    1 (0.35995): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.08006): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.07355): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.06054): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.03776): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    10 (0.03125): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    7 (0.02799): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    20 (0.02148): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

576: VISUAL SPEECH RECOGNITION WITH STOCHASTIC NETWORKS
    id = 949
    authors = Movellan_J 
    11 (0.18095): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.15817): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.12563): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.10284): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    21 (0.06379): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    9 (0.04101): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

577: Induction of Multiscale Temporal Structure
    id = 462
    authors = Mozer_M 
    21 (0.23953): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    4 (0.21024): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.12237): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    7 (0.07355): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    15 (0.02148): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

578: A Model of Auditory Streaming
    id = 991
    authors = Denham_M McCabe_S 
    2 (0.28184): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    16 (0.18095): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    18 (0.09959): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    12 (0.07355): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    14 (0.02474): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

579: Segmental Neural Net Optimization for Continuous Speech Recognition
    id = 832
    authors = Makhoul_J Schwartz_R Zavaliagkos_G Zhao_Y 
    10 (0.28835): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.16143): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.14841): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    9 (0.02474): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.01823): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    19 (0.01497): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

580: The Tempo 2 Algorithm: Adjusting Time-Delays By Supervised Learning .
    id = 306
    authors = Bodenhausen_U Waibel_A 
    11 (0.27859): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.19397): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.18095): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

581: Performance of Synthetic Neural Network Classification of Noisy Radar Signals
    id = 122
    authors = Ahalt_S Garber_F Jouny_I Krishnamurthy_A 
    2 (0.32415): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.14841): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.11586): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    54 (0.06705): 14 number  (0.09980) 16 error  (0.09980) 1 learning  (0.09980) 17 state  (0.07311) 24 performance  (0.07311) 20 information  (0.07311) 6 function  (0.04641) 7 figure  (0.04641) 8 time  (0.04641) 18 results  (0.04641)
    22 (0.01823): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

582: Training a Limited-Interconnect, Synthetic Neural IC
    id = 179
    authors = Afghan_A Akers_L Haghighi_S Walker_M 
    18 (0.22977): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    20 (0.15492): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    12 (0.11912): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.07681): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    25 (0.06705): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    10 (0.02148): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    22 (0.00847): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    27 (0.00847): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)

583: Oriented Non-Radial Basis Functions for Image Coding and Analysis .
    id = 384
    authors = Christian_J Saha_A Tang_D Wu_C 
    9 (0.36646): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.13864): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.05728): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.05403): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    7 (0.05077): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

584: Transforming Neural-Net Output Levels to Probability Distributions .
    id = 401
    authors = Denker_J LeCun_Y 
    1 (0.22977): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.15492): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    20 (0.08006): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    16 (0.05077): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    19 (0.04752): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    6 (0.03776): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.03125): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    15 (0.02148): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    24 (0.01823): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    22 (0.01823): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

585: DYNAMIC CELL STRUCTURES
    id = 905
    authors = Bmske_JO Sommer_G 
    15 (0.36971): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    5 (0.14190): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    3 (0.06379): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    16 (0.03776): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    4 (0.02474): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    18 (0.02474): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    8 (0.02148): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

586: Directional-Unit Boltzmann Machines
    id = 594
    authors = Mozer_M Williams_C Zemel_R 
    14 (0.22651): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    4 (0.16468): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    6 (0.11912): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    16 (0.11261): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    10 (0.04426): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

587: Comparison of Three Classification Techniques, CART, C4.5 and Multi-Layer Perceptrons ..
    id = 416
    authors = Pearson_R Tsoi_A 
    20 (0.41202): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    18 (0.09634): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    22 (0.07355): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    7 (0.06054): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    15 (0.03125): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

588: MODEL OF BIOLOGICAL NEURON AS A TEMPORAL NEURAL NETWORK
    id = 854
    authors = Kairiss_E Murphy_S 
    0 (0.14841): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.14190): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.13539): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    10 (0.08006): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    13 (0.06705): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    19 (0.03450): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    15 (0.02799): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    11 (0.02799): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

589: Automatic Local Annealing
    id = 159
    authors = Leinbach_J 
    1 (0.22977): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.20699): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.12888): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.07355): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.02799): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

590: GDS: Gradient Descent Generation of Symbolic Classification Rules
    id = 836
    authors = Blasig_R 
    12 (0.19722): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    5 (0.18746): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.11586): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.07030): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.04752): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.03776): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    19 (0.03125): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

591: An Analog VLSI Model of Central Pattern Generation in the Leech
    id = 778
    authors = Siegel_M 
    11 (0.29160): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.27859): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.05077): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    27 (0.03776): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    5 (0.01497): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

592: Efficient Parallel Learning Algorithms for Neural Networks
    id = 94
    authors = Kramer_A Sangiovanni-Vincentelli_A 
    16 (0.22977): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    25 (0.12237): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    18 (0.09959): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    13 (0.07681): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    1 (0.07681): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.06054): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    9 (0.01823): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

593: Winner-Take-All Networks of O(N) Complexity
    id = 171
    authors = Lazzaro_J Mahowald_M Mead_C Ryckebusch_S 
    16 (0.24930): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    9 (0.14841): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.11912): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    10 (0.09959): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.05403): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    17 (0.01172): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

594: A Model of Neural Oscillator for a Unified Submodule
    id = 154
    authors = Borisyuk_G Borisyuk_R Chulaevsky_V Kirillov_A Kovalenko_Y Kryukov_V Makarenko_V 
    1 (0.29160): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    17 (0.10284): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    15 (0.09308): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    7 (0.08657): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.03776): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.02799): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.02148): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    19 (0.01172): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

595: Summed Weight Neuron Perturbation: An O(N) Improvement Over Weight Perturbation
    id = 599
    authors = Flower_B Jabri_M 
    0 (0.18746): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.17444): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    11 (0.13539): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    20 (0.10284): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    5 (0.04426): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    13 (0.02148): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.01823): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

596: Neural Network Routing for Random Multistage Interconnection Networks
    id = 517
    authors = Giles_C Goudreau_M 
    3 (0.29160): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    14 (0.18746): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    22 (0.08006): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    10 (0.07681): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.03125): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

597: Optimal Signalling in Attractor Neural Networks
    id = 761
    authors = Meilijson_I Ruppin_E 
    5 (0.25255): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    10 (0.23953): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.11586): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    18 (0.06054): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    31 (0.00521): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    30 (0.00521): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

598: HIGHER ORDER STATISTICAL DECORRELATION WITHOUT INFORMATION LOSS
    id = 874
    authors = Brauer_W Deco_G 
    4 (0.23302): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    6 (0.15492): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    7 (0.13864): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.08657): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    15 (0.03776): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    13 (0.02474): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

599: Efficient Design of Boltzmann Machines .
    id = 397
    authors = Gupta_A Maass_W 
    0 (0.20699): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.19722): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.13213): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    6 (0.10284): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

600: Synchronization in Neural Nets
    id = 85
    authors = Haggerty_J Vidal_J 
    15 (0.16143): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    0 (0.15817): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.14190): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.13864): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.06705): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    17 (0.00847): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

601: Skeletonization: A Technique for Trimming the Fat from a Network via Relevance Assessment
    id = 102
    authors = Mozer_M Smolensky_P 
    27 (0.36320): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    8 (0.12563): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    19 (0.10610): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    1 (0.06379): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    22 (0.00847): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    17 (0.00847): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    30 (0.00521): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)

602: Some Solutions to the Missing Feature Problem in Vision
    id = 621
    authors = Ahmad_S Tresp_V 
    9 (0.27859): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.11261): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.08006): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.07030): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    5 (0.06054): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    28 (0.03450): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    22 (0.03450): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    17 (0.01497): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)

603: Efficient Pattern Recognition Using a New Transformation Distance
    id = 579
    authors = Cun_Y Denker_J Simard_P 
    1 (0.23302): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.08657): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    14 (0.08332): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    4 (0.08332): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.07355): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    11 (0.04752): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    13 (0.04752): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    6 (0.03450): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

604: A Neural Model of Descending Gain Control in the Electrosensory System
    id = 685
    authors = Nelson_M 
    6 (0.22326): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.21024): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.08006): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    10 (0.06705): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    15 (0.05403): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    5 (0.02148): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    41 (0.01172): 21 problem  (0.16446) 7 figure  (0.13864) 2 model  (0.09990) 16 error  (0.08699) 17 state  (0.07408) 24 performance  (0.07408) 14 number  (0.06117) 10 networks  (0.03535) 3 neural  (0.03535) 12 algorithm  (0.02244)
    25 (0.00847): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

605: Word Space
    id = 682
    authors = Schfitze_H 
    4 (0.22326): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    18 (0.21675): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    0 (0.11261): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    17 (0.08332): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    12 (0.02148): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

606: A Computational Model for Cursive Handwriting Based on the Minimization Principle
    id = 791
    authors = Kawato_M Koike_Y Vatikiotis-Bateson_E Wada_Y 
    20 (0.26557): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    3 (0.13539): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.11261): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.10610): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.05403): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

607: How to Choose an Activation Function
    id = 740
    authors = Mhaskar_H Micchelli_C 
    2 (0.17119): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.13864): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    6 (0.12563): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.09308): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.07681): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    55 (0.06054): 5 data  (0.33106) 12 algorithm  (0.10543) 17 state  (0.04903) 19 units  (0.04903) 2 model  (0.04903) 7 figure  (0.02082) 6 function  (0.02082) 9 set  (0.02082) 8 time  (0.02082) 10 networks  (0.02082)
    7 (0.01497): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    19 (0.01172): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

608: Learning to See Rotation and Dilation with a Hebb Rule .
    id = 328
    authors = Sereno_M 
    10 (0.25255): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    16 (0.20699): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    4 (0.18746): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    22 (0.01823): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

609: Translating Locative Prepositions .
    id = 367
    authors = Munro_P Tabasko_M 
    15 (0.20048): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.19397): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.17119): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.05728): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.02474): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    21 (0.00847): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)

610: Cycles: A Simulation Tool for Studying Cyclic Neural Networks
    id = 30
    authors = Gately_M 
    15 (0.22001): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.13213): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    14 (0.10610): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    3 (0.09308): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    16 (0.06379): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    0 (0.04752): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.02148): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

611: The Computation of Stereo Disparity for Transparent and for Opaque Surfaces
    id = 620
    authors = Kersten_D Madarasmi_S Pong_T 
    19 (0.32415): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    2 (0.22326): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.05728): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    13 (0.04426): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    18 (0.01823): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    11 (0.01497): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    30 (0.00521): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)
    31 (0.00521): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

612: Lg Depth Estimation and Ripple Fire Characterization ..
    id = 359
    authors = Baumgardt_D Perry_J 
    7 (0.26882): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.14515): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    16 (0.12237): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    10 (0.11912): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    3 (0.02148): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

613: Modeling Interactions of the Rat's Place and Head Direction Systems
    id = 992
    authors = Rexlish_A Touretzky_D 
    6 (0.26882): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    5 (0.26882): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.10284): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.02148): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    31 (0.00847): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

614: TEMPORAL DYNAMICS OF GENERALIZATION IN NEURAL NETWORKS
    id = 876
    authors = Venkatesh_S Wang_C 
    19 (0.26882): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    0 (0.16468): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.14190): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.04752): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    15 (0.02799): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    48 (0.01172): 21 problem  (0.14210) 16 error  (0.08701) 2 model  (0.08701) 10 networks  (0.08701) 17 state  (0.06865) 11 training  (0.06865) 8 time  (0.06865) 9 set  (0.05028) 14 number  (0.05028) 3 neural  (0.05028)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    18 (0.00847): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)

615: Direction Selective Silicon Retina that uses Null Inhibition
    id = 521
    authors = Benson_R Delbruck_T 
    15 (0.25906): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.14841): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.09308): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    19 (0.08332): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    3 (0.05077): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.02799): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    36 (0.02148): 15 system  (0.22042) 19 units  (0.12720) 18 results  (0.06266) 14 number  (0.06266) 7 figure  (0.05549) 3 neural  (0.05549) 10 networks  (0.05549) 4 input  (0.04832) 23 hidden  (0.04832) 5 data  (0.03398)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    31 (0.00521): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)

616: Recognition of Manipulated Objects by Motor Learning
    id = 495
    authors = Gomi_H Kawato_M 
    0 (0.23302): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.23302): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.08332): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    14 (0.05403): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    10 (0.03125): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    8 (0.02148): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.01823): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

617: Learning to Segment Images Using Dynamic Feature Binding
    id = 482
    authors = Behrmann_M Mozer_M Zemel_R 
    5 (0.34693): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    2 (0.12888): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.12888): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.06379): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

618: Stimulus Encoding By Multidimensional Receptive Fields in Single Cells and Cell Populations in V1 of Awake Monkey
    id = 619
    authors = Aertsen_A Hochstein_S Stern_E Vaadia_E 
    4 (0.21024): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    6 (0.19397): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.16143): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.07681): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    15 (0.01823): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

619: Evolution and Learning in Neural Networks ..
    id = 394
    authors = Keesing_R Stork_D 
    0 (0.30788): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    14 (0.30137): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.03450): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    17 (0.00847): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

620: Weight Space Probability Densities in Stochastic Learning: I. Dynamics and Equilibria
    id = 628
    authors = Leen_T Moody_J 
    4 (0.24930): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    15 (0.18746): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    10 (0.17444): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.04426): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

621: How the Catfish Tracks Its Prey: An Interactive 'Pipelined' Processing System May Direct Foraging via Reticulospinal Neurons
    id = 42
    authors = Kanwal_J 
    20 (0.51616): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    5 (0.10935): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    4 (0.02474): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    27 (0.00847): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

622: Perceiving Complex Visual Scenes: An Oscillator Neural Network Model that Integrates Selective Attention, Perceptual Organisation, and Invariant Recognition
    id = 683
    authors = Goebel_R 
    2 (0.19072): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.13864): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.11912): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.09308): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.07355): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.03776): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    21 (0.02474): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

623: Training Neural Networks with Deficient Data
    id = 716
    authors = Ahmad_S Neuneier_R Tresp_V 
    3 (0.21350): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.17119): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.10610): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    14 (0.07030): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    0 (0.07030): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.05077): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

624: A NEURAL MODEL OF DELUSIONS AND HALLUCINATIONS IN SCHIZOPHRENIA
    id = 862
    authors = Horn_D Reggia_J Ruppin_E 
    5 (0.23628): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    14 (0.23302): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.18421): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

625: Connectionist Approaches to the Use of Markov Models for Speech Recognition .
    id = 314
    authors = Bourlard_H Morgan_N Wooters_C 
    14 (0.25255): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    11 (0.17770): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.16793): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.04752): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.01497): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    17 (0.01497): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    44 (0.00847): 16 error  (0.13557) 3 neural  (0.12005) 11 training  (0.08903) 0 network  (0.07351) 4 input  (0.05800) 24 performance  (0.05800) 9 set  (0.04248) 5 data  (0.04248) 10 networks  (0.04248) 23 hidden  (0.02697)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

626: Statistical Prediction with Kanerva's Sparse Distributed Memory
    id = 157
    authors = Rogers_D 
    33 (0.17770): 0 network  (0.09122) 11 training  (0.08608) 14 number  (0.07065) 16 error  (0.07065) 3 neural  (0.06036) 12 algorithm  (0.06036) 17 state  (0.05522) 24 performance  (0.05522) 2 model  (0.05008) 18 results  (0.05008)
    5 (0.15492): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    13 (0.15166): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.07030): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    15 (0.06379): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.05403): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    27 (0.00847): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

627: Correlation Functions in a Large Stochastic Neural Network
    id = 759
    authors = Ginzburg_I Sompolinski_H 
    16 (0.30137): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    9 (0.10610): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.07681): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.07355): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    17 (0.06705): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    11 (0.03776): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    10 (0.01823): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

628: Decoding Cursive Scripts
    id = 804
    authors = Singer_Y Tishby_N 
    17 (0.19722): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    23 (0.17770): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    4 (0.16143): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.07030): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.03450): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    26 (0.03450): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

629: Inverse Dynamics of Speech Motor Control
    id = 830
    authors = Hirayama_M Kawato_M Vatikiotis-Bateson_E 
    6 (0.21350): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    7 (0.17444): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.17444): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.05728): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    16 (0.03125): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    14 (0.02148): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

630: Adaptive Stimulus Representations: A Computational Theory of Hippocampal-Region Function
    id = 687
    authors = Gluck_M Myers_C 
    21 (0.22326): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    9 (0.13539): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.12563): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.10935): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.03450): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    1 (0.03450): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    10 (0.02148): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

631: JPMAX: LEARNING TO RECOGNIZE MOVING OBJECTS AS A MODEL-FITTING PROBLEM
    id = 959
    authors = Becker_S 
    15 (0.23302): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    23 (0.20048): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    2 (0.11912): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.09634): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.01823): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    16 (0.01497): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

632: A Mean Field Theory of Layer IV of Visual Cortex and Its Application to Artificial Neural Networks
    id = 70
    authors = Scofield_C 
    15 (0.32089): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.23302): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.06705): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    7 (0.02148): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    27 (0.00847): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)

633: Can Simple Cells Learn Curves? A Hebbian Model in a Structured Environment
    id = 200
    authors = Kammen_D Softky_W 
    2 (0.44456): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    11 (0.10935): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    30 (0.08657): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)
    14 (0.01497): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

634: Biologically Plausible Local Learning Rules for the Adaptation of the Vestibulo-Ocular Reflex
    id = 690
    authors = Coenen_O Lisberger_S Sejnowski_T 
    22 (0.20699): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    3 (0.15817): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    18 (0.13539): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    13 (0.11261): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    10 (0.05403): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

635: Adaptive Soft Weight Tying using Gaussian Mixtures
    id = 550
    authors = Hinton_G Nowlan_S 
    20 (0.16468): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    2 (0.14515): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.09308): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.08657): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.06054): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    3 (0.06054): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.03776): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.03450): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

636: Human Reading and the Curse of Dimensionality
    id = 986
    authors = Martin_G 
    2 (0.25906): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    11 (0.18421): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.15817): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.04752): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

637: Reading a Neural Code
    id = 189
    authors = Bialek_W Rieke_F Warland_D de-Ruyter-van-Steveninck_R 
    13 (0.25580): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    5 (0.19722): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    2 (0.08983): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.04426): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.03125): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    28 (0.03125): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    14 (0.02474): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    18 (0.01172): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)

638: Bayesian Modeling and Classification of Neural Signals
    id = 774
    authors = Lewicki_M 
    8 (0.13864): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.12888): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.12888): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.11912): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    31 (0.05728): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    19 (0.04426): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    15 (0.03450): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    22 (0.03450): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    18 (0.00847): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)

639: An Analog Self-Organizing Neural Network Chip
    id = 175
    authors = Gilbert_S Mann_J 
    11 (0.29811): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.16143): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.08983): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    15 (0.08983): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    5 (0.03776): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

640: A Simple Weight Decay Can Improve Generalization
    id = 545
    authors = Hertz_J Krogh_A 
    2 (0.27208): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    5 (0.25906): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.07355): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.06054): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    20 (0.00847): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

641: Destabilization and Route to Chaos in Neural Networks with Random Connectivity
    id = 640
    authors = Cessac_B Doyon_B Quoy_M Samuelides_M 
    6 (0.16793): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    39 (0.16793): 21 problem  (0.12135) 9 set  (0.11311) 14 number  (0.09665) 3 neural  (0.08018) 18 results  (0.06371) 17 state  (0.05548) 1 learning  (0.05548) 13 output  (0.05548) 24 performance  (0.04725) 8 time  (0.03901)
    11 (0.14841): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.12888): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    9 (0.04426): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

642: Learning by State Recurrence Detection
    id = 66
    authors = Goodwin_J Rosen_B Vidal_J 
    13 (0.29811): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    6 (0.25580): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.11261): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

643: The Effect of Catecholamines on Performance: From Unit to System Behavior
    id = 197
    authors = Cohen_J Printz_H Servan-Schreiber_D 
    10 (0.17444): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    8 (0.09959): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.08983): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    16 (0.08332): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    2 (0.07681): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.06054): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    4 (0.04752): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    3 (0.03450): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.02148): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)

644: Learning Curves, Model Selection and Complexity of Neural Networks
    id = 647
    authors = Amari_S Murata_N Yoshizawa_S 
    0 (0.21675): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.11912): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    10 (0.10284): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    19 (0.09308): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    13 (0.07030): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    12 (0.04426): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    11 (0.04101): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

645: Models of Ocular Dominance Column Formation: Analytical and Computational Results
    id = 133
    authors = Keller_J Miller_K Stryker_M 
    7 (0.24604): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    12 (0.17119): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.14190): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    11 (0.07355): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.04426): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

646: Correlated Neuronal Response: Time Scales and Mechanisms
    id = 993
    authors = Bair_W Koch_C Zohary_E 
    5 (0.19397): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.18421): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.10284): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.07355): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.06705): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    21 (0.05077): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

647: Backpropagation without Multiplication
    id = 729
    authors = Graf_H Simard_P 
    14 (0.22001): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    15 (0.13864): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    4 (0.09634): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.07355): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.04426): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.03776): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.03125): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    7 (0.02799): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    5 (0.02148): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    19 (0.01172): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

648: Harmony Networks Do Not Work
    id = 988
    authors = Gourley_R 
    38 (0.28510): 15 system  (0.16412) 4 input  (0.11882) 18 results  (0.08862) 17 state  (0.06597) 24 performance  (0.06597) 23 hidden  (0.05842) 21 problem  (0.04332) 2 model  (0.04332) 7 figure  (0.03577) 8 time  (0.03577)
    19 (0.22977): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    17 (0.08332): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    11 (0.04101): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    20 (0.01823): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.01497): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    37 (0.01172): 8 time  (0.12266) 18 results  (0.11534) 14 number  (0.11534) 6 function  (0.09335) 7 figure  (0.06404) 17 state  (0.04938) 16 error  (0.04205) 23 hidden  (0.04205) 10 networks  (0.04205) 9 set  (0.03472)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)

649: Signal Processing by Multiplexing and Demultiplexing in Neurons .
    id = 323
    authors = Tam_D 
    5 (0.26557): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.14190): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.11586): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.07355): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    14 (0.04101): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    7 (0.03450): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

650: Using Local Trajectory Optimizers to Speed Up Global Optimization in Dynamic Programming
    id = 783
    authors = Atkeson_C 
    13 (0.21675): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    1 (0.15817): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    29 (0.11912): 6 function  (0.17004) 11 training  (0.13338) 4 input  (0.08041) 1 learning  (0.08041) 18 results  (0.07227) 5 data  (0.07227) 16 error  (0.05190) 9 set  (0.05190) 8 time  (0.04375) 17 state  (0.03560)
    14 (0.06705): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    2 (0.06054): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    15 (0.02799): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    18 (0.01823): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)

651: Nonlinear Pattern Separation in Single Hippocampal Neurons with Active Dendritic Membrane
    id = 435
    authors = Brown_T Claiborne_B Zador_A 
    8 (0.15817): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.15492): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    28 (0.15166): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    5 (0.06379): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    2 (0.05077): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.04426): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    6 (0.03450): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)

652: How Oscillatory Neuronal Responses Reflect Bistability and Switching of the Hidden Assembly Dynamics
    id = 692
    authors = Bauer_H Deppisch_J Geisel_T Pawelzik_K 
    0 (0.26557): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    21 (0.14841): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    14 (0.14515): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    10 (0.05403): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.03450): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.02799): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

653: Modeling Small Oscillating Biological Networks in Analog VLSI
    id = 134
    authors = Bower_J Mead_C Ryckebusch_S 
    9 (0.45758): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    12 (0.10610): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.05728): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    15 (0.02799): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    4 (0.01823): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.01497): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

654: The 'Moving Targets' Training Algorithm
    id = 252
    authors = Rohwer_R 
    10 (0.24930): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    4 (0.23953): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    1 (0.09959): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.06705): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    19 (0.01497): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

655: Extracting Tree-structured Representations of Trained Networks
    id = 987
    authors = Craven_M Shavlik_J 
    6 (0.14190): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    21 (0.11912): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    0 (0.11586): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    26 (0.10610): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    20 (0.08332): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    1 (0.05403): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.03125): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    32 (0.01823): 20 information  (0.10804) 9 set  (0.10804) 1 learning  (0.10804) 15 system  (0.09379) 19 units  (0.07953) 14 number  (0.07003) 10 networks  (0.06528) 22 models  (0.04627) 4 input  (0.04627) 17 state  (0.04152)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)

656: Temporal Difference Learning of Position Evaluation in the Game of Go
    id = 802
    authors = Dayan_P Schraudolph_N Sejnowski_T 
    10 (0.19072): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.14841): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.12563): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    15 (0.09634): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    7 (0.09308): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    19 (0.01172): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    31 (0.00521): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

657: Optimal Stochastic Search and Adaptive Momentum
    id = 760
    authors = Leen_T Orr_G 
    0 (0.18095): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    10 (0.16793): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    5 (0.13864): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    15 (0.07681): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.05403): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    14 (0.02799): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.02148): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    26 (0.01823): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)

658: Analysis of Short Term Memories for Neural Networks
    id = 826
    authors = Hsu_H Kuo_J Principe_J 
    13 (0.31764): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.23953): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.07030): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.03450): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

659: How Perception Guides Production in Birdsong Learning
    id = 999
    authors = Fry_C 
    7 (0.21350): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    34 (0.17119): 23 hidden  (0.09126) 4 input  (0.09126) 11 training  (0.08546) 19 units  (0.07966) 8 time  (0.07386) 22 models  (0.06227) 21 problem  (0.06227) 20 information  (0.05647) 24 performance  (0.05067) 16 error  (0.04487)
    11 (0.09634): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.08657): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.05728): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    2 (0.03776): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.02474): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

660: The Computation of Sound Source Elevation in the Barn Owl
    id = 186
    authors = Pearson_J Spence_C 
    0 (0.21024): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    10 (0.14515): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    6 (0.13539): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.10935): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.06054): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    3 (0.02148): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

661: ACIIVE LEARNING FOR FUNCTION APPROXIMATION
    id = 917
    authors = Niyogi_P Sung_K 
    5 (0.13539): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.12237): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.11912): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.11586): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.09308): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    19 (0.05728): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)

662: A Massively Parallel Self-Tuning Context-Free Parser
    id = 151
    authors = Santos_E 
    11 (0.40551): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.15492): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    4 (0.04752): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    18 (0.04101): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

663: Associative Learning via Inhibitory Search
    id = 92
    authors = Ackley_D 
    6 (0.33717): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.22326): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.05403): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    11 (0.03450): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    10 (0.02148): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

664: Handwritten Digit Recognition with a Back-Propagation Network
    id = 233
    authors = Boser_B Denker_J Henderson_D Howard_R Hubbard_W Jackel_L LeCun_Y 
    0 (0.21350): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.13539): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    17 (0.11912): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    3 (0.11586): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.03450): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.03125): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    14 (0.03125): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

665: Human and Machine 'Quick Modeling' .
    id = 570
    authors = Bernasconi_J Gustarson_K 
    11 (0.25255): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    35 (0.19072): 2 model  (0.12882) 11 training  (0.10820) 23 hidden  (0.08070) 24 performance  (0.07382) 0 network  (0.06695) 15 system  (0.05320) 22 models  (0.04632) 5 data  (0.03945) 6 function  (0.03945) 17 state  (0.03945)
    1 (0.11912): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.06054): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.03776): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    7 (0.02148): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

666: Pattern Class Degeneracy in an Unrestricted Storage Density Memory
    id = 69
    authors = Cooper_L Elbaurn_C Reilly_D Scofield_C 
    13 (0.31439): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    6 (0.09959): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    10 (0.08006): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    48 (0.07030): 21 problem  (0.14210) 16 error  (0.08701) 2 model  (0.08701) 10 networks  (0.08701) 17 state  (0.06865) 11 training  (0.06865) 8 time  (0.06865) 9 set  (0.05028) 14 number  (0.05028) 3 neural  (0.05028)
    8 (0.05077): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.03125): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    18 (0.03125): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)

667: The Power of Approximating: A Comparison of Activation Functions
    id = 648
    authors = DasGupta_B Schnitger_G 
    0 (0.16468): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.15166): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    1 (0.12563): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.10935): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.08657): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    17 (0.01172): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

668: The Efficient Learning of Multiple Task Sequences
    id = 459
    authors = Singh_S 
    18 (0.17119): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    9 (0.15166): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    15 (0.14515): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    7 (0.08983): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    19 (0.05403): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    2 (0.03776): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.02799): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    48 (0.00847): 21 problem  (0.14210) 16 error  (0.08701) 2 model  (0.08701) 10 networks  (0.08701) 17 state  (0.06865) 11 training  (0.06865) 8 time  (0.06865) 9 set  (0.05028) 14 number  (0.05028) 3 neural  (0.05028)

669: Using A Translation-Invariant Neural Network to Diagnose Heart Arrhythmia.
    id = 214
    authors = Lee_S 
    9 (0.31764): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.20373): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    17 (0.07030): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    0 (0.04426): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.03776): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

670: RecNorm: Simultaneous Normalisation and Classification Applied to Speech Recognition .
    id = 317
    authors = Bridle_J Cox_S 
    3 (0.25580): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    20 (0.15166): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    11 (0.08983): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    12 (0.08983): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    9 (0.06054): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.01823): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    21 (0.00847): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

671: A REAL TIME CLUSTERING CMOS NEURAL ENGINE
    id = 937
    authors = Huertas_J Linares-Barranco_B Serrano-Gotarredona_T 
    2 (0.33066): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.14190): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.07681): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.05728): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    25 (0.04426): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    8 (0.02148): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    29 (0.00847): 6 function  (0.17004) 11 training  (0.13338) 4 input  (0.08041) 1 learning  (0.08041) 18 results  (0.07227) 5 data  (0.07227) 16 error  (0.05190) 9 set  (0.05190) 8 time  (0.04375) 17 state  (0.03560)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

672: Partitioning of Sensory Data by a Cortical Network
    id = 34
    authors = Ambros-Ingerson_J Granger_R Henry_H Lynch_G 
    2 (0.24930): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.14841): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.14841): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.07355): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.05403): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

673: Threshold Network Learning in the Presence of Equivalences
    id = 536
    authors = Shawe-Taylor_J 
    12 (0.18746): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.18746): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.11586): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.08657): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.07030): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    11 (0.02474): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    14 (0.01497): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

674: Neural Network Analysis of Distributed Representations of Dynamical Sensory- Motor Transformations in the Leech
    id = 188
    authors = Fang_Y Lockery_S Sejnowski_T 
    20 (0.26882): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    2 (0.21350): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.17444): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

675: Dimensionality Reduction and Prior Knowledge in E-Set Recognition
    id = 206
    authors = Hinton_G Lang_K 
    13 (0.19072): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    20 (0.19072): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    14 (0.12237): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    10 (0.04101): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.03776): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    24 (0.03450): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    11 (0.03125): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.02148): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)

676: Illumination and View Position in 3D Visual Recognition
    id = 478
    authors = Shashua_A 
    0 (0.52267): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.09308): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    13 (0.04426): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

677: Hidden Markov Models for Human Genes
    id = 795
    authors = Baldi_P Brunak_S Chauvin_Y Englebrecht_J Krogh_A 
    20 (0.33066): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    12 (0.14841): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.12563): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.05077): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    17 (0.01172): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

678: Improving Performance in Neural Networks Using a Boosting Algorithm
    id = 578
    authors = Drucker_H Schapire_R Simard_P 
    13 (0.30462): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.16143): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.13539): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.03776): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.02474): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.01497): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

679: ADVANTAGE UPDATING APPLIED TO A DIFFERENTIAL GAME
    id = 887
    authors = Baird_L Harmon_M Klopf_A 
    5 (0.52267): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    27 (0.05728): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    10 (0.05403): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.03776): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

680: Real-Time Computer Vision and Robotics Using Analog VLSI Circuits
    id = 276
    authors = Bair_W Harris_J Horiuchi_T Hsu_A Koch_C Luo_J 
    8 (0.27859): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.13864): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    14 (0.09308): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    5 (0.08657): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.03450): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.03125): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    18 (0.01172): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

681: Surface Learning with Applications to Lipreading
    id = 705
    authors = Bregler_C Omohundro_S 
    21 (0.43155): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    2 (0.16468): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.03776): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    10 (0.01823): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

682: Segmentation Circuits Using Constrained Optimization
    id = 526
    authors = Harris_J 
    5 (0.21350): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.15492): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.12237): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    18 (0.07355): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    13 (0.04426): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    9 (0.03450): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.01497): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    17 (0.01497): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)

683: A Model of Feedback to the Lateral Geniculate Nucleus
    id = 623
    authors = Brody_C 
    1 (0.17770): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    14 (0.15492): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.12563): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.12563): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.05728): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    10 (0.03125): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    18 (0.00847): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

684: Introduction to a System for Implementing Neural Net Connections on SIMD Architectures
    id = 83
    authors = Tomboulian_S 
    11 (0.21675): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.19072): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.09634): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.07030): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.06379): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.03776): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    34 (0.01172): 23 hidden  (0.09126) 4 input  (0.09126) 11 training  (0.08546) 19 units  (0.07966) 8 time  (0.07386) 22 models  (0.06227) 21 problem  (0.06227) 20 information  (0.05647) 24 performance  (0.05067) 16 error  (0.04487)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

685: Convergence and Pattern-Stabilization in the Boltzmann Machine
    id = 148
    authors = Cheng_R Karo_M 
    39 (0.17770): 21 problem  (0.12135) 9 set  (0.11311) 14 number  (0.09665) 3 neural  (0.08018) 18 results  (0.06371) 17 state  (0.05548) 1 learning  (0.05548) 13 output  (0.05548) 24 performance  (0.04725) 8 time  (0.03901)
    0 (0.16468): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.13213): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.08657): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    4 (0.08657): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

686: Bayesian Backprop in Action: Pruning, Committees, Error Bars, and an Application to Spectroscopy
    id = 726
    authors = Thodberg_H 
    18 (0.26231): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    14 (0.24604): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    7 (0.07681): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.03125): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.02474): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    19 (0.01823): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

687: Computing with Almost Optimal Size Neural Networks
    id = 575
    authors = Kailath_T Roychowdhury_V Siu_K 
    4 (0.33391): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    16 (0.19397): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    22 (0.09308): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    18 (0.05077): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    17 (0.00521): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    30 (0.00521): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)

688: Self-Organization of Associative Database and Its Applications
    id = 79
    authors = Arimoto_S Suzuki_H 
    1 (0.34368): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.14841): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    6 (0.14190): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.03125): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

689: Analog LSI Implementation of an Auto-Adaptive Network for Real-Time Separation of Independent Signals
    id = 527
    authors = Andreou_A Cohen_M Pouliquen_P 
    10 (0.29160): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    4 (0.13539): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    26 (0.10935): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    5 (0.04752): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    25 (0.03776): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    12 (0.02148): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    14 (0.01823): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)

690: Bumptrees for Efficient Function, Constraint, and Classification Learning .
    id = 379
    authors = Omohundro_S 
    8 (0.21024): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.20373): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    15 (0.16468): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.05077): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.04752): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

691: Statistical Mechanics of Temporal Association in Neural Networks
    id = 309
    authors = Herz_A Li_Z vanHemmen_J 
    5 (0.43806): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    9 (0.11261): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.07355): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    14 (0.03450): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    7 (0.01497): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

692: DYNAMIC MODELLING OF CHAOTIC TIME SERIES W1TH NEURAL NETWORKS
    id = 882
    authors = Kuo_J Principe_J 
    0 (0.24604): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.17770): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.10935): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    11 (0.09308): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.02148): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    14 (0.01497): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

693: Using Local Models to Control Movement
    id = 223
    authors = Atkeson_C 
    1 (0.24930): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    11 (0.17119): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    12 (0.10284): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    4 (0.07030): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.04426): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    18 (0.01497): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    10 (0.01497): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)

694: Self-organisation in real neurons: Anti-Hebb in 'Channel Space'?
    id = 436
    authors = Bell_A 
    4 (0.32089): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.30462): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.02474): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.01823): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

695: Information Processing to Create Eye Movements
    id = 471
    authors = Robinson_D 
    4 (0.20373): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    1 (0.19397): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.13864): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.06054): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    7 (0.04426): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.02474): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.01823): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

696: Time Dependent Adaptive Neural Networks
    id = 271
    authors = Pineda_F 
    21 (0.23302): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    13 (0.15817): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    11 (0.13213): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    15 (0.07355): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.04426): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.03450): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

697: Computational Elements of the Adaptive Controller of the Human Arm
    id = 834
    authors = Mussa-Ivaldi_F Shadmehr_R 
    1 (0.18746): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.15492): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    10 (0.14841): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.13539): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.04426): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

698: REINFORCEMENT LEARNING METHODS FOR CONTINUOUS-TIME MARKOV DECISION PROBLEMS
    id = 892
    authors = Bradtke_S Duff_M 
    4 (0.23953): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.15492): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.10284): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.08657): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.06054): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    15 (0.02474): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

699: MULTIDIMENSIONAL SCALING AND DATA CLUSTERING
    id = 900
    authors = Buhmann_J Hofmann_T 
    4 (0.23628): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.19072): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    46 (0.12563): 22 models  (0.12591) 14 number  (0.09337) 9 set  (0.09337) 23 hidden  (0.07710) 16 error  (0.07710) 17 state  (0.04456) 13 output  (0.04456) 11 training  (0.04456) 6 function  (0.04456) 1 learning  (0.04456)
    9 (0.05728): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    16 (0.04752): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    3 (0.02148): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

700: Refining PID Controllers using Neural Networks
    id = 496
    authors = Ray_W Scott_G Shavlik_J 
    1 (0.28835): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.11912): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    22 (0.11261): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    10 (0.10610): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    12 (0.03125): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    27 (0.01172): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

701: Packet Routing in Dynamically Changing Networks: A Reinforcement Learning Approach
    id = 784
    authors = Boyan_J Littman_M 
    3 (0.22326): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.20699): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.14190): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.06379): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    11 (0.02799): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    7 (0.01497): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

702: FACTORIAL LEARNING AND THE EM ALGORITHM
    id = 920
    authors = Ghahramani_Z 
    12 (0.29486): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.21350): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.10935): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.04426): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

703: On the Non-Existence of a Universal Learning Algorithm for Recurrent Neural Networks
    id = 754
    authors = Wiklicky_H 
    9 (0.23302): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    13 (0.22651): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    6 (0.09959): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.07681): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.03776): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

704: INTERFERENCE IN LEARNING INTERNAL MODELS OF INVERSE DYNAMICS IN HUMANS
    id = 982
    authors = Brashers-Krug_T Mussa-lvaldi_F Shadmehr_R 
    9 (0.17444): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    15 (0.11912): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.11586): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.09308): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    14 (0.06054): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    13 (0.04101): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.02799): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    18 (0.02148): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)

705: Spatial Organization of Neural Networks: A Probabilistic Modeling Approach
    id = 76
    authors = Dikaiakos_M Kontoravdis_D Stafylopatis_A 
    8 (0.30788): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.10610): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.10610): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.07030): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.07030): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

706: SPATIAL REPRESENTATIONS IN THE PARIETAL CORTEX MAY USE BASIS FUNCTIONS
    id = 863
    authors = Pouget_A Sejnowski_T 
    2 (0.19397): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.13864): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    14 (0.13213): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.12888): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    15 (0.06054): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    11 (0.02799): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

707: The Perceptron Algorithm Is Fast for Non-Malicious Distributions
    id = 267
    authors = Baum_E 
    18 (0.47385): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    8 (0.11586): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.04101): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    19 (0.02474): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.01172): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

708: 3D Object Recognition Using Unsupervised Feature Extraction
    id = 485
    authors = Bfilthoff_H Edelman_S Gold_J Intrator_N 
    8 (0.23302): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.19072): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.11912): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    14 (0.06054): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.05403): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    9 (0.02474): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

709: Algorithms for Better Representation and Faster Learning in Radial Basis Function Networks
    id = 243
    authors = Keeler_J Saha_A 
    3 (0.20048): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.10610): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    14 (0.09634): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    4 (0.08657): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.06054): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.05403): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    17 (0.05077): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    1 (0.03776): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

710: Complexity of Finite Precision Neural Network Classifier
    id = 266
    authors = Dembo_A Kailath_T Siu_K 
    15 (0.19072): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    13 (0.18421): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.12563): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    14 (0.11912): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.05403): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

711: Generalized Hopfield Networks and Nonlinear Optimization ........
    id = 228
    authors = Reklaitis_G Tenorio_M Tsirukis_A 
    6 (0.29486): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    16 (0.18421): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    0 (0.05728): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.04101): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    58 (0.03450): 17 state  (0.13615) 2 model  (0.09973) 19 units  (0.09973) 0 network  (0.06331) 5 data  (0.06331) 7 figure  (0.02689) 6 function  (0.02689) 9 set  (0.02689) 8 time  (0.02689) 10 networks  (0.02689)
    17 (0.03125): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    12 (0.01497): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    24 (0.01172): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.01172): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

712: Sigma-Pi Learning: On Radial Basis Functions and Cortical Associative Learning
    id = 242
    authors = Koch_C Mel_B 
    6 (0.35669): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    19 (0.21024): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    2 (0.08983): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    18 (0.00847): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

713: Theory of Self-Organization of Cortical Maps
    id = 141
    authors = Tanaka_S 
    18 (0.26231): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    1 (0.16793): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    24 (0.14190): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    7 (0.04752): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.03125): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.02148): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    17 (0.00847): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

714: Recurrent Eye Tracking Network Using a Distributed Representation of Image Motion
    id = 475
    authors = Lisberger_S Sejnowski_T Viola_P 
    4 (0.21024): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.15166): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.12563): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.12237): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.03776): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.03125): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    17 (0.00847): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

715: An Optimality Principle for Unsupervised Learning
    id = 91
    authors = Sanger_T 
    9 (0.19397): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    13 (0.14190): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    5 (0.13213): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.12563): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.04752): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.03125): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

716: Language Induction by Phase Transition in Dynamical Recognizers ..
    id = 370
    authors = Pollack_J 
    15 (0.27208): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    5 (0.13213): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.08983): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    25 (0.06705): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    10 (0.04101): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.04101): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    19 (0.01823): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    14 (0.01497): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)

717: Computer Modeling of Associative Learning
    id = 138
    authors = Alkon_D Quek_F Vogl_T 
    4 (0.20699): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.16143): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    14 (0.10935): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.06379): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    17 (0.05728): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    15 (0.04426): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    9 (0.04426): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

718: The Connectivity Analysis of Simple Association
    id = 35
    authors = Hammerstrom_D 
    5 (0.20699): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.20373): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.09308): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    18 (0.07681): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    8 (0.07355): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

719: A Parallel Gradient Descent Method for Learning in Analog VLSI Neural Networks
    id = 675
    authors = Alspector_J Jayakumar_A Lippe_D Meir_R Yuhas_B 
    1 (0.18095): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.15166): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    17 (0.12563): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    3 (0.10284): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.06379): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.03125): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)

720: SARDNET: A SELF-ORGANIZING FEATURE MAP FOR SEQUENCES
    id = 915
    authors = James_D Miikkulainen_R 
    3 (0.40551): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.14841): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    7 (0.06379): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    10 (0.04752): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    19 (0.00847): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

721: New Hardware for Massive Neural Networks
    id = 20
    authors = Coon_D Perera_A 
    20 (0.27533): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    11 (0.21024): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.12563): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.02799): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    12 (0.02474): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

722: Harmonic Grammars for Formal Languages
    id = 676
    authors = Smolensky_P 
    2 (0.22001): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.16468): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    22 (0.15817): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    6 (0.10610): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    9 (0.01823): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    20 (0.00847): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

723: LIMITS ON LEARNING MACHINE ACCURACY IMPOSED BY DATA QUAL1TY
    id = 873
    authors = Chiang_W Cortes_C Jackel_L 
    14 (0.14841): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.14190): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.14190): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.09959): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    15 (0.06379): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    20 (0.04101): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    3 (0.03776): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

724: MORPHOGENESIS OF THE LATERAL GENICULATE NUCLEUS: HOW SINGULARITIES AFFECT GLOBAL STRUCTURE
    id = 860
    authors = Malpeli_J Schulten_K Tzonev_S 
    4 (0.22326): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    6 (0.19397): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    9 (0.12888): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.08006): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    14 (0.03450): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

725: Efficient Computation of Complex Distance Metrics Using Hierarchical Filtering
    id = 721
    authors = Simard_P 
    10 (0.34042): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    7 (0.26557): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    31 (0.05077): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    19 (0.00847): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

726: A CONVOLUTIONAL NEURAL NETWORK HAND TRACKER
    id = 955
    authors = Nowlan_S Platt_J 
    10 (0.41202): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.22001): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    25 (0.01497): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.01497): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    8 (0.01497): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

727: Learning a Color Algorithm from Examples
    id = 64
    authors = Hurlbert_A Poggio_T 
    10 (0.21024): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.17770): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.15166): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    15 (0.10284): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.02799): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

728: Learning Theory and Experiments with Competitive Networks .
    id = 400
    authors = Bilbro_G VandenBout_D 
    0 (0.17119): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.09634): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.08332): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.07681): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.07355): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    19 (0.06379): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    6 (0.05077): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    21 (0.04752): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    9 (0.02799): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)

729: Analysis of Distributed Representation of Constituent Structure in Connectionist Systems
    id = 75
    authors = Smolensky_P 
    23 (0.32089): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    7 (0.25255): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    20 (0.05403): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    3 (0.03450): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    15 (0.01497): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

730: What Size Net Gives Valid Generalization?
    id = 99
    authors = Baum_E Haussler_D 
    8 (0.27533): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.13864): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    24 (0.12237): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    2 (0.07355): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.02799): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    15 (0.02474): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    17 (0.01497): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

731: Phase Transitions in Neural Networks
    id = 19
    authors = Chover_J 
    15 (0.12237): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.11912): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    11 (0.10935): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.10935): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.09634): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.07030): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    25 (0.04426): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)

732: "Fast Learning in Multi-Resolution Hierarchies'
    id = 93
    authors = Moody_J 
    7 (0.26557): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.13213): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    10 (0.10935): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    26 (0.07355): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    2 (0.06705): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

733: Proximity Effect Corrections in Electron Beam Lithography .
    id = 345
    authors = Cummings_K Frye_R Reitman_E 
    0 (0.17444): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.16468): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.15166): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    20 (0.10284): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    14 (0.04101): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    1 (0.03450): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

734: CATASTROPHIC INTERFERENCE IN HUMAN MOTOR LEARNING
    id = 846
    authors = Brashers-Krug_T Shadmehr_R Todorov_E 
    7 (0.22977): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.16793): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.11912): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    11 (0.08657): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    9 (0.05728): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.01497): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    26 (0.00521): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)

735: HIERARCHICAL MIXTURES OF EXPERTS METHODOLOGY APPLIED TO CONTINUOUS SPEECH RECOGNITION
    id = 950
    authors = Makhoul_J Schwartz_R Sroka_J Zhao_Y 
    17 (0.19072): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    4 (0.19072): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.13539): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    18 (0.08006): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    6 (0.06054): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    9 (0.02148): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

736: Programmable Synaptic Chip for Electronic Neural Networks
    id = 58
    authors = Khanna_S Langenbacher_H Moopenn_A Thakoor_A 
    12 (0.30788): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    7 (0.27208): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.07681): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    29 (0.00847): 6 function  (0.17004) 11 training  (0.13338) 4 input  (0.08041) 1 learning  (0.08041) 18 results  (0.07227) 5 data  (0.07227) 16 error  (0.05190) 9 set  (0.05190) 8 time  (0.04375) 17 state  (0.03560)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

737: INTERIOR POINT IMPLEMENTATIONS OF ALTERNATING MINIMIZATION TRAINING
    id = 914
    authors = Lemmon_M Szymanski_P 
    5 (0.20373): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    3 (0.14515): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.12888): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    1 (0.09634): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.07681): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    14 (0.01823): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

738: Figure of Merit Training for Detection and Spotting
    id = 827
    authors = Chang_E Lippmann_R 
    15 (0.28510): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    5 (0.17770): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    9 (0.06379): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.06379): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.06379): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.02148): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

739: Supervised Learning from Incomplete Data via an EM Approach
    id = 715
    authors = Ghahramani_Z Jordan_M 
    5 (0.22326): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    17 (0.14841): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    8 (0.09959): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    10 (0.08332): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.06379): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.03450): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.01823): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)

740: An Information-Theoretic Approach to Deciphering the Hippocampal Code
    id = 699
    authors = Gothard_K Markus_E McNaughton_B Skaggs_W 
    10 (0.44131): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.12888): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.04101): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.03125): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    4 (0.02474): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.01497): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

741: Lower Boundaries of Motoneuron Desynchronization via Renshaw Interneurons
    id = 767
    authors = Druzinsky_R Heckman_C Maltenfort_M Rymer_W 
    2 (0.17119): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.15492): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.13539): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.13539): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    9 (0.08006): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

742: Learning in Feedforward Networks with Nonsmooth Functions
    id = 558
    authors = Downs_T Redding_N 
    15 (0.35669): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    13 (0.09959): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.07681): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.05728): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    25 (0.03450): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.02148): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)

743: Heterogeneous Neural Networks for Adaptive Behavior in Dynamic Environments
    id = 156
    authors = Beer_R Chiel_H Sterling_L 
    25 (0.32415): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    7 (0.14190): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.08983): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.04426): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    14 (0.02148): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    2 (0.01823): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.01823): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    3 (0.01497): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.01497): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)

744: Computer Recognition of Wave Location in Graphical Data by a Neural Network
    id = 515
    authors = Freeman_D 
    4 (0.31764): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    17 (0.21024): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    8 (0.09308): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    26 (0.02799): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    5 (0.02148): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

745: An Artificial Neural Network for Spatio-Temporal Bipolar Patterns: Application to Phoneme Classification
    id = 3
    authors = Atlas_L Homma_T Marks_R 
    5 (0.33717): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.14190): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.10935): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.05403): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    18 (0.00847): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)

746: Microelectronic Implementations of Connectionist Neural Networks
    id = 53
    authors = Denker_J Graf_H Mackie_S Schwartz_D 
    15 (0.28184): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    22 (0.10935): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    0 (0.09959): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.07355): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    20 (0.05077): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.02799): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    10 (0.02799): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    9 (0.01823): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    19 (0.00847): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

747: SEXNET: A Neural Network Identifies Sex From Human Faces .
    id = 363
    authors = Golomb_B Lawrence_D Sejnowski_T 
    12 (0.35344): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    3 (0.14190): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    40 (0.06379): 5 data  (0.16090) 16 error  (0.08362) 12 algorithm  (0.08362) 18 results  (0.07503) 22 models  (0.06645) 15 system  (0.04927) 13 output  (0.04927) 21 problem  (0.04927) 0 network  (0.04927) 2 model  (0.04927)
    1 (0.05403): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.02148): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    22 (0.02148): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    0 (0.01823): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)

748: Bayesian Learning via Stochastic Dynamics
    id = 631
    authors = Neal_R 
    12 (0.16468): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    7 (0.15817): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    11 (0.14841): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.14515): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.02474): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    15 (0.02148): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

749: Transition Point Dynamic Programming
    id = 780
    authors = Buckland_K Lawrence_P 
    2 (0.35669): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    10 (0.16793): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.07355): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    19 (0.06054): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

750: Dual Mechanisms for Neural Binding and Segmentation
    id = 824
    authors = Finkel_L Sajda_P 
    3 (0.21350): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    5 (0.15492): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    4 (0.12888): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.11261): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    10 (0.05403): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

751: FORWARD DYNAMIC MODELS IN HUMAN MOTOR CONTROL: PSYCHOPHYSICAL EVIDENCE
    id = 849
    authors = Ghahramani_Z Jordan_M Wolpert_D 
    11 (0.32740): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.13864): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.08657): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.08332): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    16 (0.04101): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

752: GEMINI: Gradient Estimation Through Matrix Inversion After Noise Injection
    id = 106
    authors = Galland_C Hinton_G LeCun_Y 
    10 (0.18746): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.15166): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.13213): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.07030): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.06705): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.05728): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

753: A Trellis-Structured Neural Network
    id = 61
    authors = Dickinson_B Petsche_T 
    5 (0.22977): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.19722): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    32 (0.09634): 20 information  (0.10804) 9 set  (0.10804) 1 learning  (0.10804) 15 system  (0.09379) 19 units  (0.07953) 14 number  (0.07003) 10 networks  (0.06528) 22 models  (0.04627) 4 input  (0.04627) 17 state  (0.04152)
    11 (0.06705): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    13 (0.03125): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    16 (0.02474): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    20 (0.01823): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    22 (0.00847): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

754: Experimental Demonstrations of Optical Neural Computers
    id = 39
    authors = Brady_D Hsu_K Psaltis_D 
    5 (0.27208): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    15 (0.15166): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    2 (0.09634): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.09634): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.03450): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.01172): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    18 (0.01172): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

755: Adjoint-Functions and Temporal Learning Algorithms in Neural Networks
    id = 301
    authors = Barhen_J Toomarian_N 
    7 (0.22651): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    11 (0.22001): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    9 (0.21024): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    22 (0.01172): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

756: A Neural Network to Detect Homologies in Proteins
    id = 236
    authors = Agin_P Bengio_S Bengio_Y Pouliot_Y 
    7 (0.15817): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.12888): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.11261): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    21 (0.10935): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    12 (0.08332): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    4 (0.05077): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    14 (0.04101): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

757: PULSESTREAM SYNAPSES WITH NON-VOLATILE ANALOGUE AMORPHOUS-SILICON MEMORIES
    id = 938
    authors = Churcher_S Hajto_J Holmes_A Murray_A Rose_M 
    0 (0.32415): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.16143): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    7 (0.06379): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    5 (0.06054): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    18 (0.04101): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    27 (0.01823): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    14 (0.01497): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

758: CLASSIFYING WITH GAUSSIAN MIXTURES AND CLUSTERS
    id = 928
    authors = Kambhatla_N Leen_T 
    10 (0.21675): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    4 (0.21024): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    18 (0.15817): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    7 (0.04101): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.02799): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    17 (0.02799): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

759: Neural Architecture
    id = 181
    authors = Braitenberg_V 
    20 (0.24279): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    10 (0.13213): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.12563): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    26 (0.08983): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    4 (0.06054): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    3 (0.01823): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

760: ICEG MORPHOLOGY CLASSIFICATION USING AN ANALOGUE VLSI NEURAL NETWORK
    id = 934
    authors = Flower_B Jabri_M Pickard_S 
    4 (0.29811): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    9 (0.15492): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.05728): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.05728): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    16 (0.04752): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    17 (0.04101): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    14 (0.02148): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

761: Spreading Activation over Distributed Microfeatures
    id = 153
    authors = Hendler_J 
    10 (0.33717): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    9 (0.21675): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    12 (0.06379): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    21 (0.03776): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

762: Connectivity Versus Entropy
    id = 0
    authors = Abu-Mostafa_Y 
    17 (0.19397): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    1 (0.16143): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.15817): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    15 (0.08983): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    8 (0.07355): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

763: Learning in Higher-Order 'Artificial Dendritic Trees'
    id = 244
    authors = Bell_A 
    13 (0.22326): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    34 (0.10935): 23 hidden  (0.09126) 4 input  (0.09126) 11 training  (0.08546) 19 units  (0.07966) 8 time  (0.07386) 22 models  (0.06227) 21 problem  (0.06227) 20 information  (0.05647) 24 performance  (0.05067) 16 error  (0.04487)
    7 (0.10284): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    5 (0.08983): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    25 (0.06705): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    4 (0.04426): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    3 (0.03450): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    27 (0.00847): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)

764: Non-Intrusive Gaze Tracking Using Artificial Neural Networks
    id = 794
    authors = Baluja_S Pomerleau_D 
    13 (0.30788): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    5 (0.17444): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.09308): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.07030): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.02474): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    19 (0.01172): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

765: Associative Memory in a Network of 'Biological' Neurons .
    id = 297
    authors = Gerstner_W 
    5 (0.24604): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    14 (0.22651): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    0 (0.12563): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.03125): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

766: Pulse-Firing Neural Chips for Hundreds of Neurons
    id = 280
    authors = Brownlow_M Hamilton_A Han_I Murray_A Reekie_H Tarassenko_L 
    8 (0.14190): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    10 (0.12237): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.11261): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.07355): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.07030): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    14 (0.06705): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    1 (0.05403): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.04101): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)

767: Network activity determines spatio-temporal integration in single cells
    id = 434
    authors = Bernander_O Douglas_R Koch_C 
    22 (0.17119): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    13 (0.12563): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    15 (0.11912): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    8 (0.09634): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.08332): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.07030): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    60 (0.02148): 14 number  (0.14130) 15 system  (0.06570) 17 state  (0.06570) 16 error  (0.06570) 2 model  (0.06570) 7 figure  (0.06570) 8 time  (0.02790) 6 function  (0.02790) 9 set  (0.02790) 0 network  (0.02790)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

768: A Neurocomputer Board Based on the ANNA Neural Network Chip
    id = 523
    authors = Boser_B Jackel_L Sackinger_E 
    2 (0.18421): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    14 (0.14515): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    19 (0.12563): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    17 (0.08006): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    4 (0.05077): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    26 (0.04426): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    8 (0.03450): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.02474): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

769: IMPLEMENTATION OF NEURAL HARDWARE WrFH THE NEURAL VLSI OF URAN IN APPLICATIONS WITH REDUCED REPRESENTATIONS
    id = 944
    authors = Han_I Kim_K Lee_H 
    7 (0.31764): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    10 (0.13539): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.11912): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.07681): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.02799): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

770: DIRECTION SELECTIVITY IN PRIMARY VISUAL CORTEX USING MASSIVE INTRACORTICAL CONNECTIONS
    id = 844
    authors = Douglas_R Koch_C Suarez_H 
    12 (0.31439): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    4 (0.09959): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    14 (0.09959): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    1 (0.08006): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.06379): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    31 (0.01172): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    22 (0.00847): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    28 (0.00847): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)

771: The Sigmoid Nonlinearity in Prepyriform Cortex
    id = 25
    authors = Eeckman_F 
    1 (0.24279): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.16793): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    21 (0.10610): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    3 (0.09308): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.03125): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.02474): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    9 (0.01823): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

772: Estimating Analogical Similarity by Dot-Products of Holographic Reduced Representations
    id = 838
    authors = Plate_T 
    2 (0.22326): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.20373): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    14 (0.17770): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.05403): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

773: PATTERNS OF DAMAGE IN NEURAL NETWORKS: THE EFFECTS OF LESION AREA, SHAPE AND NUMBER
    id = 848
    authors = Reggia_J Ruppin_E 
    3 (0.18095): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    25 (0.17770): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    6 (0.15492): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    9 (0.12888): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    11 (0.01823): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

774: Kohonen Feature Maps and Growing Cell Structures--a Performance Comparison
    id = 588
    authors = Fritzke_B 
    9 (0.14841): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    17 (0.13539): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    7 (0.12888): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    31 (0.12237): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    0 (0.08657): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.02799): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    11 (0.02474): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    38 (0.00847): 15 system  (0.16412) 4 input  (0.11882) 18 results  (0.08862) 17 state  (0.06597) 24 performance  (0.06597) 23 hidden  (0.05842) 21 problem  (0.04332) 2 model  (0.04332) 7 figure  (0.03577) 8 time  (0.03577)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)

775: A Back-Propagation Algorithm with Optimal Use of Hidden Units
    id = 149
    authors = Chauvin_Y 
    7 (0.22977): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    6 (0.21675): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    5 (0.08657): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    14 (0.06054): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    3 (0.02799): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.02148): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    17 (0.01823): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)

776: Hidden Markov Models in Molecular Biology: New Algorithms and Applications
    id = 664
    authors = Baldi_P Chauvin_Y Hunkapiller_T McClure_M 
    7 (0.29811): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    18 (0.14515): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    2 (0.13864): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.05077): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.04426): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

777: Dopaminergic Neuromodulation Brings a Dynamical Plasticity to the Retina
    id = 770
    authors = Boussard_E Vibert_J 
    8 (0.38273): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.18095): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    15 (0.08983): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    44 (0.01172): 16 error  (0.13557) 3 neural  (0.12005) 11 training  (0.08903) 0 network  (0.07351) 4 input  (0.05800) 24 performance  (0.05800) 9 set  (0.04248) 5 data  (0.04248) 10 networks  (0.04248) 23 hidden  (0.02697)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

778: Neural Control for Rolling Mills: Incorporating Domain Theories to Overcome Data Deficiency
    id = 509
    authors = Holmann_R Roscheisen_M Tresp_V 
    10 (0.22326): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    9 (0.21675): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    11 (0.09308): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    8 (0.08983): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.03450): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    27 (0.01497): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

779: Simulation of the Neocognitron on a CCD Parallel Processing Architecture . . .
    id = 427
    authors = Chiang_A Chuang_M 
    22 (0.35995): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    10 (0.18421): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    6 (0.10284): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.01823): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    36 (0.01172): 15 system  (0.22042) 19 units  (0.12720) 18 results  (0.06266) 14 number  (0.06266) 7 figure  (0.05549) 3 neural  (0.05549) 10 networks  (0.05549) 4 input  (0.04832) 23 hidden  (0.04832) 5 data  (0.03398)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

780: When Is an Integrate-and-fire Neuron like a Poisson Neuron?
    id = 998
    authors = Stevens_C Zador_A 
    31 (0.21350): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    13 (0.13864): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.12237): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    3 (0.11261): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    24 (0.03776): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    11 (0.02799): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    16 (0.02799): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

781: INFERRING GROUND TRUTH FROM SUBJECTIVE LABELLING OF VENUS IMAGES
    id = 978
    authors = Baldi_P Burl_M Fayyad_U Perona_P Smyth_P 
    12 (0.26231): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    3 (0.26231): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.10284): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    9 (0.03776): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    65 (0.00847): 11 training  (0.08934) 7 figure  (0.03794) 8 time  (0.03794) 6 function  (0.03794) 10 networks  (0.03794) 9 set  (0.03794) 0 network  (0.03794) 1 learning  (0.03794) 2 model  (0.03794) 5 data  (0.03794)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

782: Unsupervised Learning of Mixtures of Multiple Causes in Binary Data
    id = 703
    authors = Saund_E 
    1 (0.24604): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.10284): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    5 (0.09959): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.09959): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.09308): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.02474): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    48 (0.01823): 21 problem  (0.14210) 16 error  (0.08701) 2 model  (0.08701) 10 networks  (0.08701) 17 state  (0.06865) 11 training  (0.06865) 8 time  (0.06865) 9 set  (0.05028) 14 number  (0.05028) 3 neural  (0.05028)
    32 (0.00847): 20 information  (0.10804) 9 set  (0.10804) 1 learning  (0.10804) 15 system  (0.09379) 19 units  (0.07953) 14 number  (0.07003) 10 networks  (0.06528) 22 models  (0.04627) 4 input  (0.04627) 17 state  (0.04152)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

783: Time-Warping Network: A Hybrid Framework for Speech Recognition
    id = 447
    authors = Bocchieri_E Levin_E Pieraccini_R 
    10 (0.27208): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    4 (0.21024): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.09308): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.05077): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.03776): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

784: Analog Neural Networks of Limited Precision I: Computing with Multilinear Threshold Functions
    id = 270
    authors = Obradovic_Z Parberry_I 
    20 (0.22326): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    14 (0.15817): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    3 (0.08657): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.08332): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.06054): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    36 (0.05728): 15 system  (0.22042) 19 units  (0.12720) 18 results  (0.06266) 14 number  (0.06266) 7 figure  (0.05549) 3 neural  (0.05549) 10 networks  (0.05549) 4 input  (0.04832) 23 hidden  (0.04832) 5 data  (0.03398)
    6 (0.01823): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

785: Lance M. Optican, and 3oels Kjter Learning How to Teach or Selecting Minimal Surface Data
    id = 473
    authors = Geiger_D Pereira_R 
    2 (0.22651): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.20699): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    7 (0.10935): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    12 (0.07355): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.02474): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    18 (0.02148): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    8 (0.01497): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    60 (0.01497): 14 number  (0.14130) 15 system  (0.06570) 17 state  (0.06570) 16 error  (0.06570) 2 model  (0.06570) 7 figure  (0.06570) 8 time  (0.02790) 6 function  (0.02790) 9 set  (0.02790) 0 network  (0.02790)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

786: Basins of Attraction for Electronic Neural Networks
    id = 54
    authors = Marcus_C Westervelt_R 
    7 (0.46735): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.07681): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    10 (0.06054): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    14 (0.03450): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    1 (0.02799): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

787: Stability Results for Neural Networks
    id = 57
    authors = Farrell_J Michel_A Porod_W 
    6 (0.21675): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    13 (0.15817): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.14190): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    14 (0.08657): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    1 (0.05403): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    27 (0.01823): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

788: Cricket Wind Detection
    id = 184
    authors = Miller_J 
    4 (0.21024): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.18421): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    16 (0.16143): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    3 (0.07030): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    5 (0.04426): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

789: JANUS: Speech-to-Speech Translation Using Connectionist and Non-Connectionist Techniques
    id = 451
    authors = Jain_A McNair_A Osterholtz_L Saito_H Schmidbauer_O Sloboda_T Tebelskis_J Waibel_A Woszczyna_M 
    2 (0.17770): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.14190): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.12237): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    6 (0.10284): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    21 (0.07030): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.03776): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.01823): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)

790: Induction of Finite-State Automata Using Second-Order Recurrent Networks
    id = 466
    authors = Kuhn_G Watrous_R 
    9 (0.19397): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    27 (0.15492): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    19 (0.15166): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    1 (0.10935): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.03125): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.02148): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.01172): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    33 (0.01172): 0 network  (0.09122) 11 training  (0.08608) 14 number  (0.07065) 16 error  (0.07065) 3 neural  (0.06036) 12 algorithm  (0.06036) 17 state  (0.05522) 24 performance  (0.05522) 2 model  (0.05008) 18 results  (0.05008)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)

791: Unsupervised Learning in Neurodynamics Using the Phase Velocity Field Approach
    id = 255
    authors = Toomarian_N Zak_M 
    18 (0.38273): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    5 (0.09959): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.07681): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.05728): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.02474): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.02148): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    4 (0.02148): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

792: Comparing the Performance of Connectionist and Statistical Classifiers on an Image Segmentation Problem
    id = 259
    authors = Blanz_W Gish_S 
    8 (0.19722): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.13539): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    19 (0.13539): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    12 (0.06379): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.05728): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.03776): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    1 (0.02799): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.02148): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.02148): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

793: Foraging in an Uncertain Environment Using Predictive Hebbian Learning
    id = 775
    authors = Dayan_P Montague_P Sejnowski_T 
    1 (0.28835): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.22001): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.11586): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.01497): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

794: A Method for Learning from Hints
    id = 582
    authors = Abu-Mostafa_Y 
    14 (0.41202): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.11586): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.10284): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    11 (0.03450): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

795: Transient Signal Detection with Neural Networks: The Search for the Desired Signal
    id = 657
    authors = Principe_J Zahalka_A 
    14 (0.32089): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    10 (0.29160): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    16 (0.03125): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    21 (0.00847): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

796: Agnostic PAC-Leaming of Functions on Analog Neural Nets
    id = 739
    authors = Maass_W 
    1 (0.19722): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.17119): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    15 (0.10610): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    9 (0.09634): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    13 (0.04426): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.03450): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.03450): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

797: Unsupervised Classifiers, Mutual Information and 'Phantom Targets' .
    id = 563
    authors = Bridle_J Heading_A MacKay_D 
    12 (0.41853): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.08657): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.06705): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    26 (0.03776): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    7 (0.03776): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    10 (0.02799): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

798: Flight Control in the Dragonfly: A Neurobiological Simulation .
    id = 355
    authors = Faller_W Luttges_M 
    4 (0.34368): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    1 (0.16793): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    15 (0.08332): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    21 (0.05077): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    11 (0.02148): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    24 (0.00847): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

799: Constraints on Adaptive Networks for Modeling Human Generalization
    id = 90
    authors = Gluck_M Henkle_V Pavel_M 
    3 (0.27208): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.23302): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.09308): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    6 (0.04101): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    57 (0.03450): 23 hidden  (0.19481) 11 training  (0.05901) 10 networks  (0.05901) 13 output  (0.05901) 2 model  (0.05901) 6 function  (0.05901) 24 performance  (0.05901) 5 data  (0.02506) 21 problem  (0.02506) 4 input  (0.02506)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

800: Learning in Networks of Nondeterministic Adaptive Logic Elements
    id = 87
    authors = Windecker_R 
    26 (0.30462): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    7 (0.16793): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    8 (0.09308): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.06705): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.03450): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

801: Don Montgomery, and Mark Saffman Principles of Risk Minimization for Learning Theory
    id = 530
    authors = Vapnik_V 
    15 (0.30788): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    0 (0.12563): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.09634): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.06705): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    40 (0.05728): 5 data  (0.16090) 16 error  (0.08362) 12 algorithm  (0.08362) 18 results  (0.07503) 22 models  (0.06645) 15 system  (0.04927) 13 output  (0.04927) 21 problem  (0.04927) 0 network  (0.04927) 2 model  (0.04927)
    8 (0.02474): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

802: COMPARING THE PREDICTION ACCURACY OF ARTIFICIAL NEURAL NETWORKS AND OTHER STATISTICAL MODELS FOR BREAST CANCER SURVIVAL
    id = 975
    authors = Burke_H Goodman_P Rosen_D 
    11 (0.35018): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.12888): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.09959): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.06705): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    26 (0.01823): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    25 (0.00847): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

803: REINFORCEMENT LEARNING W1TH SOFT STATE AGGREGATION
    id = 888
    authors = Jaakkola_T Jordan_M Singh_S 
    10 (0.32740): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.12563): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.09308): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.08006): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.03776): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.01497): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

804: Discovering High Order Features with Mean Field Modules
    id = 246
    authors = Galland_C Hinton_G 
    14 (0.43155): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    16 (0.10284): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    1 (0.09634): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.02799): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    37 (0.00847): 8 time  (0.12266) 18 results  (0.11534) 14 number  (0.11534) 6 function  (0.09335) 7 figure  (0.06404) 17 state  (0.04938) 16 error  (0.04205) 23 hidden  (0.04205) 10 networks  (0.04205) 9 set  (0.03472)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

805: Adaptive Neural Networks Using MOS Charge Storage
    id = 177
    authors = Howard_R Hubbard_W Schwartz_D 
    3 (0.21350): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    9 (0.10935): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    4 (0.10610): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    2 (0.08332): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    20 (0.07681): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    12 (0.03776): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    16 (0.03450): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    8 (0.01823): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    7 (0.01497): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)

806: Optimization with Artificial Neural Network Systems: A Mapping Principle and a Comparison to Gradient Based Methods
    id = 49
    authors = Leong_H 
    2 (0.32415): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    15 (0.12237): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.08332): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    1 (0.06379): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    18 (0.03450): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    5 (0.03125): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.02799): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

807: Optimal Stopping and Effective Machine Complexity in Learning
    id = 738
    authors = Judd_J Venkatesh_S Wang_C 
    6 (0.34368): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.12888): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.07681): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.06705): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.02799): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.02148): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    11 (0.01823): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

808: Song Learning in Birds
    id = 182
    authors = Konishi_M 
    5 (0.18746): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    18 (0.10284): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    3 (0.09959): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.09308): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    14 (0.06379): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.06054): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    15 (0.04752): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    10 (0.03125): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    21 (0.00847): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)

809: Neuromorphic Networks Based on Sparse Optical Orthogonal Codes
    id = 84
    authors = Salehi_J Vecchi_M 
    12 (0.21350): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    20 (0.18421): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    5 (0.09308): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.07030): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    16 (0.04101): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    8 (0.03776): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    6 (0.02799): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    15 (0.02474): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

810: Practical Characteristics of Neural Network and Conventional Pattern Classifiers.
    id = 417
    authors = Lippmann_R Ng_K 
    5 (0.31113): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.24930): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.09308): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    14 (0.01497): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

811: TRAFFIC: Recognizing Objects Using Hierarchical Reference Frame Transformations
    id = 217
    authors = Hinton_G Mozer_M Zemel_R 
    19 (0.34693): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    2 (0.17770): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.08006): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.04426): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    17 (0.02148): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

812: A GROWING NEURAL GAS NETWORK LEARNS TOPOLOGIES
    id = 921
    authors = Fritzke_B 
    5 (0.24604): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    9 (0.12237): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.08657): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    8 (0.04752): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    11 (0.04426): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.04101): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    17 (0.03450): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    14 (0.03125): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    16 (0.02799): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    4 (0.01823): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)

813: Integrated Modeling and Control Based on Reinforcement Learning .
    id = 349
    authors = Sutton_R 
    6 (0.23628): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.18095): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.17444): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.07681): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

814: A Computational Mechanism to Account for Averaged Modified Hand Trajectories
    id = 504
    authors = Flash_T Henis_E 
    15 (0.30137): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    5 (0.16143): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.12888): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.03450): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    10 (0.02148): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    14 (0.01823): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

815: LEARNING TO PLAY THE GAME OF CHESS
    id = 976
    authors = Thmn_S 
    21 (0.28510): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    1 (0.21675): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.11912): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.02799): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    9 (0.01823): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

816: Statistical Modeling of Cell-Assemblies Activities in Associative Cortex of Behaving Monkeys
    id = 688
    authors = Gat_I Tishby_N 
    13 (0.33717): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    22 (0.14190): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    16 (0.12563): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    0 (0.04101): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

817: A Reconfigurable Analog VLSI Neural Network Chip
    id = 277
    authors = Graf_H Satyanarayana_S Tsividis_Y 
    14 (0.39900): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    3 (0.20373): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.04101): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    6 (0.02799): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

818: Visual Motion Computation in Analog VLSI using Pulses
    id = 668
    authors = Bair_W Koch_C Sarpeshkar_R 
    6 (0.31113): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.16793): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.11261): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    3 (0.05077): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.02799): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

819: ASYMPTOTICS OF GRADIENT-BASED NEURAL NETWORK TRAINING ALGORITHMS
    id = 885
    authors = Fine_T Mukherjee_S 
    9 (0.35669): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.22001): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    8 (0.08332): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

820: Structural Risk Minimization for Character Recognition
    id = 486
    authors = Boser_B Bottou_L Guyon_I Solla_S Vapnik_V 
    9 (0.20048): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    19 (0.14515): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    3 (0.12563): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    16 (0.07030): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    1 (0.07030): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    10 (0.05077): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    18 (0.02148): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

821: COMBINING ESTIMATORS USING NON-CONSTANT WEIGHTING FUNCTIONS
    id = 895
    authors = Taniguchi_M Tresp_V 
    5 (0.31113): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.22326): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.05403): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.04426): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.01497): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)

822: Perturbing Hebbian Rules
    id = 431
    authors = Dayan_P Goodhill_G 
    16 (0.24604): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    2 (0.19722): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.06379): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.05728): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    5 (0.04752): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.04426): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    14 (0.01823): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.01497): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

823: EFFECTS OF NOISE ON CONVERGENCE AND GENERALIZATION IN RECURRENT NETWORKS
    id = 924
    authors = Giles_C Horne_B Jim_K 
    11 (0.26231): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.12888): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    10 (0.08983): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.08657): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    18 (0.08332): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    8 (0.01497): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    19 (0.00847): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

824: Visual Grammars and their Neural Nets
    id = 481
    authors = Mjolsness_E 
    0 (0.34693): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.20373): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.04752): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.03450): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    1 (0.02148): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.02148): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

825: Repeat Until Bored: A Pattern Selection Strategy
    id = 551
    authors = Munro_P 
    7 (0.26557): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    0 (0.15166): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.12888): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.08006): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    11 (0.03776): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    52 (0.00847): 11 training  (0.11603) 1 learning  (0.11603) 18 results  (0.11603) 23 hidden  (0.09581) 4 input  (0.07559) 5 data  (0.05537) 13 output  (0.05537) 2 model  (0.05537) 7 figure  (0.03515) 10 networks  (0.03515)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

826: Backpropagation Convergence via Deterministic Nonmonotone Perturbed Minimization
    id = 748
    authors = Mangasarian_O Solodov_M 
    2 (0.32415): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.15166): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    19 (0.12237): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    11 (0.03776): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    7 (0.02799): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

827: Natural Dolphin Echo Recognition Using an Integrator Gateway Network.
    id = 322
    authors = Moore_P Nachtigall_P Penner_R Roitblat_H 
    1 (0.24930): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    0 (0.16468): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.14190): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    21 (0.11261): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

828: Static and Dynamic Error Propagation Networks with Application to Speech Coding
    id = 65
    authors = Fallside_F Robinson_A 
    1 (0.33391): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    18 (0.12563): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    9 (0.07681): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    13 (0.05403): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.05077): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    8 (0.03125): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    48 (0.01172): 21 problem  (0.14210) 16 error  (0.08701) 2 model  (0.08701) 10 networks  (0.08701) 17 state  (0.06865) 11 training  (0.06865) 8 time  (0.06865) 9 set  (0.05028) 14 number  (0.05028) 3 neural  (0.05028)
    27 (0.00847): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

829: A Delay-Line Based Motion Detection Chip .
    id = 340
    authors = Horiuchi_T Koch_C Lazzaro_J Moore_A 
    26 (0.23302): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    17 (0.12888): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    13 (0.09959): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    7 (0.09634): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.08006): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    5 (0.02474): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    15 (0.01823): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

830: Generalization by Weight-Elimination with Application to Forecasting .
    id = 404
    authors = Huberman_B Rumelhart_D Weigend_A 
    10 (0.19397): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    11 (0.16468): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.11586): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.08983): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    1 (0.05403): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.03125): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.01497): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    17 (0.01497): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    6 (0.01497): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)

831: From Speech Recognition to Spoken Language Understanding .
    id = 320
    authors = Glass_J Goodine_D Hirschman_L Leung_H Phillips_M Polifroni_J Seneft_S Zue_V 
    17 (0.36971): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    12 (0.15492): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    0 (0.11586): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.02799): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    19 (0.00847): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    31 (0.00521): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

832: Compact EEPROM-based Weight Functions ..
    id = 421
    authors = Chu_R Ko_P Kramer_A Sin_C 
    2 (0.31764): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    1 (0.14190): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    11 (0.10610): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    21 (0.05077): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    0 (0.04752): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.01172): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

833: Exploiting Syllable Structure in a Connectionist Phonology Model ..
    id = 369
    authors = Touretzky_D Wheeler_D 
    9 (0.15166): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.12237): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    7 (0.11586): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.10935): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.10284): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.06379): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)

834: The Hopfield Model with Multi-Level Neurons
    id = 29
    authors = Fleisher_M 
    2 (0.36320): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    12 (0.17770): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    25 (0.05728): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    8 (0.04101): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    31 (0.01497): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    16 (0.01172): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    21 (0.00847): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

835: SINGLE TRANSISTOR LEARNING SYNAPSES
    id = 945
    authors = Hasler_P 
    0 (0.28510): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.24930): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.07355): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.02474): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.02148): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    7 (0.01823): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    27 (0.00847): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

836: Oscillatory Neural Fields for Globally Optimal Path Planning
    id = 494
    authors = Lemmon_M 
    5 (0.32740): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    15 (0.19722): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    7 (0.05403): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    21 (0.05077): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    6 (0.04101): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

837: Meiosis Networks
    id = 249
    authors = Hanson_S 
    25 (0.25255): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    0 (0.14190): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    8 (0.11586): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.06054): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.04101): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.03776): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    9 (0.03450): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

838: Computing Motion Using Resistive Networks
    id = 44
    authors = Hutchinson_J Koch_C Luo_J Mead_C 
    1 (0.34368): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    16 (0.19722): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    0 (0.07355): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    19 (0.04752): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

839: Phonetic Classification and Recognition Using the Multi-Layer Perceptton .
    id = 319
    authors = Glass_J Leung_H Phillips_M Zue_V 
    5 (0.32415): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    0 (0.22651): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    15 (0.11261): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

840: Stochastic Learning Networks and their Electronic Implementation
    id = 1
    authors = Allen_R Alspector_J Hu_V Satyanarayana_S 
    5 (0.27533): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.25906): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    12 (0.07355): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.04752): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    17 (0.01172): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    23 (0.00847): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

841: Exploratory Feature Extraction in Speech Signals .
    id = 318
    authors = Intrator_N 
    7 (0.23302): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    29 (0.22977): 6 function  (0.17004) 11 training  (0.13338) 4 input  (0.08041) 1 learning  (0.08041) 18 results  (0.07227) 5 data  (0.07227) 16 error  (0.05190) 9 set  (0.05190) 8 time  (0.04375) 17 state  (0.03560)
    8 (0.07681): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    13 (0.06705): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    21 (0.04101): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    16 (0.01823): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    11 (0.01497): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

842: Obstacle Avoidance through Reinforcement Learning
    id = 492
    authors = Mayhew_J Prescott_T 
    11 (0.20699): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.20699): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    15 (0.18095): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.05403): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    19 (0.02148): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    5 (0.01172): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

843: Neural Net and Traditional Classifiers
    id = 40
    authors = Huang_W Lippmann_R 
    10 (0.22977): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.16143): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    15 (0.15166): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    2 (0.09634): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    5 (0.02799): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

844: GROUPING COMPONENTS OF THREE-DIMENSIONAL MOVING OBJECTS IN AREA MST OF VISUAL CORTEX
    id = 864
    authors = Sejnowski_T Zemel_R 
    27 (0.30137): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    23 (0.13213): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    7 (0.12237): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    1 (0.05077): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.04752): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.01823): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

845: A Neural Network for Motion Detection of Drift-Balanced Stimuli
    id = 516
    authors = Tunley_H 
    22 (0.38273): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    7 (0.17444): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    5 (0.05728): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    19 (0.04426): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    14 (0.01172): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

846: Some Approximation Properties of Projection Pursuit Learning Networks
    id = 543
    authors = Atkeson_C Zhao_Y 
    3 (0.28835): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    5 (0.20048): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    7 (0.09308): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    2 (0.07681): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    50 (0.00847): 23 hidden  (0.22812) 20 information  (0.09208) 8 time  (0.07265) 4 input  (0.07265) 12 algorithm  (0.07265) 22 models  (0.05322) 3 neural  (0.05322) 18 results  (0.05322) 11 training  (0.03378) 21 problem  (0.03378)
    21 (0.00847): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

847: Adaptive Knot Placement for Nonparametric Regression
    id = 731
    authors = Cherkassky_V Najafi_H 
    7 (0.39900): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    26 (0.06379): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    6 (0.05077): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    28 (0.04752): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    3 (0.04426): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.03125): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    1 (0.02799): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    25 (0.01823): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    22 (0.01497): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

848: Metamorphosis Networks: An Alternative to Constructive Models
    id = 589
    authors = Bonnlander_B Mozer_M 
    10 (0.29486): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    8 (0.14515): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.13539): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.05403): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    17 (0.02799): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    2 (0.01497): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

849: BIAS, VARIANCE AND THE COMBINATION OF LEAST SQUARES ESTIMATORS
    id = 880
    authors = Meir_R 
    3 (0.29160): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.22001): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.08006): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    7 (0.05077): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.03125): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

850: FINDING STRUCTURE IN REINFORCEMENT LEARN1NG
    id = 891
    authors = Schwartz_A Thrun_S 
    1 (0.30137): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.11261): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    4 (0.08983): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.07030): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    0 (0.06705): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.02474): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    13 (0.01497): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.00847): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

851: Stochastic Neurodynamics .
    id = 294
    authors = Cowen_J 
    2 (0.29811): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.14515): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    22 (0.10610): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    8 (0.04426): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    23 (0.04101): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    6 (0.03125): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    15 (0.01172): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.00847): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

852: Generalization Properties of Radial Basis Functions .
    id = 381
    authors = Atkeson_C Botros_S 
    2 (0.25580): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.16793): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.12237): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.12237): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

853: Unsmearing Visual Motion: Development of Long-Range Horizontal Intrinsic Connections
    id = 624
    authors = Marshall_J Martin_K 
    11 (0.22001): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    16 (0.15166): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    0 (0.12237): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.08006): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    13 (0.06705): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.02799): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    12 (0.01497): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    14 (0.00847): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

854: Reinforcement Learning Applied to Linear Quadratic Regulation
    id = 609
    authors = Bradtke_S 
    10 (0.21675): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    3 (0.15166): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    44 (0.09959): 16 error  (0.13557) 3 neural  (0.12005) 11 training  (0.08903) 0 network  (0.07351) 4 input  (0.05800) 24 performance  (0.05800) 9 set  (0.04248) 5 data  (0.04248) 10 networks  (0.04248) 23 hidden  (0.02697)
    0 (0.08657): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.05728): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    4 (0.03125): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.02474): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.02148): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

855: A Low-Power CMOS Circuit Which Emulates Temporal Electrical Properties of Neurons
    id = 168
    authors = Cole_C Meador_J 
    14 (0.18421): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    7 (0.13213): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.13213): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.12237): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    8 (0.05403): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    16 (0.03125): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    9 (0.02148): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    27 (0.01172): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

856: Adaptive Spline Networks .
    id = 377
    authors = Freidman_J 
    4 (0.22001): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.19722): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.13213): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    28 (0.09308): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    20 (0.02799): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    44 (0.01172): 16 error  (0.13557) 3 neural  (0.12005) 11 training  (0.08903) 0 network  (0.07351) 4 input  (0.05800) 24 performance  (0.05800) 9 set  (0.04248) 5 data  (0.04248) 10 networks  (0.04248) 23 hidden  (0.02697)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

857: A RAPID GRAPH-BASED METHOD FOR ARBITRARY TRANSFORMATION-INVARIANT PATFERN CLASSIFICATION
    id = 926
    authors = Sperduti_A Stork_D 
    17 (0.22977): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    1 (0.20373): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    14 (0.12563): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    16 (0.04101): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    4 (0.03776): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    12 (0.02799): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    24 (0.01172): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

858: Spiral Waves in Integrate-and-Fire Neural Networks
    id = 695
    authors = Chu_P Cowan_J Milton_J 
    0 (0.29160): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    3 (0.14515): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    20 (0.08983): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    13 (0.08657): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    18 (0.05728): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    30 (0.00521): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)

859: Discriminability-Based Transfer between Neural Networks
    id = 598
    authors = Pratt_L 
    3 (0.26231): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    19 (0.17119): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    8 (0.11912): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    18 (0.09634): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    12 (0.01823): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    22 (0.00847): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    31 (0.00521): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)

860: Encoding Labeled Graphs by Labeling RAAM
    id = 840
    authors = Sperduti_A 
    2 (0.18421): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    11 (0.17119): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    19 (0.09308): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    8 (0.07355): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    7 (0.06054): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    17 (0.05077): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    13 (0.03450): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    4 (0.02474): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

861: On the Use of Projection Pursuit Constraints for Training Neural Networks
    id = 573
    authors = Intrator_N 
    1 (0.30137): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    2 (0.16793): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.14190): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    0 (0.05403): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    22 (0.01172): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

862: Design and Implementation of a High Speed CMAC Neural Network .
    id = 424
    authors = Box_B Glynn_J Miller_W Whitney_E 
    9 (0.19072): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    1 (0.15492): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.09634): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    12 (0.09308): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    2 (0.06705): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.03125): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.03125): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    7 (0.02148): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    26 (0.00847): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)

863: Gradient Descent: Second Order Momentum and Saturating Error
    id = 537
    authors = Pearlmutter_B 
    17 (0.51942): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    6 (0.04752): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    15 (0.04101): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    10 (0.02799): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    0 (0.02474): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    22 (0.01172): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

864: Speech Recognition using Connectionist Approaches .
    id = 321
    authors = Choukri_K 
    7 (0.32740): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    9 (0.13213): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    8 (0.08006): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.06054): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    17 (0.02148): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    19 (0.02148): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    4 (0.01823): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    16 (0.01497): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    2 (0.01172): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)

865: On the Use of Evidence in Neural Networks
    id = 639
    authors = Wolpert_D 
    6 (0.37622): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.10610): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    12 (0.10610): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    8 (0.05403): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    2 (0.02148): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.01172): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

866: Dataflow Architectures: Flexible Platforms for Neural Network Simulation
    id = 284
    authors = Smotroff_I 
    11 (0.15492): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.14515): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    4 (0.10284): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    16 (0.09308): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    19 (0.05728): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    0 (0.05403): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    21 (0.03450): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    9 (0.03450): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.01497): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    24 (0.01172): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

867: Grammatical Inference by Attentional Control of Synchronization in an Oscillating Elman Network
    id = 708
    authors = Baird_B Eeckman_F Troyer_T 
    10 (0.50640): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    13 (0.14190): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    22 (0.01497): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    18 (0.00521): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    17 (0.00521): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)

868: Programmable Analog Pulse-Firing Neural Networks
    id = 167
    authors = Hamilton_A Murray_A Tarassenko_L 
    8 (0.20048): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    0 (0.19072): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.12563): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    15 (0.08983): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    10 (0.03450): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    16 (0.02474): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    19 (0.01497): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    31 (0.00521): 12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

869: Learning the Solution to the Aperture Problem for Pattern Motion with a Hebb Rule
    id = 143
    authors = Sereno_M 
    0 (0.16143): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    13 (0.15492): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    16 (0.14190): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    5 (0.12237): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.09308): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

870: The Boltzmann Perceptron Network: A Multi-Layered Feed-Forward Network Equivalent to the Boltzmann Machine
    id = 103
    authors = Gersho_A Yair_E 
    0 (0.33391): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    9 (0.25255): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.05728): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    2 (0.01823): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

871: Classification of Multi-Spectral Pixels by the Binary Diamond Neural Network
    id = 842
    authors = Salu_Y 
    4 (0.39249): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    21 (0.14841): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    0 (0.07681): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    2 (0.02474): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.01823): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    14 (0.01497): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    12 (0.00847): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

872: Rapid Quality Estimation of Neural Network Input Representations
    id = 990
    authors = Cherkauer_K Shavlik_J 
    13 (0.27859): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.15817): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    2 (0.07030): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    5 (0.07030): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.05077): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.03776): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    14 (0.01497): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    15 (0.00847): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

873: Multi-Layer Perceptrons with B-Spline Receptive Field Functions .
    id = 378
    authors = Flax_M Gelfand_J Handelman_D Lane_S 
    1 (0.27859): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    4 (0.13213): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    8 (0.10610): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    27 (0.07681): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    13 (0.07030): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    9 (0.01497): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

874: Learning Temporal Dependencies in Connectionist Speech Recognition
    id = 831
    authors = Hochberg_M Renals_S Robinson_T 
    21 (0.31764): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    11 (0.18095): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    9 (0.13539): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    0 (0.02474): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    12 (0.01497): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

875: Analog Circuits for Conslxained Optimization
    id = 279
    authors = Platt_J 
    14 (0.28510): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    7 (0.22001): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    4 (0.06705): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.06379): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    6 (0.01823): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    5 (0.01497): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    9 (0.01172): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    11 (0.00847): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

876: Speaker Independent Speech Recognition with Neural Networks and Speech Knowledge
    id = 211
    authors = Bengio_Y Cardin_R De-Mori_R 
    2 (0.26557): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    14 (0.19397): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    20 (0.13213): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    5 (0.04101): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    1 (0.01823): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    7 (0.01497): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    13 (0.01172): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

877: Designing Linear Threshold Based Neural Network Pattern Classifiers .
    id = 395
    authors = Fine_T 
    11 (0.35344): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    20 (0.22977): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    0 (0.04426): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    1 (0.04101): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

878: A Lagrangian Approach to Fixed Points .
    id = 296
    authors = Miranker_W Mjolsness_E 
    18 (0.50965): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    2 (0.05728): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    15 (0.05403): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.03125): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    10 (0.01497): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    19 (0.00847): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

879: A Computer Simulation of Olfactory Cortex with Functional Implications for Storage and Retrieval of Olfactory Information
    id = 11
    authors = Bower_J Wilson_M 
    8 (0.16793): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    3 (0.11912): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.11912): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.09634): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    16 (0.08983): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    18 (0.07355): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    1 (0.02148): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

880: Towards an Organizing Principle for a Layered Perceptual Network
    id = 50
    authors = Linsker_R 
    8 (0.19072): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    5 (0.11586): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    2 (0.10935): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    13 (0.08983): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    9 (0.08332): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.06379): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    6 (0.01823): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.01172): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    0 (0.00847): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    30 (0.00847): 6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111)

881: Mapping Classifier Systems Into Neural Networks
    id = 95
    authors = Davis_L 
    6 (0.24604): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.22651): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    27 (0.06379): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    12 (0.04101): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    22 (0.04101): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    15 (0.02799): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    16 (0.02148): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    2 (0.01823): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.00847): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    3 (0.00847): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)

882: Unsupervised Discrimination of Clustered Data via Optimization of Binary Information Gain
    id = 634
    authors = Schraudolph_N Sejnowski_T 
    1 (0.30788): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    13 (0.20373): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    2 (0.11912): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    5 (0.03125): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    11 (0.01172): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

883: Discovering Discrete Distributed Representations .
    id = 371
    authors = Mozer_M 
    3 (0.22001): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.18746): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    21 (0.13539): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    8 (0.12563): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    1 (0.00847): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

884: The CHIR Algorithm for Feed Forward Networks with Binary Weights
    id = 247
    authors = Grossman_T 
    11 (0.24930): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    8 (0.11912): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    4 (0.09308): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    22 (0.07355): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    5 (0.05403): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    6 (0.04752): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    3 (0.03125): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.02474): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

885: Learning to See Where and What: Training a Net to Make Saccades and Recognize Handwritten Characters
    id = 627
    authors = Chapman_D Martin_G Pittman_J Rashid_M 
    15 (0.42829): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    0 (0.17444): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    10 (0.05403): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    6 (0.01172): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    7 (0.00847): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

886: A MODEL FOR CHEMOSENSORY RECEPTION
    id = 851
    authors = Hammer_M Malaka_R Ragg_T 
    11 (0.18746): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    1 (0.14190): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    16 (0.13864): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    13 (0.12237): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    3 (0.05403): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    10 (0.03125): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.00847): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    25 (0.00521): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)

887: Model Based Image Compression and Adaptive Data Representation by Interacting Filter Banks
    id = 221
    authors = Inui_T Kawato_M Miyake_S Okamoto_T 
    6 (0.18095): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.14841): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    8 (0.13539): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    9 (0.12237): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    5 (0.05403): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    1 (0.01497): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    22 (0.00847): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    17 (0.00847): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)

888: Generalization and Parameter Estimation in Feedforward Nets: Some Experiments
    id = 261
    authors = Bourlard_H Morgan_N 
    11 (0.21675): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    15 (0.21350): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    6 (0.10935): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    4 (0.07030): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    19 (0.06379): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

889: A Connectionist Expert System that Actually Works
    id = 118
    authors = Bradshaw_G Ceci_L Fozzard_R 
    6 (0.37297): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.12888): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    27 (0.07681): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    5 (0.06054): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    13 (0.01823): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    15 (0.01823): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    8 (0.00847): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    25 (0.00847): 17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

890: On the Power of Neural Networks for Solving Hard Problems
    id = 13
    authors = Bruck_J Goodman_J 
    0 (0.23302): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    5 (0.17770): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    12 (0.16143): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    11 (0.06054): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    3 (0.03776): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    23 (0.01172): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

891: HYPERPARAMETERS, EVIDENCE AND GENERALISATION FOR AN UNREALISABLE RULE
    id = 875
    authors = Marion_G Saad_D 
    11 (0.22326): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    5 (0.19072): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    28 (0.10610): 8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017)
    3 (0.08983): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    13 (0.04101): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    14 (0.02148): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    10 (0.01497): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)

892: Back Propagation is Sensitive to Initial Conditions .
    id = 402
    authors = Kolen_J Pollack_J 
    14 (0.19072): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    10 (0.12563): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    7 (0.09634): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    3 (0.08983): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.08657): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    11 (0.03125): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.03125): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    9 (0.01823): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    5 (0.01823): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    26 (0.01172): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)

893: LEARNING PROTOTYPE MODELS FOR TANGENT DISTANCE
    id = 967
    authors = Hastie_T Sackinger_E Simard_P 
    11 (0.22326): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    2 (0.16793): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    6 (0.10610): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    24 (0.09308): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    5 (0.06705): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    23 (0.02474): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)
    19 (0.00521): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)

894: Networks for the Separation of Sources that are Superimposed and Delayed . .
    id = 518
    authors = Faggin_F Platt_J 
    27 (0.30462): 23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984)
    15 (0.16143): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    3 (0.08983): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    6 (0.06054): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    1 (0.02474): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    8 (0.02148): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    17 (0.01823): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    13 (0.00847): 18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596)
    36 (0.00847): 15 system  (0.22042) 19 units  (0.12720) 18 results  (0.06266) 14 number  (0.06266) 7 figure  (0.05549) 3 neural  (0.05549) 10 networks  (0.05549) 4 input  (0.04832) 23 hidden  (0.04832) 5 data  (0.03398)
    23 (0.00521): 19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803)

895: Probabilistic Anomaly Detection in Dynamic Systems
    id = 803
    authors = Smyth_P 
    1 (0.21024): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.14190): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    19 (0.09308): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    14 (0.08006): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    7 (0.07681): 24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736)
    26 (0.03125): 2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346)
    3 (0.02799): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    0 (0.02148): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    16 (0.00847): 9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)

896: Use of Bad Training Data for Better Predictions
    id = 743
    authors = Grossman_T Lapedes_A 
    19 (0.29160): 19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968)
    0 (0.16468): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    6 (0.12563): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    14 (0.05403): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    9 (0.03450): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    10 (0.01172): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    22 (0.00521): 21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

897: Cross-Validation Estimates IMSE
    id = 749
    authors = Plutowski_M Sakata_S White_H 
    14 (0.33391): 6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414)
    2 (0.12888): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    3 (0.07030): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    4 (0.06705): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    18 (0.04752): 13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984)
    12 (0.02474): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    1 (0.01172): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    6 (0.00847): 11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

898: Learning in the Vestibular System: Simulations of Vestibular Compensation Using Recurrent Back-Propagation
    id = 502
    authors = Anastasio_T 
    1 (0.32740): 22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499)
    5 (0.20699): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    9 (0.06379): 11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329)
    11 (0.03776): 24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749)
    17 (0.02148): 23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538)
    8 (0.02148): 22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252)
    42 (0.00847): 11 training  (0.10393) 21 problem  (0.09050) 2 model  (0.09050) 6 function  (0.07707) 13 output  (0.06364) 15 system  (0.06364) 5 data  (0.06364) 24 performance  (0.06364) 17 state  (0.05021) 22 models  (0.03678)
    20 (0.00521): 16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)
    21 (0.00521): 8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605)

899: GRAMMAR LEARNING BY A SELF-ORGANIZING NETWORK
    id = 847
    authors = Negishi_M 
    3 (0.26882): 5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244)
    41 (0.11912): 21 problem  (0.16446) 7 figure  (0.13864) 2 model  (0.09990) 16 error  (0.08699) 17 state  (0.07408) 24 performance  (0.07408) 14 number  (0.06117) 10 networks  (0.03535) 3 neural  (0.03535) 12 algorithm  (0.02244)
    15 (0.10935): 14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901)
    12 (0.06705): 3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763)
    4 (0.05077): 17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513)
    5 (0.03450): 16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800)
    2 (0.02799): 7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529)
    0 (0.01172): 1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421)
    10 (0.00847): 0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120)
    24 (0.00521): 12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284)

0 (5.87674 / 67):  1 learning  (0.17162) 4 input  (0.17063) 2 model  (0.16387) 3 neural  (0.15874) 0 network  (0.15718) 6 function  (0.02090) 21 problem  (0.01976) 16 error  (0.01685) 11 training  (0.01507) 13 output  (0.01421) 14 number  (0.01350) 10 networks  (0.01080) 15 system  (0.00987) 8 time  (0.00980) 17 state  (0.00831) 20 information  (0.00752) 9 set  (0.00567) 24 performance  (0.00454) 12 algorithm  (0.00404) 19 units  (0.00390)
1 (5.51661 / 67):  22 models  (0.16803) 17 state  (0.16644) 2 model  (0.16144) 7 figure  (0.16098) 12 algorithm  (0.16060) 24 performance  (0.01992) 10 networks  (0.01726) 1 learning  (0.01643) 21 problem  (0.01605) 23 hidden  (0.01499) 14 number  (0.01347) 11 training  (0.01294) 6 function  (0.01082) 20 information  (0.00968) 18 results  (0.00885) 13 output  (0.00680) 4 input  (0.00567) 0 network  (0.00483) 15 system  (0.00468) 9 set  (0.00460)
2 (5.18831 / 67):  7 figure  (0.16116) 5 data  (0.15358) 8 time  (0.15270) 9 set  (0.15189) 6 function  (0.14295) 18 results  (0.02657) 3 neural  (0.01940) 1 learning  (0.01731) 13 output  (0.01618) 12 algorithm  (0.01529) 23 hidden  (0.01465) 19 units  (0.01384) 4 input  (0.01368) 2 model  (0.01118) 14 number  (0.01054) 24 performance  (0.01029) 22 models  (0.00957) 0 network  (0.00925) 17 state  (0.00917) 11 training  (0.00892)
3 (5.13513 / 67):  5 data  (0.17781) 10 networks  (0.17178) 15 system  (0.16470) 20 information  (0.16356) 0 network  (0.16315) 2 model  (0.01480) 3 neural  (0.01472) 16 error  (0.01406) 4 input  (0.01293) 6 function  (0.01244) 7 figure  (0.01179) 1 learning  (0.01138) 8 time  (0.01105) 14 number  (0.01097) 18 results  (0.00755) 21 problem  (0.00739) 11 training  (0.00731) 13 output  (0.00666) 12 algorithm  (0.00568) 17 state  (0.00519)
4 (4.38641 / 67):  17 state  (0.16627) 18 results  (0.16598) 19 units  (0.16551) 15 system  (0.16084) 16 error  (0.15131) 22 models  (0.02399) 23 hidden  (0.02208) 24 performance  (0.01913) 12 algorithm  (0.01646) 21 problem  (0.01513) 4 input  (0.01208) 20 information  (0.01132) 3 neural  (0.01093) 0 network  (0.01084) 14 number  (0.00846) 1 learning  (0.00779) 5 data  (0.00503) 13 output  (0.00503) 10 networks  (0.00484) 7 figure  (0.00436)
5 (4.12176 / 67):  16 error  (0.15107) 1 learning  (0.13221) 6 function  (0.09408) 11 training  (0.09316) 21 problem  (0.08860) 15 system  (0.06041) 19 units  (0.05696) 17 state  (0.05504) 18 results  (0.04905) 0 network  (0.03800) 5 data  (0.03374) 20 information  (0.02330) 2 model  (0.02320) 10 networks  (0.02157) 3 neural  (0.01782) 8 time  (0.01224) 4 input  (0.01214) 9 set  (0.01062) 12 algorithm  (0.00677) 14 number  (0.00626)
6 (4.06690 / 67):  11 training  (0.16667) 14 number  (0.16122) 12 algorithm  (0.15752) 10 networks  (0.14889) 13 output  (0.14036) 22 models  (0.02741) 15 system  (0.01899) 7 figure  (0.01868) 23 hidden  (0.01827) 1 learning  (0.01744) 16 error  (0.01539) 6 function  (0.01508) 24 performance  (0.01374) 0 network  (0.01302) 20 information  (0.01220) 21 problem  (0.01128) 17 state  (0.00830) 8 time  (0.00830) 2 model  (0.00789) 18 results  (0.00491)
7 (4.03926 / 67):  24 performance  (0.17391) 9 set  (0.15591) 4 input  (0.15466) 19 units  (0.15073) 14 number  (0.14556) 21 problem  (0.02905) 0 network  (0.02284) 1 learning  (0.01839) 15 system  (0.01736) 16 error  (0.01736) 22 models  (0.01580) 10 networks  (0.01394) 20 information  (0.01280) 23 hidden  (0.01156) 6 function  (0.01011) 3 neural  (0.00980) 5 data  (0.00939) 18 results  (0.00691) 12 algorithm  (0.00618) 2 model  (0.00608)
8 (3.59664 / 67):  22 models  (0.17528) 20 information  (0.17459) 23 hidden  (0.17447) 21 problem  (0.16750) 24 performance  (0.16204) 10 networks  (0.01856) 16 error  (0.01472) 12 algorithm  (0.01368) 2 model  (0.01263) 7 figure  (0.01252) 15 system  (0.01159) 11 training  (0.01077) 6 function  (0.00868) 17 state  (0.00822) 3 neural  (0.00810) 8 time  (0.00775) 5 data  (0.00648) 9 set  (0.00357) 4 input  (0.00241) 19 units  (0.00148)
9 (3.38643 / 67):  11 training  (0.18392) 21 problem  (0.18120) 16 error  (0.16911) 1 learning  (0.15715) 6 function  (0.15283) 12 algorithm  (0.02662) 13 output  (0.02069) 24 performance  (0.01379) 3 neural  (0.01366) 14 number  (0.01329) 23 hidden  (0.01058) 7 figure  (0.01008) 10 networks  (0.00836) 0 network  (0.00823) 19 units  (0.00737) 18 results  (0.00601) 2 model  (0.00503) 9 set  (0.00367) 8 time  (0.00244) 22 models  (0.00231)
10 (3.31315 / 67):  0 network  (0.09328) 20 information  (0.08571) 5 data  (0.07651) 3 neural  (0.07071) 23 hidden  (0.06428) 15 system  (0.06075) 8 time  (0.05734) 10 networks  (0.05621) 2 model  (0.05028) 18 results  (0.04120) 1 learning  (0.03868) 4 input  (0.03742) 22 models  (0.03527) 7 figure  (0.03439) 24 performance  (0.03275) 13 output  (0.03200) 6 function  (0.03073) 9 set  (0.02910) 21 problem  (0.02052) 17 state  (0.01964)
11 (3.29682 / 67):  24 performance  (0.12757) 9 set  (0.09843) 20 information  (0.09754) 23 hidden  (0.07651) 21 problem  (0.07486) 22 models  (0.06624) 5 data  (0.06599) 6 function  (0.05091) 7 figure  (0.05040) 14 number  (0.04749) 10 networks  (0.04115) 8 time  (0.04026) 4 input  (0.03621) 19 units  (0.03380) 13 output  (0.02835) 15 system  (0.02582) 11 training  (0.00909) 0 network  (0.00744) 12 algorithm  (0.00706) 3 neural  (0.00491)
12 (3.23987 / 67):  3 neural  (0.18358) 13 output  (0.15702) 23 hidden  (0.14515) 18 results  (0.14399) 8 time  (0.14348) 0 network  (0.02666) 5 data  (0.02395) 20 information  (0.02279) 1 learning  (0.01982) 10 networks  (0.01763) 7 figure  (0.01660) 2 model  (0.01608) 22 models  (0.01402) 4 input  (0.01325) 11 training  (0.01183) 9 set  (0.01118) 6 function  (0.01002) 15 system  (0.00770) 12 algorithm  (0.00538) 17 state  (0.00371)
13 (3.01709 / 67):  18 results  (0.15460) 13 output  (0.13203) 8 time  (0.11473) 3 neural  (0.11307) 23 hidden  (0.11238) 19 units  (0.06198) 15 system  (0.05243) 17 state  (0.04537) 16 error  (0.04274) 14 number  (0.03596) 12 algorithm  (0.02004) 4 input  (0.01948) 7 figure  (0.01630) 9 set  (0.01284) 20 information  (0.01118) 11 training  (0.00979) 2 model  (0.00965) 24 performance  (0.00675) 10 networks  (0.00522) 0 network  (0.00522)
14 (2.76961 / 67):  6 function  (0.10972) 7 figure  (0.09465) 11 training  (0.08334) 9 set  (0.08153) 12 algorithm  (0.06464) 5 data  (0.05741) 17 state  (0.04625) 1 learning  (0.04534) 8 time  (0.04429) 16 error  (0.04414) 21 problem  (0.04037) 19 units  (0.04007) 14 number  (0.03916) 2 model  (0.03916) 22 models  (0.03826) 10 networks  (0.03132) 24 performance  (0.02966) 13 output  (0.02378) 4 input  (0.01760) 0 network  (0.00916)
15 (2.68377 / 67):  14 number  (0.17981) 4 input  (0.10824) 19 units  (0.10669) 13 output  (0.08849) 24 performance  (0.08677) 9 set  (0.08242) 10 networks  (0.07293) 11 training  (0.07293) 12 algorithm  (0.06826) 18 results  (0.03901) 0 network  (0.01583) 3 neural  (0.01521) 8 time  (0.01443) 23 hidden  (0.01303) 16 error  (0.01225) 22 models  (0.00665) 2 model  (0.00509) 17 state  (0.00338) 7 figure  (0.00229) 6 function  (0.00167)
16 (1.59167 / 67):  9 set  (0.09131) 4 input  (0.09078) 14 number  (0.08816) 0 network  (0.08188) 19 units  (0.06931) 3 neural  (0.06486) 10 networks  (0.06172) 12 algorithm  (0.06146) 15 system  (0.05570) 13 output  (0.04889) 5 data  (0.04496) 1 learning  (0.04156) 20 information  (0.03659) 8 time  (0.03501) 11 training  (0.02899) 24 performance  (0.01852) 16 error  (0.01616) 7 figure  (0.01486) 2 model  (0.01381) 17 state  (0.01198)
17 (1.30022 / 67):  23 hidden  (0.10685) 14 number  (0.09981) 4 input  (0.08092) 8 time  (0.07707) 18 results  (0.06971) 24 performance  (0.06779) 3 neural  (0.06747) 22 models  (0.05947) 19 units  (0.05883) 21 problem  (0.04538) 9 set  (0.04026) 13 output  (0.03898) 20 information  (0.02873) 2 model  (0.02777) 7 figure  (0.02681) 17 state  (0.02393) 6 function  (0.02233) 16 error  (0.01624) 12 algorithm  (0.01400) 11 training  (0.01144)
18 (1.22526 / 67):  13 output  (0.10248) 23 hidden  (0.06851) 24 performance  (0.06580) 12 algorithm  (0.06308) 18 results  (0.05901) 11 training  (0.05765) 10 networks  (0.05391) 22 models  (0.05357) 14 number  (0.05153) 1 learning  (0.04984) 3 neural  (0.04576) 17 state  (0.04542) 21 problem  (0.04304) 4 input  (0.03965) 2 model  (0.03795) 6 function  (0.02572) 20 information  (0.02538) 0 network  (0.01859) 7 figure  (0.01825) 8 time  (0.01655)
19 (1.18213 / 67):  19 units  (0.10971) 17 state  (0.10830) 15 system  (0.10338) 16 error  (0.07698) 18 results  (0.07205) 24 performance  (0.06924) 10 networks  (0.04953) 13 output  (0.04707) 9 set  (0.04073) 12 algorithm  (0.03968) 5 data  (0.03968) 4 input  (0.03369) 0 network  (0.03264) 20 information  (0.03229) 14 number  (0.02771) 3 neural  (0.02595) 23 hidden  (0.02208) 11 training  (0.01610) 2 model  (0.01539) 7 figure  (0.01504)
20 (0.93758 / 67):  16 error  (0.10000) 17 state  (0.09335) 21 problem  (0.08051) 6 function  (0.07829) 11 training  (0.07740) 22 models  (0.07563) 15 system  (0.06456) 7 figure  (0.05703) 18 results  (0.05393) 20 information  (0.04950) 1 learning  (0.04905) 2 model  (0.04905) 12 algorithm  (0.03931) 19 units  (0.02336) 9 set  (0.02292) 23 hidden  (0.02159) 0 network  (0.01362) 24 performance  (0.01052) 10 networks  (0.00963) 14 number  (0.00963)
21 (0.81740 / 67):  8 time  (0.12471) 11 training  (0.09122) 16 error  (0.07447) 9 set  (0.06787) 6 function  (0.06686) 7 figure  (0.06432) 0 network  (0.05975) 1 learning  (0.05671) 2 model  (0.04706) 15 system  (0.04605) 21 problem  (0.04300) 3 neural  (0.03945) 4 input  (0.03082) 12 algorithm  (0.02930) 13 output  (0.02524) 22 models  (0.02423) 5 data  (0.02423) 10 networks  (0.02321) 23 hidden  (0.01814) 14 number  (0.01458)
22 (0.80986 / 67):  21 problem  (0.14379) 13 output  (0.10896) 8 time  (0.06952) 23 hidden  (0.06850) 24 performance  (0.06440) 16 error  (0.05416) 11 training  (0.05006) 22 models  (0.04647) 18 results  (0.04443) 20 information  (0.04443) 12 algorithm  (0.03725) 2 model  (0.03725) 17 state  (0.03623) 3 neural  (0.03572) 5 data  (0.03469) 1 learning  (0.03008) 6 function  (0.02445) 7 figure  (0.02240) 0 network  (0.01472) 4 input  (0.01216)
23 (0.58290 / 67):  19 units  (0.11609) 7 figure  (0.07922) 16 error  (0.07851) 17 state  (0.07780) 9 set  (0.06575) 18 results  (0.06221) 22 models  (0.06079) 2 model  (0.05157) 12 algorithm  (0.05086) 14 number  (0.04803) 8 time  (0.04590) 4 input  (0.04023) 6 function  (0.03526) 15 system  (0.03314) 5 data  (0.02959) 23 hidden  (0.02817) 24 performance  (0.02605) 13 output  (0.02463) 11 training  (0.01896) 20 information  (0.01470)
24 (0.51758 / 67):  12 algorithm  (0.14408) 17 state  (0.08030) 10 networks  (0.07393) 22 models  (0.06914) 13 output  (0.05878) 14 number  (0.05878) 7 figure  (0.05639) 11 training  (0.04762) 20 information  (0.04284) 0 network  (0.04284) 2 model  (0.04124) 19 units  (0.04124) 8 time  (0.03646) 24 performance  (0.03327) 23 hidden  (0.02610) 16 error  (0.02371) 5 data  (0.02371) 21 problem  (0.02291) 18 results  (0.02131) 3 neural  (0.01733)
25 (0.51590 / 67):  17 state  (0.19332) 7 figure  (0.07976) 16 error  (0.06217) 8 time  (0.06057) 19 units  (0.05577) 15 system  (0.05417) 22 models  (0.05417) 6 function  (0.05417) 21 problem  (0.04697) 12 algorithm  (0.04218) 2 model  (0.04138) 23 hidden  (0.03178) 9 set  (0.03098) 5 data  (0.02538) 3 neural  (0.02458) 1 learning  (0.02298) 20 information  (0.02138) 0 network  (0.01738) 14 number  (0.01658) 11 training  (0.01658)
26 (0.51004 / 67):  2 model  (0.12272) 1 learning  (0.10493) 0 network  (0.07905) 21 problem  (0.07500) 15 system  (0.05398) 16 error  (0.05398) 11 training  (0.05398) 4 input  (0.04751) 5 data  (0.04427) 6 function  (0.04346) 10 networks  (0.04023) 19 units  (0.03861) 9 set  (0.03861) 20 information  (0.03618) 22 models  (0.03457) 7 figure  (0.03295) 14 number  (0.02890) 17 state  (0.02890) 3 neural  (0.01192) 12 algorithm  (0.01192)
27 (0.42043 / 67):  23 hidden  (0.18068) 20 information  (0.10635) 21 problem  (0.09168) 3 neural  (0.08288) 18 results  (0.06723) 24 performance  (0.06234) 8 time  (0.04865) 1 learning  (0.04865) 0 network  (0.04767) 22 models  (0.03984) 9 set  (0.03300) 6 function  (0.03104) 17 state  (0.02909) 4 input  (0.02322) 19 units  (0.01930) 5 data  (0.01539) 7 figure  (0.01539) 15 system  (0.01441) 13 output  (0.01441) 11 training  (0.00952)
28 (0.29187 / 67):  8 time  (0.11844) 7 figure  (0.10446) 6 function  (0.10167) 16 error  (0.07371) 22 models  (0.06812) 5 data  (0.06393) 11 training  (0.05275) 9 set  (0.04157) 1 learning  (0.04157) 12 algorithm  (0.04017) 14 number  (0.03597) 21 problem  (0.03178) 24 performance  (0.02899) 13 output  (0.02899) 15 system  (0.02619) 17 state  (0.02479) 18 results  (0.02340) 3 neural  (0.02340) 23 hidden  (0.01780) 2 model  (0.01361)
29 (0.09506 / 67):  6 function  (0.17004) 11 training  (0.13338) 4 input  (0.08041) 1 learning  (0.08041) 18 results  (0.07227) 5 data  (0.07227) 16 error  (0.05190) 9 set  (0.05190) 8 time  (0.04375) 17 state  (0.03560) 3 neural  (0.03153) 21 problem  (0.03153) 2 model  (0.02338) 20 information  (0.02338) 0 network  (0.01930) 24 performance  (0.01930) 7 figure  (0.01116) 14 number  (0.01116) 15 system  (0.00708) 19 units  (0.00708)
30 (0.08626 / 67):  6 function  (0.19932) 9 set  (0.16813) 19 units  (0.12804) 16 error  (0.08794) 24 performance  (0.07903) 7 figure  (0.06121) 21 problem  (0.03893) 20 information  (0.03002) 14 number  (0.02557) 11 training  (0.02111) 10 networks  (0.02111) 17 state  (0.02111) 23 hidden  (0.01665) 18 results  (0.01665) 3 neural  (0.01665) 0 network  (0.01220) 22 models  (0.01220) 4 input  (0.00774) 5 data  (0.00774) 1 learning  (0.00774)
31 (0.08459 / 67):  12 algorithm  (0.13036) 13 output  (0.10314) 22 models  (0.09407) 7 figure  (0.08500) 6 function  (0.08046) 20 information  (0.07593) 24 performance  (0.07139) 11 training  (0.05325) 9 set  (0.03964) 21 problem  (0.03964) 17 state  (0.03964) 2 model  (0.03057) 14 number  (0.03057) 18 results  (0.03057) 23 hidden  (0.01696) 4 input  (0.01696) 15 system  (0.01242) 3 neural  (0.00788) 1 learning  (0.00788) 19 units  (0.00788)
32 (0.08040 / 67):  20 information  (0.10804) 9 set  (0.10804) 1 learning  (0.10804) 15 system  (0.09379) 19 units  (0.07953) 14 number  (0.07003) 10 networks  (0.06528) 22 models  (0.04627) 4 input  (0.04627) 17 state  (0.04152) 5 data  (0.04152) 24 performance  (0.03677) 2 model  (0.03202) 8 time  (0.02251) 16 error  (0.01776) 6 function  (0.01301) 18 results  (0.01301) 3 neural  (0.01301) 13 output  (0.01301) 0 network  (0.00826)
33 (0.07370 / 67):  0 network  (0.09122) 11 training  (0.08608) 14 number  (0.07065) 16 error  (0.07065) 3 neural  (0.06036) 12 algorithm  (0.06036) 17 state  (0.05522) 24 performance  (0.05522) 2 model  (0.05008) 18 results  (0.05008) 22 models  (0.04494) 10 networks  (0.03979) 4 input  (0.03979) 23 hidden  (0.03979) 15 system  (0.03979) 7 figure  (0.03465) 19 units  (0.02437) 13 output  (0.01922) 21 problem  (0.01922) 8 time  (0.01408)
34 (0.06449 / 67):  23 hidden  (0.09126) 4 input  (0.09126) 11 training  (0.08546) 19 units  (0.07966) 8 time  (0.07386) 22 models  (0.06227) 21 problem  (0.06227) 20 information  (0.05647) 24 performance  (0.05067) 16 error  (0.04487) 18 results  (0.04487) 9 set  (0.04487) 3 neural  (0.03907) 10 networks  (0.03327) 0 network  (0.02748) 6 function  (0.01588) 2 model  (0.01588) 15 system  (0.01588) 14 number  (0.01588) 7 figure  (0.01588)
35 (0.05318 / 67):  2 model  (0.12882) 11 training  (0.10820) 23 hidden  (0.08070) 24 performance  (0.07382) 0 network  (0.06695) 15 system  (0.05320) 22 models  (0.04632) 5 data  (0.03945) 6 function  (0.03945) 17 state  (0.03945) 7 figure  (0.03258) 1 learning  (0.03258) 4 input  (0.03258) 20 information  (0.03258) 12 algorithm  (0.02570) 3 neural  (0.02570) 14 number  (0.02570) 19 units  (0.02570) 18 results  (0.01883) 10 networks  (0.01883)
36 (0.05067 / 67):  15 system  (0.22042) 19 units  (0.12720) 18 results  (0.06266) 14 number  (0.06266) 7 figure  (0.05549) 3 neural  (0.05549) 10 networks  (0.05549) 4 input  (0.04832) 23 hidden  (0.04832) 5 data  (0.03398) 0 network  (0.03398) 22 models  (0.03398) 20 information  (0.02681) 24 performance  (0.01964) 13 output  (0.01964) 6 function  (0.01246) 16 error  (0.01246) 17 state  (0.01246) 21 problem  (0.01246) 1 learning  (0.01246)
37 (0.04941 / 67):  8 time  (0.12266) 18 results  (0.11534) 14 number  (0.11534) 6 function  (0.09335) 7 figure  (0.06404) 17 state  (0.04938) 16 error  (0.04205) 23 hidden  (0.04205) 10 networks  (0.04205) 9 set  (0.03472) 19 units  (0.03472) 11 training  (0.02740) 0 network  (0.02740) 24 performance  (0.02740) 15 system  (0.02740) 12 algorithm  (0.02740) 1 learning  (0.02007) 3 neural  (0.02007) 4 input  (0.01274) 13 output  (0.01274)
38 (0.04774 / 67):  15 system  (0.16412) 4 input  (0.11882) 18 results  (0.08862) 17 state  (0.06597) 24 performance  (0.06597) 23 hidden  (0.05842) 21 problem  (0.04332) 2 model  (0.04332) 7 figure  (0.03577) 8 time  (0.03577) 11 training  (0.03577) 0 network  (0.03577) 19 units  (0.03577) 16 error  (0.03577) 20 information  (0.02822) 12 algorithm  (0.02067) 3 neural  (0.01312) 5 data  (0.01312) 1 learning  (0.01312) 13 output  (0.01312)
39 (0.04313 / 67):  21 problem  (0.12135) 9 set  (0.11311) 14 number  (0.09665) 3 neural  (0.08018) 18 results  (0.06371) 17 state  (0.05548) 1 learning  (0.05548) 13 output  (0.05548) 24 performance  (0.04725) 8 time  (0.03901) 23 hidden  (0.03901) 11 training  (0.03078) 20 information  (0.03078) 4 input  (0.03078) 19 units  (0.03078) 0 network  (0.02255) 10 networks  (0.02255) 15 system  (0.01431) 12 algorithm  (0.01431) 2 model  (0.00608)
40 (0.04104 / 67):  5 data  (0.16090) 16 error  (0.08362) 12 algorithm  (0.08362) 18 results  (0.07503) 22 models  (0.06645) 15 system  (0.04927) 13 output  (0.04927) 21 problem  (0.04927) 0 network  (0.04927) 2 model  (0.04927) 4 input  (0.04069) 24 performance  (0.04069) 19 units  (0.04069) 23 hidden  (0.03210) 1 learning  (0.02351) 17 state  (0.01493) 6 function  (0.01493) 14 number  (0.01493) 10 networks  (0.01493) 9 set  (0.01493)
41 (0.02471 / 67):  21 problem  (0.16446) 7 figure  (0.13864) 2 model  (0.09990) 16 error  (0.08699) 17 state  (0.07408) 24 performance  (0.07408) 14 number  (0.06117) 10 networks  (0.03535) 3 neural  (0.03535) 12 algorithm  (0.02244) 4 input  (0.02244) 11 training  (0.02244) 8 time  (0.02244) 1 learning  (0.02244) 23 hidden  (0.02244) 5 data  (0.00953) 6 function  (0.00953) 0 network  (0.00953) 18 results  (0.00953) 20 information  (0.00953)
42 (0.02345 / 67):  11 training  (0.10393) 21 problem  (0.09050) 2 model  (0.09050) 6 function  (0.07707) 13 output  (0.06364) 15 system  (0.06364) 5 data  (0.06364) 24 performance  (0.06364) 17 state  (0.05021) 22 models  (0.03678) 1 learning  (0.03678) 8 time  (0.03678) 14 number  (0.03678) 18 results  (0.03678) 3 neural  (0.02335) 16 error  (0.02335) 9 set  (0.02335) 23 hidden  (0.00992) 12 algorithm  (0.00992) 19 units  (0.00992)
43 (0.01968 / 67):  11 training  (0.14878) 10 networks  (0.08767) 3 neural  (0.08767) 18 results  (0.07239) 7 figure  (0.07239) 8 time  (0.07239) 0 network  (0.05711) 9 set  (0.05711) 6 function  (0.04183) 1 learning  (0.04183) 21 problem  (0.02656) 17 state  (0.02656) 22 models  (0.02656) 15 system  (0.02656) 16 error  (0.02656) 4 input  (0.02656) 2 model  (0.01128) 5 data  (0.01128) 24 performance  (0.01128) 20 information  (0.01128)
44 (0.01926 / 67):  16 error  (0.13557) 3 neural  (0.12005) 11 training  (0.08903) 0 network  (0.07351) 4 input  (0.05800) 24 performance  (0.05800) 9 set  (0.04248) 5 data  (0.04248) 10 networks  (0.04248) 23 hidden  (0.02697) 8 time  (0.02697) 22 models  (0.02697) 2 model  (0.02697) 7 figure  (0.02697) 18 results  (0.02697) 19 units  (0.02697) 13 output  (0.02697) 20 information  (0.02697) 12 algorithm  (0.02697) 1 learning  (0.01145)
45 (0.01843 / 67):  8 time  (0.15592) 21 problem  (0.10789) 2 model  (0.09188) 9 set  (0.09188) 22 models  (0.07587) 17 state  (0.04384) 10 networks  (0.04384) 0 network  (0.04384) 18 results  (0.04384) 5 data  (0.04384) 12 algorithm  (0.02783) 24 performance  (0.02783) 15 system  (0.02783) 19 units  (0.02783) 23 hidden  (0.02783) 4 input  (0.01182) 3 neural  (0.01182) 1 learning  (0.01182) 20 information  (0.01182) 13 output  (0.01182)
46 (0.01801 / 67):  22 models  (0.12591) 14 number  (0.09337) 9 set  (0.09337) 23 hidden  (0.07710) 16 error  (0.07710) 17 state  (0.04456) 13 output  (0.04456) 11 training  (0.04456) 6 function  (0.04456) 1 learning  (0.04456) 10 networks  (0.02828) 7 figure  (0.02828) 0 network  (0.02828) 24 performance  (0.02828) 18 results  (0.02828) 20 information  (0.02828) 19 units  (0.02828) 21 problem  (0.02828) 2 model  (0.01201) 3 neural  (0.01201)
47 (0.01759 / 67):  5 data  (0.09492) 12 algorithm  (0.07837) 9 set  (0.07837) 15 system  (0.07837) 6 function  (0.07837) 24 performance  (0.07837) 22 models  (0.06183) 10 networks  (0.06183) 17 state  (0.06183) 4 input  (0.04529) 0 network  (0.04529) 2 model  (0.04529) 8 time  (0.02875) 7 figure  (0.02875) 1 learning  (0.01221) 23 hidden  (0.01221) 3 neural  (0.01221) 18 results  (0.01221) 19 units  (0.01221) 14 number  (0.01221)
48 (0.01508 / 67):  21 problem  (0.14210) 16 error  (0.08701) 2 model  (0.08701) 10 networks  (0.08701) 17 state  (0.06865) 11 training  (0.06865) 8 time  (0.06865) 9 set  (0.05028) 14 number  (0.05028) 3 neural  (0.05028) 1 learning  (0.03192) 4 input  (0.03192) 5 data  (0.01356) 0 network  (0.01356) 7 figure  (0.01356) 6 function  (0.01356) 24 performance  (0.01356) 20 information  (0.01356) 22 models  (0.01356) 19 units  (0.01356)
49 (0.01466 / 67):  20 information  (0.18217) 6 function  (0.10734) 13 output  (0.10734) 4 input  (0.05122) 2 model  (0.05122) 17 state  (0.05122) 12 algorithm  (0.05122) 11 training  (0.05122) 1 learning  (0.05122) 21 problem  (0.03252) 23 hidden  (0.03252) 18 results  (0.03252) 3 neural  (0.03252) 5 data  (0.01381) 7 figure  (0.01381) 0 network  (0.01381) 24 performance  (0.01381) 16 error  (0.01381) 19 units  (0.01381) 15 system  (0.01381)
50 (0.01382 / 67):  23 hidden  (0.20869) 5 data  (0.18925) 21 problem  (0.11152) 18 results  (0.05322) 24 performance  (0.05322) 14 number  (0.03378) 1 learning  (0.03378) 13 output  (0.03378) 0 network  (0.03378) 17 state  (0.03378) 22 models  (0.01435) 4 input  (0.01435) 6 function  (0.01435) 7 figure  (0.01435) 2 model  (0.01435) 3 neural  (0.01435) 19 units  (0.01435) 15 system  (0.01435) 16 error  (0.01435) 12 algorithm  (0.01435)
51 (0.01382 / 67):  23 hidden  (0.22812) 20 information  (0.09208) 8 time  (0.07265) 4 input  (0.07265) 12 algorithm  (0.07265) 22 models  (0.05322) 3 neural  (0.05322) 18 results  (0.05322) 11 training  (0.03378) 21 problem  (0.03378) 9 set  (0.03378) 6 function  (0.01435) 7 figure  (0.01435) 0 network  (0.01435) 1 learning  (0.01435) 5 data  (0.01435) 2 model  (0.01435) 24 performance  (0.01435) 17 state  (0.01435) 16 error  (0.01435)
52 (0.01298 / 67):  11 training  (0.11603) 1 learning  (0.11603) 18 results  (0.11603) 23 hidden  (0.09581) 4 input  (0.07559) 5 data  (0.05537) 13 output  (0.05537) 2 model  (0.05537) 7 figure  (0.03515) 10 networks  (0.03515) 6 function  (0.03515) 8 time  (0.01493) 9 set  (0.01493) 0 network  (0.01493) 3 neural  (0.01493) 24 performance  (0.01493) 20 information  (0.01493) 21 problem  (0.01493) 19 units  (0.01493) 22 models  (0.01493)
53 (0.01047 / 67):  14 number  (0.15506) 6 function  (0.10904) 8 time  (0.10904) 9 set  (0.08602) 23 hidden  (0.06301) 15 system  (0.06301) 21 problem  (0.04000) 7 figure  (0.04000) 1 learning  (0.04000) 5 data  (0.04000) 2 model  (0.01699) 3 neural  (0.01699) 4 input  (0.01699) 0 network  (0.01699) 24 performance  (0.01699) 18 results  (0.01699) 19 units  (0.01699) 17 state  (0.01699) 22 models  (0.01699) 20 information  (0.01699)
54 (0.00796 / 67):  14 number  (0.09980) 16 error  (0.09980) 1 learning  (0.09980) 17 state  (0.07311) 24 performance  (0.07311) 20 information  (0.07311) 6 function  (0.04641) 7 figure  (0.04641) 8 time  (0.04641) 18 results  (0.04641) 0 network  (0.01971) 5 data  (0.01971) 23 hidden  (0.01971) 2 model  (0.01971) 4 input  (0.01971) 3 neural  (0.01971) 19 units  (0.01971) 22 models  (0.01971) 15 system  (0.01971) 13 output  (0.01971)
55 (0.00712 / 67):  5 data  (0.33106) 12 algorithm  (0.10543) 17 state  (0.04903) 19 units  (0.04903) 2 model  (0.04903) 7 figure  (0.02082) 6 function  (0.02082) 9 set  (0.02082) 8 time  (0.02082) 10 networks  (0.02082) 0 network  (0.02082) 1 learning  (0.02082) 4 input  (0.02082) 3 neural  (0.02082) 24 performance  (0.02082) 20 information  (0.02082) 21 problem  (0.02082) 18 results  (0.02082) 23 hidden  (0.02082) 22 models  (0.02082)
56 (0.00628 / 67):  13 output  (0.17152) 4 input  (0.11174) 8 time  (0.08185) 9 set  (0.05196) 2 model  (0.05196) 24 performance  (0.05196) 20 information  (0.05196) 23 hidden  (0.05196) 6 function  (0.02207) 5 data  (0.02207) 7 figure  (0.02207) 21 problem  (0.02207) 0 network  (0.02207) 1 learning  (0.02207) 22 models  (0.02207) 3 neural  (0.02207) 18 results  (0.02207) 15 system  (0.02207) 16 error  (0.02207) 14 number  (0.02207)
57 (0.00461 / 67):  23 hidden  (0.19481) 11 training  (0.05901) 10 networks  (0.05901) 13 output  (0.05901) 2 model  (0.05901) 6 function  (0.05901) 24 performance  (0.05901) 5 data  (0.02506) 21 problem  (0.02506) 4 input  (0.02506) 7 figure  (0.02506) 8 time  (0.02506) 0 network  (0.02506) 1 learning  (0.02506) 3 neural  (0.02506) 22 models  (0.02506) 17 state  (0.02506) 14 number  (0.02506) 15 system  (0.02506) 18 results  (0.02506)
58 (0.00377 / 67):  7 figure  (0.09973) 12 algorithm  (0.09973) 15 system  (0.09973) 5 data  (0.06331) 18 results  (0.06331) 1 learning  (0.06331) 8 time  (0.02689) 9 set  (0.02689) 10 networks  (0.02689) 0 network  (0.02689) 2 model  (0.02689) 6 function  (0.02689) 4 input  (0.02689) 3 neural  (0.02689) 24 performance  (0.02689) 20 information  (0.02689) 21 problem  (0.02689) 19 units  (0.02689) 23 hidden  (0.02689) 22 models  (0.02689)
59 (0.00377 / 67):  17 state  (0.13615) 2 model  (0.09973) 19 units  (0.09973) 0 network  (0.06331) 5 data  (0.06331) 7 figure  (0.02689) 6 function  (0.02689) 9 set  (0.02689) 8 time  (0.02689) 10 networks  (0.02689) 1 learning  (0.02689) 4 input  (0.02689) 3 neural  (0.02689) 24 performance  (0.02689) 20 information  (0.02689) 21 problem  (0.02689) 18 results  (0.02689) 23 hidden  (0.02689) 22 models  (0.02689) 11 training  (0.02689)
60 (0.00335 / 67):  14 number  (0.14130) 15 system  (0.06570) 17 state  (0.06570) 16 error  (0.06570) 2 model  (0.06570) 7 figure  (0.06570) 8 time  (0.02790) 6 function  (0.02790) 9 set  (0.02790) 0 network  (0.02790) 1 learning  (0.02790) 5 data  (0.02790) 4 input  (0.02790) 3 neural  (0.02790) 24 performance  (0.02790) 20 information  (0.02790) 21 problem  (0.02790) 19 units  (0.02790) 23 hidden  (0.02790) 22 models  (0.02790)
61 (0.00251 / 67):  4 input  (0.11197) 9 set  (0.11197) 6 function  (0.07108) 10 networks  (0.07108) 8 time  (0.03019) 7 figure  (0.03019) 11 training  (0.03019) 0 network  (0.03019) 1 learning  (0.03019) 5 data  (0.03019) 3 neural  (0.03019) 2 model  (0.03019) 24 performance  (0.03019) 20 information  (0.03019) 21 problem  (0.03019) 19 units  (0.03019) 18 results  (0.03019) 23 hidden  (0.03019) 22 models  (0.03019) 12 algorithm  (0.03019)
62 (0.00251 / 67):  16 error  (0.07108) 21 problem  (0.07108) 17 state  (0.07108) 18 results  (0.07108) 23 hidden  (0.07108) 15 system  (0.07108) 4 input  (0.03019) 7 figure  (0.03019) 5 data  (0.03019) 6 function  (0.03019) 8 time  (0.03019) 0 network  (0.03019) 1 learning  (0.03019) 3 neural  (0.03019) 2 model  (0.03019) 24 performance  (0.03019) 19 units  (0.03019) 20 information  (0.03019) 14 number  (0.03019) 22 models  (0.03019)
63 (0.00209 / 67):  4 input  (0.11674) 8 time  (0.07411) 5 data  (0.07411) 16 error  (0.07411) 10 networks  (0.03147) 7 figure  (0.03147) 9 set  (0.03147) 11 training  (0.03147) 0 network  (0.03147) 1 learning  (0.03147) 6 function  (0.03147) 3 neural  (0.03147) 2 model  (0.03147) 24 performance  (0.03147) 20 information  (0.03147) 21 problem  (0.03147) 19 units  (0.03147) 23 hidden  (0.03147) 22 models  (0.03147) 12 algorithm  (0.03147)
64 (0.00126 / 67):  18 results  (0.08101) 20 information  (0.08101) 17 state  (0.08101) 6 function  (0.03441) 5 data  (0.03441) 9 set  (0.03441) 7 figure  (0.03441) 8 time  (0.03441) 10 networks  (0.03441) 0 network  (0.03441) 1 learning  (0.03441) 4 input  (0.03441) 3 neural  (0.03441) 2 model  (0.03441) 24 performance  (0.03441) 19 units  (0.03441) 21 problem  (0.03441) 16 error  (0.03441) 23 hidden  (0.03441) 22 models  (0.03441)
65 (0.00042 / 67):  15 system  (0.08934) 8 time  (0.03794) 7 figure  (0.03794) 6 function  (0.03794) 10 networks  (0.03794) 9 set  (0.03794) 11 training  (0.03794) 1 learning  (0.03794) 2 model  (0.03794) 0 network  (0.03794) 5 data  (0.03794) 4 input  (0.03794) 3 neural  (0.03794) 24 performance  (0.03794) 20 information  (0.03794) 21 problem  (0.03794) 19 units  (0.03794) 23 hidden  (0.03794) 22 models  (0.03794) 12 algorithm  (0.03794)
66 (0.00042 / 67):  11 training  (0.08934) 7 figure  (0.03794) 8 time  (0.03794) 6 function  (0.03794) 10 networks  (0.03794) 9 set  (0.03794) 0 network  (0.03794) 1 learning  (0.03794) 2 model  (0.03794) 5 data  (0.03794) 4 input  (0.03794) 3 neural  (0.03794) 24 performance  (0.03794) 20 information  (0.03794) 21 problem  (0.03794) 19 units  (0.03794) 18 results  (0.03794) 23 hidden  (0.03794) 22 models  (0.03794) 12 algorithm  (0.03794)
